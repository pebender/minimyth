diff -Naur xine-lib-1.1.15-old/configure.ac xine-lib-1.1.15-new/configure.ac
--- xine-lib-1.1.15-old/configure.ac	2008-08-13 09:26:38.000000000 -0700
+++ xine-lib-1.1.15-new/configure.ac	2008-12-22 09:11:43.000000000 -0800
@@ -863,6 +863,20 @@
 
 
 dnl ---------------------------------------------
+dnl Check for VDPAU
+dnl ---------------------------------------------
+AC_ARG_WITH([vdpau], AS_HELP_STRING([--without-vdpau], [Doesn't build VDPAU plugins]))
+if test "x$with_vdpau" != "xno"; then
+  AC_CHECK_HEADERS([vdpau/vdpau_x11.h], [have_vdpau=yes], [have_vdpau=no])
+  if test "x$have_vdpau" = "xyes"; then
+    AC_CHECK_LIB(vdpau, vdp_device_create_x11, have_vdpau="yes", [have_vdpau="no"], [$X_LIBS $X_PRE_LIBS -lXext $X_EXTRA_LIBS])
+  fi
+fi
+
+AM_CONDITIONAL(HAVE_VDPAU, test "x$have_vdpau" = "xyes" )
+
+
+dnl ---------------------------------------------
 dnl Check for xcb
 dnl ---------------------------------------------
 AC_ARG_WITH([xcb], AS_HELP_STRING([--without-xcb], [Doesn't build XCB video out plugins]))
@@ -2747,6 +2761,7 @@
 src/libmpeg2/Makefile
 src/libmusepack/Makefile
 src/libmusepack/musepack/Makefile
+src/libvdpau/Makefile
 src/libspudec/Makefile
 src/libspucc/Makefile
 src/libspucmml/Makefile
@@ -3083,6 +3098,9 @@
     echo "   - xcb-xv (XVideo using XCB)"
   fi
 fi
+if test "x$have_vdpau" = "xyes"; then
+  echo "   - vdpau (X11 VDPAU)"
+fi
 if test "x$no_aalib" != "xyes"; then
   echo "   - aa (Ascii ART)"
 fi
diff -Naur xine-lib-1.1.15-old/include/xine.h.in xine-lib-1.1.15-new/include/xine.h.in
--- xine-lib-1.1.15-old/include/xine.h.in	2008-06-25 06:04:09.000000000 -0700
+++ xine-lib-1.1.15-new/include/xine.h.in	2008-12-22 09:11:43.000000000 -0800
@@ -482,6 +482,7 @@
 #define XINE_IMGFMT_YUY2 (('2'<<24)|('Y'<<16)|('U'<<8)|'Y')
 #define XINE_IMGFMT_XVMC (('C'<<24)|('M'<<16)|('v'<<8)|'X')
 #define XINE_IMGFMT_XXMC (('C'<<24)|('M'<<16)|('x'<<8)|'X')
+#define XINE_IMGFMT_VDPAU (('A'<<24)|('P'<<16)|('D'<<8)|'V')
 
 /* get current xine's virtual presentation timestamp (1/90000 sec)
  * note: this is mostly internal data.
diff -Naur xine-lib-1.1.15-old/README-VDPAU xine-lib-1.1.15-new/README-VDPAU
--- xine-lib-1.1.15-old/README-VDPAU	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/README-VDPAU	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,74 @@
+xine-vdpau README:
+------------------------------------------------------------------------------
+
+So, you want to give it a try, but wonder which steps are required.
+Ok, so here it is:
+
+0) you need nvidia's driver 180.16 or later.
+
+1) get the sources:
+svn co svn://jusst.de/xine-vdpau
+
+2) compile the sources:
+cd xine-vdpau
+./autogen.sh
+./configure
+make
+make install (as root)
+    **(make sure that no other xine-lib installation will conflict with this one)
+
+3) edit your xine configuration
+nano $HOME/.xine/config (if it does not exist, first run "xine --no-logo" then quit.
+search for "engine.buffers.video_num_frames" and set it to 22
+
+4) running the beast:
+xine --no-logo --verbose /path/to/a/working/sample
+    ** the --no-logo will tell xine to not play its crappy mpv logo (which, atm, doesn't work with vdpau_mpeg12)
+    ** --verbose will print some usefull things in your console (in case of problems, that are very likely to happen,
+        the developers will ask you to give this output, at least)
+    ** You can find working h264 samples at http://hftom.free.fr/video_samples/
+    ** MKV or MOV WON'T WORK, at that moment. (we are concentrating on TS streams, but yes, it will work in the future)
+    ** most mpeg2 should work, if you have a non working one, please provide a sample.
+
+5) update your svn copy quite often
+
+6) don't blame us if it crashes, burn you gpu (unlikely:) or anything else.
+
+
+------------------------------------------------------------------------------
+
+FAQ:
+
+Q:
+  Why my file plays fine with mplayer-vdpau and not with xine-vdpau?
+A:
+  We are not using the nvidia's libavcodec patch.
+  We are writing decoders from scratch.
+  So don't expect them to be as mature as ffmpeg ones. Not yet.
+
+Q:
+  Why mpeg2 doesn't use less cpu than software decoder?
+A:
+  Because at that moment it does a lot of memcpy. This will be fixed soon, but that's not
+  a priority. Stability is our focus.
+
+Q:
+  Is deinterlacing working?
+A:
+  Yes. It's already quite good (doing 50i->50p), but could even be better in the future.
+
+Q:
+  How do i get it working with VDR, Kaffeine, whatever.
+A:
+  Ask VDR, Kaffeine, whatever developers.
+    (Note: for kaffeine you are lucky, i'm going to tell you the tip.
+     Build kaffeine like that: ./configure --without-xcb && make && make install)
+
+Q:
+  How can i contact you?
+A:
+  IRC: #xine-vdpau on freenode
+  MAIL: http://lists.kafic.ba/mailman/listinfo/xine-vdpau
+  Eventually, nvnews.
+
+----------------------------------------------------------------------------
diff -Naur xine-lib-1.1.15-old/src/libvdpau/dpb.c xine-lib-1.1.15-new/src/libvdpau/dpb.c
--- xine-lib-1.1.15-old/src/libvdpau/dpb.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/dpb.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,365 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * dpb.c: Implementing Decoded Picture Buffer
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "dpb.h"
+#include "nal.h"
+#include "video_out.h"
+
+struct decoded_picture* init_decoded_picture(struct nal_unit *src_nal,
+    VdpVideoSurface surface, vo_frame_t *img)
+{
+  struct decoded_picture *pic = malloc(sizeof(struct decoded_picture));
+  pic->nal = init_nal_unit();
+  copy_nal_unit(pic->nal, src_nal);
+  pic->used_for_reference = 0;
+  pic->delayed_output = 0;
+  pic->top_is_reference = pic->nal->slc->field_pic_flag
+        ? (pic->nal->slc->bottom_field_flag ? 0 : 1) : 1;
+  pic->bottom_is_reference = pic->nal->slc->field_pic_flag
+        ? (pic->nal->slc->bottom_field_flag ? 1 : 0) : 1;
+  pic->surface = surface;
+  pic->img = img;
+  pic->next = NULL;
+
+  return pic;
+}
+
+void free_decoded_picture(struct decoded_picture *pic)
+{
+  pic->img->free(pic->img);
+  free_nal_unit(pic->nal);
+}
+
+struct decoded_picture* dpb_get_next_out_picture(struct dpb *dpb)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  struct decoded_picture *outpic = NULL;
+
+  if(dpb->used < MAX_DPB_SIZE)
+    return NULL;
+
+  if (pic != NULL)
+    do {
+      if (pic->delayed_output &&
+          (outpic == NULL ||
+              (pic->nal->top_field_order_cnt <= outpic->nal->top_field_order_cnt &&
+                  pic->nal->bottom_field_order_cnt <= outpic->nal->bottom_field_order_cnt)||
+              outpic->nal->nal_unit_type == NAL_SLICE_IDR))
+        outpic = pic;
+    } while ((pic = pic->next) != NULL);
+
+  return outpic;
+}
+
+struct decoded_picture* dpb_get_picture(struct dpb *dpb, uint32_t picnum)
+{
+  struct decoded_picture *pic = dpb->pictures;
+
+  if (pic != NULL)
+    do {
+      if (pic->nal->curr_pic_num == picnum)
+        return pic;
+    } while ((pic = pic->next) != NULL);
+
+  return NULL;
+}
+
+struct decoded_picture* dpb_get_picture_by_ltpn(struct dpb *dpb,
+    uint32_t longterm_picnum)
+{
+  struct decoded_picture *pic = dpb->pictures;
+
+  if (pic != NULL)
+    do {
+      if (pic->nal->long_term_pic_num == longterm_picnum)
+        return pic;
+    } while ((pic = pic->next) != NULL);
+
+  return NULL;
+}
+
+struct decoded_picture* dpb_get_picture_by_ltidx(struct dpb *dpb,
+    uint32_t longterm_idx)
+{
+  struct decoded_picture *pic = dpb->pictures;
+
+  if (pic != NULL)
+    do {
+      if (pic->nal->long_term_frame_idx == longterm_idx)
+        return pic;
+    } while ((pic = pic->next) != NULL);
+
+  return NULL;
+}
+
+int dpb_set_unused_ref_picture_a(struct dpb *dpb, struct decoded_picture *refpic)
+{
+  struct decoded_picture *pic = dpb->pictures;
+    if (pic != NULL)
+      do {
+        if (pic == refpic) {
+          pic->used_for_reference = 0;
+          if(!pic->delayed_output)
+            dpb_remove_picture(dpb, pic);
+          return 0;
+        }
+      } while ((pic = pic->next) != NULL);
+
+    return -1;
+}
+
+int dpb_set_unused_ref_picture(struct dpb *dpb, uint32_t picnum)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  if (pic != NULL)
+    do {
+      if (pic->nal->curr_pic_num == picnum) {
+        pic->used_for_reference = 0;
+        if(!pic->delayed_output)
+          dpb_remove_picture(dpb, pic);
+        return 0;
+      }
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_set_unused_ref_picture_byltpn(struct dpb *dpb, uint32_t longterm_picnum)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  if (pic != NULL)
+    do {
+      if (pic->nal->long_term_pic_num == longterm_picnum) {
+        pic->used_for_reference = 0;
+        if(!pic->delayed_output)
+          dpb_remove_picture(dpb, pic);
+        return 0;
+      }
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_set_unused_ref_picture_bylidx(struct dpb *dpb, uint32_t longterm_idx)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  if (pic != NULL)
+    do {
+      if (pic->nal->long_term_frame_idx == longterm_idx) {
+        pic->used_for_reference = 0;
+        if(!pic->delayed_output)
+          dpb_remove_picture(dpb, pic);
+        return 0;
+      }
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_set_unused_ref_picture_lidx_gt(struct dpb *dpb, uint32_t longterm_idx)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  if (pic != NULL)
+    do {
+      if (pic->nal->long_term_frame_idx >= longterm_idx) {
+        pic->used_for_reference = 0;
+        if(!pic->delayed_output) {
+          struct decoded_picture *next_pic = pic->next;
+          dpb_remove_picture(dpb, pic);
+          pic = next_pic;
+          continue;
+        }
+      }
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+
+int dpb_set_output_picture(struct dpb *dpb, struct decoded_picture *outpic)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  if (pic != NULL)
+    do {
+      if (pic == outpic) {
+        pic->delayed_output = 0;
+        if(!pic->used_for_reference)
+          dpb_remove_picture(dpb, pic);
+        return 0;
+      }
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_remove_picture(struct dpb *dpb, struct decoded_picture *rempic)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  struct decoded_picture *last_pic = NULL;
+
+  if (pic != NULL)
+    do {
+      if (pic == rempic) {
+        // FIXME: free the picture....
+
+        if (last_pic != NULL)
+          last_pic->next = pic->next;
+        else
+          dpb->pictures = pic->next;
+        free_decoded_picture(pic);
+        dpb->used--;
+        return 0;
+      }
+
+      last_pic = pic;
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_remove_picture_by_picnum(struct dpb *dpb, uint32_t picnum)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  struct decoded_picture *last_pic = NULL;
+
+  if (pic != NULL)
+    do {
+      if (pic->nal->curr_pic_num == picnum) {
+        dpb_remove_picture(dpb, pic);
+      }
+
+      last_pic = pic;
+    } while ((pic = pic->next) != NULL);
+
+  return -1;
+}
+
+int dpb_add_picture(struct dpb *dpb, struct decoded_picture *pic, uint32_t num_ref_frames)
+{
+  int i = 0;
+  struct decoded_picture *last_pic;
+
+  pic->next = dpb->pictures;
+  dpb->pictures = pic;
+  dpb->num_ref_frames = num_ref_frames;
+  dpb->used++;
+
+  if(dpb->used > num_ref_frames) {
+    do {
+      if(pic->used_for_reference) {
+        i++;
+        if(i>num_ref_frames) {
+          pic->used_for_reference = 0;
+          if(!pic->delayed_output) {
+            dpb_remove_picture(dpb, pic);
+          }
+          pic = last_pic;
+        }
+        last_pic = pic;
+      }
+    } while ((pic = pic->next) != NULL);
+  }
+
+  return 0;
+}
+
+int dpb_flush(struct dpb *dpb)
+{
+  struct decoded_picture *pic = dpb->pictures;
+
+  if (pic != NULL)
+    do {
+      struct decoded_picture *next_pic = pic->next;
+      dpb_set_unused_ref_picture_a(dpb, pic);
+      pic = next_pic;
+    } while (pic != NULL);
+
+  printf("Flushed, used: %d\n", dpb->used);
+  //dpb->pictures = NULL;
+  //dpb->used = 0;
+
+  return 0;
+}
+
+void dpb_free_all( struct dpb *dpb )
+{
+  struct decoded_picture *pic = dpb->pictures;
+
+  if (pic != NULL)
+    do {
+      struct decoded_picture *next_pic = pic->next;
+      free_decoded_picture(pic);
+      --dpb->used;
+      pic = next_pic;
+    } while (pic != NULL);
+
+  printf("dpb_free_all, used: %d\n", dpb->used);
+}
+
+int fill_vdpau_reference_list(struct dpb *dpb, VdpReferenceFrameH264 *reflist)
+{
+  struct decoded_picture *pic = dpb->pictures;
+  struct decoded_picture *last_pic = NULL;
+
+  int i = 0;
+  int used_refframes = 0;
+
+  if (pic != NULL)
+    do {
+      if (pic->used_for_reference) {
+        reflist[i].surface = pic->surface;
+        reflist[i].is_long_term = pic->nal->used_for_long_term_ref;
+        if(reflist[i].is_long_term)
+          reflist[i].frame_idx = pic->nal->slc->frame_num; //pic->nal->long_term_frame_idx;
+        else
+          reflist[i].frame_idx = pic->nal->slc->frame_num; //pic->nal->curr_pic_num;
+        reflist[i].top_is_reference = pic->top_is_reference; /*pic->nal->slc->field_pic_flag
+            ? (pic->nal->slc->bottom_field_flag ? 0 : 1) : 1;*/
+        reflist[i].bottom_is_reference = pic->bottom_is_reference; /*pic->nal->slc->field_pic_flag
+            ? (pic->nal->slc->bottom_field_flag ? 1 : 0) : 1;*/
+        reflist[i].field_order_cnt[0] = pic->nal->top_field_order_cnt;
+        reflist[i].field_order_cnt[1] = pic->nal->bottom_field_order_cnt;
+        i++;
+      }
+      last_pic = pic;
+    } while ((pic = pic->next) != NULL && i < 16);
+
+  used_refframes = i;
+
+  // fill all other frames with invalid handles
+  while(i < 16) {
+    reflist[i].bottom_is_reference = VDP_FALSE;
+    reflist[i].top_is_reference = VDP_FALSE;
+    reflist[i].frame_idx = 0;
+    reflist[i].is_long_term = VDP_FALSE;
+    reflist[i].surface = VDP_INVALID_HANDLE;
+    reflist[i].field_order_cnt[0] = 0;
+    reflist[i].field_order_cnt[1] = 0;
+    i++;
+  }
+
+  return used_refframes;
+}
diff -Naur xine-lib-1.1.15-old/src/libvdpau/dpb.h xine-lib-1.1.15-new/src/libvdpau/dpb.h
--- xine-lib-1.1.15-old/src/libvdpau/dpb.h	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/dpb.h	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,78 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * dpb.h: Decoder Picture Buffer
+ */
+
+#ifndef DPB_H_
+#define DPB_H_
+
+#define MAX_DPB_SIZE 16
+
+#include "nal.h"
+#include "video_out.h"
+
+struct decoded_picture {
+  VdpVideoSurface surface;
+  vo_frame_t *img; /* this is the image we block, to make sure
+                    * the surface is not double-used */
+  struct nal_unit *nal;
+
+  uint8_t used_for_reference;
+  uint8_t top_is_reference;
+  uint8_t bottom_is_reference;
+
+  uint8_t delayed_output;
+
+  struct decoded_picture *next;
+};
+
+/* Decoded Picture Buffer */
+struct dpb {
+  struct decoded_picture *pictures;
+
+  uint32_t num_ref_frames;
+  uint32_t used;
+};
+
+struct decoded_picture* init_decoded_picture(struct nal_unit *src_nal,
+    VdpVideoSurface surface, vo_frame_t *img);
+void free_decoded_picture(struct decoded_picture *pic);
+
+struct decoded_picture* dpb_get_next_out_picture(struct dpb *dpb);
+
+struct decoded_picture* dpb_get_picture(struct dpb *dpb, uint32_t picnum);
+struct decoded_picture* dpb_get_picture_by_ltpn(struct dpb *dpb, uint32_t longterm_picnum);
+struct decoded_picture* dpb_get_picture_by_ltidx(struct dpb *dpb, uint32_t longterm_idx);
+
+int dpb_set_unused_ref_picture(struct dpb *dpb, uint32_t picnum);
+int dpb_set_unused_ref_picture_byltpn(struct dpb *dpb, uint32_t longterm_picnum);
+int dpb_set_unused_ref_picture_bylidx(struct dpb *dpb, uint32_t longterm_idx);
+int dpb_set_unused_ref_picture_lidx_gt(struct dpb *dpb, uint32_t longterm_idx);
+
+int dpb_set_output_picture(struct dpb *dpb, struct decoded_picture *outpic);
+
+int dpb_remove_picture(struct dpb *dpb, struct decoded_picture *rempic);
+int dpb_add_picture(struct dpb *dpb, struct decoded_picture *pic, uint32_t num_ref_frames);
+int dpb_flush(struct dpb *dpb);
+void dpb_free_all( struct dpb *dpb );
+
+int fill_vdpau_reference_list(struct dpb *dpb, VdpReferenceFrameH264 *reflist);
+
+#endif /* DPB_H_ */
diff -Naur xine-lib-1.1.15-old/src/libvdpau/h264_parser.c xine-lib-1.1.15-new/src/libvdpau/h264_parser.c
--- xine-lib-1.1.15-old/src/libvdpau/h264_parser.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/h264_parser.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,1319 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * h264_parser.c: Almost full-features H264 NAL-Parser
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <math.h>
+
+#include "h264_parser.h"
+#include "nal.h"
+
+/* default scaling_lists according to Table 7-2 */
+uint8_t default_4x4_intra[16] = { 6, 13, 13, 20, 20, 20, 28, 28, 28, 28, 32,
+    32, 32, 37, 37, 42 };
+
+uint8_t default_4x4_inter[16] = { 10, 14, 14, 20, 20, 20, 24, 24, 24, 24, 27,
+    27, 27, 30, 30, 34 };
+
+uint8_t default_8x8_intra[64] = { 6, 10, 10, 13, 11, 13, 16, 16, 16, 16, 18,
+    18, 18, 18, 18, 32, 23, 23, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 27, 27,
+    27, 27, 27, 27, 27, 27, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31,
+    33, 33, 33, 33, 33, 36, 36, 36, 36, 38, 38, 38, 40, 40, 42 };
+
+uint8_t default_8x8_inter[64] = { 9, 13, 13, 15, 13, 15, 17, 17, 17, 17, 19,
+    19, 19, 19, 19, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 24, 24,
+    24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 27, 27, 27, 27, 27, 27,
+    28, 28, 28, 28, 28, 30, 30, 30, 30, 32, 32, 32, 33, 33, 35 };
+
+struct buf_reader
+{
+  uint8_t *buf;
+  uint8_t *cur_pos;
+  int len;
+  int cur_offset;
+};
+
+static inline uint32_t read_bits(struct buf_reader *buf, int len);
+uint32_t read_exp_golomb(struct buf_reader *buf);
+int32_t read_exp_golomb_s(struct buf_reader *buf);
+
+void calculate_pic_order(struct nal_parser *parser);
+void skip_scaling_list(struct buf_reader *buf, int size);
+void parse_scaling_list(struct buf_reader *buf, uint8_t *scaling_list,
+    int length, int index);
+int parse_nal_header(struct buf_reader *buf, struct nal_parser *parser);
+uint8_t parse_sps(struct buf_reader *buf, struct nal_parser *parser);
+void parse_vui_parameters(struct buf_reader *buf,
+    struct seq_parameter_set_rbsp *sps);
+void parse_hrd_parameters(struct buf_reader *buf, struct hrd_parameters *hrd);
+uint8_t parse_pps(struct buf_reader *buf, struct pic_parameter_set_rbsp *pps,
+    struct seq_parameter_set_rbsp *sps);
+void parse_sei(struct buf_reader *buf, struct nal_parser *parser);
+uint8_t parse_slice_header(struct buf_reader *buf, struct nal_parser *parser);
+void
+    parse_ref_pic_list_reordering(struct buf_reader *buf, struct nal_unit *nal);
+void decode_ref_pic_marking(uint32_t memory_management_control_operation,
+    struct nal_parser *parser);
+void parse_pred_weight_table(struct buf_reader *buf, struct nal_unit *nal);
+void parse_dec_ref_pic_marking(struct buf_reader *buf,
+    struct nal_parser *parser);
+
+/* here goes the parser implementation */
+
+static void decode_nal(uint8_t **ret, int *len_ret, uint8_t *buf, int buf_len)
+{
+  uint8_t *end = &buf[buf_len];
+  uint8_t *pos = malloc(buf_len);
+
+  *ret = pos;
+  while (buf < end) {
+    if (buf < end - 3 && buf[0] == 0x00 && buf[1] == 0x00 && buf[2] == 0x03) {
+
+      *pos++ = 0x00;
+      *pos++ = 0x00;
+
+      buf += 3;
+      continue;
+    }
+    *pos++ = *buf++;
+  }
+
+  *len_ret = pos - *ret;
+}
+
+static inline dump_bits(uint32_t bits)
+{
+  int i;
+  printf("0b");
+  for(i=0; i < 32; i++)
+    printf("%d", (bits >> 31-i) & 0x01);
+  printf("\n");
+}
+
+static inline uint32_t read_bits(struct buf_reader *buf, int len)
+{
+  static uint32_t i_mask[33] = { 0x00, 0x01, 0x03, 0x07, 0x0f, 0x1f, 0x3f,
+      0x7f, 0xff, 0x1ff, 0x3ff, 0x7ff, 0xfff, 0x1fff, 0x3fff, 0x7fff, 0xffff,
+      0x1ffff, 0x3ffff, 0x7ffff, 0xfffff, 0x1fffff, 0x3fffff, 0x7fffff,
+      0xffffff, 0x1ffffff, 0x3ffffff, 0x7ffffff, 0xfffffff, 0x1fffffff,
+      0x3fffffff, 0x7fffffff, 0xffffffff };
+
+  int i_shr;
+  uint32_t bits = 0;
+
+  while (len > 0 && (buf->cur_pos - buf->buf) < buf->len) {
+    if ((i_shr = buf->cur_offset - len) >= 0) {
+      bits |= (*buf->cur_pos >> i_shr) & i_mask[len];
+      buf->cur_offset -= len;
+      if (buf->cur_offset == 0) {
+        buf->cur_pos++;
+        buf->cur_offset = 8;
+      }
+      //dump_bits(bits);
+      return bits;
+    }
+    else {
+      bits |= (*buf->cur_pos & i_mask[buf->cur_offset]) << -i_shr;
+      //dump_bits(bits);
+      len -= buf->cur_offset;
+      buf->cur_pos++;
+      buf->cur_offset = 8;
+    }
+  }
+  return bits;
+}
+
+/* determines if following bits are rtsb_trailing_bits */
+static inline uint8_t rbsp_trailing_bits(struct buf_reader *buf)
+{
+  // store the offset and pos in buffer
+  // to revert this afterwards.
+  int last_offset;
+  uint8_t *last_pos;
+
+  uint8_t rbsp_trailing_bits = 1;
+
+  last_offset = buf->cur_offset;
+  last_pos = buf->cur_pos;
+
+  if (read_bits(buf, 1) == 1) {
+    while (buf->cur_offset != 8)
+      if (read_bits(buf, 1) == 1)
+        rbsp_trailing_bits = 0;
+  }
+
+  // revert buffer
+  buf->cur_offset = last_offset;
+  buf->cur_pos = last_pos;
+
+  return rbsp_trailing_bits;
+}
+
+uint32_t read_exp_golomb(struct buf_reader *buf)
+{
+  int leading_zero_bits = 0;
+
+  while (read_bits(buf, 1) == 0 && leading_zero_bits < 32)
+    leading_zero_bits++;
+
+  uint32_t code = (1 << leading_zero_bits) - 1 + read_bits(buf,
+      leading_zero_bits);
+  return code;
+}
+
+int32_t read_exp_golomb_s(struct buf_reader *buf)
+{
+  uint32_t ue = read_exp_golomb(buf);
+  int32_t code = ue & 0x01 ? (ue + 1) / 2 : -(ue / 2);
+  return code;
+}
+
+int parse_nal_header(struct buf_reader *buf, struct nal_parser *parser)
+{
+  if (buf->len < 1)
+    return -1;
+
+  int ret = -1;
+
+  struct nal_unit *nal = parser->current_nal;
+
+  nal->nal_ref_idc = (buf->buf[0] >> 5) & 0x03;
+  nal->nal_unit_type = buf->buf[0] & 0x1f;
+
+  buf->cur_pos = buf->buf + 1;
+  //printf("NAL: %d\n", nal->nal_unit_type);
+
+  struct buf_reader ibuf;
+  ibuf.cur_offset = 8;
+
+  switch (nal->nal_unit_type) {
+    case NAL_SPS:
+      decode_nal(&ibuf.buf, &ibuf.len, buf->cur_pos, buf->len - 1);
+      ibuf.cur_pos = ibuf.buf;
+
+      if (!nal->sps)
+        nal->sps = malloc(sizeof(struct seq_parameter_set_rbsp));
+
+      memset(nal->sps, 0x00, sizeof(struct seq_parameter_set_rbsp));
+
+      parse_sps(&ibuf, parser);
+      free(ibuf.buf);
+      ret = NAL_SPS;
+      break;
+    case NAL_PPS:
+      if (!nal->pps)
+        nal->pps = malloc(sizeof(struct pic_parameter_set_rbsp));
+      memset(nal->pps, 0x00, sizeof(struct pic_parameter_set_rbsp));
+
+      parse_pps(buf, nal->pps, nal->sps);
+      ret = NAL_PPS;
+      break;
+    case NAL_SLICE:
+    case NAL_PART_A:
+    case NAL_PART_B:
+    case NAL_PART_C:
+    case NAL_SLICE_IDR:
+      if (nal->sps && nal->pps) {
+        if (!nal->slc)
+          nal->slc = malloc(sizeof(struct slice_header));
+
+        memset(nal->slc, 0x00, sizeof(struct slice_header));
+
+        parse_slice_header(buf, parser);
+        ret = nal->nal_unit_type;
+      }
+      break;
+    case NAL_SEI:
+      parse_sei(buf, parser);
+      ret = nal->nal_unit_type;
+      break;
+    default:
+      ret = nal->nal_unit_type;
+      break;
+  }
+
+  return ret;
+}
+
+void calculate_pic_order(struct nal_parser *parser)
+{
+  struct nal_unit *nal = parser->current_nal;
+
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  if (!sps || !pps || !slc)
+    return;
+
+  if (sps->pic_order_cnt_type == 0) {
+    if (nal->nal_unit_type == NAL_SLICE_IDR) {
+      //printf("IDR SLICE\n");
+      parser->prev_pic_order_cnt_lsb = 0;
+      parser->prev_pic_order_cnt_msb = 0;
+    }
+
+    const int max_poc_lsb = 1 << (sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+
+    if (slc->pic_order_cnt_lsb < parser->prev_pic_order_cnt_lsb
+        && parser->prev_pic_order_cnt_lsb - slc->pic_order_cnt_lsb
+            >= max_poc_lsb / 2)
+      parser->pic_order_cnt_msb = parser->prev_pic_order_cnt_msb + max_poc_lsb;
+    else if (slc->pic_order_cnt_lsb > parser->prev_pic_order_cnt_lsb
+        && parser->prev_pic_order_cnt_lsb - slc->pic_order_cnt_lsb
+            < -max_poc_lsb / 2)
+      parser->pic_order_cnt_msb = parser->prev_pic_order_cnt_msb - max_poc_lsb;
+    else
+      parser->pic_order_cnt_msb = parser->prev_pic_order_cnt_msb;
+
+    /*if (!slc->bottom_field_flag) {
+      nal->top_field_order_cnt = parser->pic_order_cnt_msb
+          + slc->pic_order_cnt_lsb;
+
+      if (!slc->field_pic_flag)
+        nal->bottom_field_order_cnt = nal->top_field_order_cnt;
+      else
+        nal->bottom_field_order_cnt = 0;
+    }
+    else
+      nal->bottom_field_order_cnt = parser->pic_order_cnt_msb
+          + slc->pic_order_cnt_lsb;
+
+    if (parser->field == -1)
+      nal->bottom_field_order_cnt += slc->delta_pic_order_cnt_bottom;
+    */
+
+    if(!slc->field_pic_flag || !slc->bottom_field_flag)
+      nal->top_field_order_cnt = parser->pic_order_cnt_msb + slc->pic_order_cnt_lsb;
+
+    if(!slc->field_pic_flag)
+      nal->bottom_field_order_cnt = nal->top_field_order_cnt + slc->delta_pic_order_cnt_bottom;
+    else
+      nal->bottom_field_order_cnt = parser->pic_order_cnt_msb + slc->pic_order_cnt_lsb;
+
+
+  } else {
+    printf("FIXME: Unsupported poc_type\n");
+  }
+
+}
+
+void skip_scaling_list(struct buf_reader *buf, int size)
+{
+  int i;
+  for (i = 0; i < size; i++) {
+    read_exp_golomb_s(buf);
+  }
+}
+
+void parse_scaling_list(struct buf_reader *buf, uint8_t *scaling_list,
+    int length, int index)
+{
+  int last_scale = 8;
+  int next_scale = 8;
+  int32_t delta_scale;
+  uint8_t use_default_scaling_matrix_flag = 0;
+  int i;
+
+  for (i = 0; i < length; i++) {
+    if (next_scale != 0) {
+      delta_scale = read_exp_golomb_s(buf);
+      next_scale = (last_scale + delta_scale + 256) % 256;
+      if (i == 0 && next_scale == 0) {
+        use_default_scaling_matrix_flag = 1;
+        break;
+      }
+    }
+    scaling_list[i] = (next_scale == 0) ? last_scale : next_scale;
+    last_scale = scaling_list[i];
+  }
+
+  if (use_default_scaling_matrix_flag) {
+    switch (index) {
+      case 0:
+      case 1:
+      case 2:
+        memcpy(scaling_list, default_4x4_intra, length);
+        break;
+      case 3:
+      case 4:
+      case 5:
+        memcpy(scaling_list, default_4x4_inter, length);
+        break;
+      case 6:
+        memcpy(scaling_list, default_8x8_intra, length);
+        break;
+      case 7:
+        memcpy(scaling_list, default_8x8_inter, length);
+        break;
+    }
+  }
+}
+
+uint8_t parse_sps(struct buf_reader *buf, struct nal_parser *parser)
+{
+  struct seq_parameter_set_rbsp *sps = parser->current_nal->sps;
+  sps->profile_idc = buf->buf[0];
+  sps->constraint_setN_flag = (buf->buf[1] >> 4) & 0x0f;
+  sps->level_idc = buf->buf[2];
+
+  buf->cur_pos = buf->buf + 3;
+  sps->seq_parameter_set_id = read_exp_golomb(buf);
+  if (sps->profile_idc == 100 || sps->profile_idc == 110 || sps->profile_idc
+      == 122 || sps->profile_idc == 144) {
+    sps->chroma_format_idc = read_exp_golomb(buf);
+    if (sps->chroma_format_idc == 3) {
+      sps->residual_colour_transform_flag = read_bits(buf, 1);
+    }
+
+    sps->bit_depth_luma_minus8 = read_exp_golomb(buf);
+    sps->bit_depth_chroma_minus8 = read_exp_golomb(buf);
+    sps->qpprime_y_zero_transform_bypass_flag = read_bits(buf, 1);
+    sps->seq_scaling_matrix_present_flag = read_bits(buf, 1);
+    if (sps->seq_scaling_matrix_present_flag) {
+      int i;
+      for (i = 0; i < 8; i++) {
+        sps->seq_scaling_list_present_flag[i] = read_bits(buf, 1);
+
+        if (sps->seq_scaling_list_present_flag[i]) {
+          if (i < 6)
+            parse_scaling_list(buf, sps->scaling_lists_4x4[i], 16, i);
+          else
+            parse_scaling_list(buf, sps->scaling_lists_8x8[i - 6], 64, i);
+        }
+      }
+    }
+  }
+
+  if (!sps->seq_scaling_matrix_present_flag) {
+    memset(sps->scaling_lists_4x4, 16, sizeof(sps->scaling_lists_4x4));
+    memset(sps->scaling_lists_8x8, 16, sizeof(sps->scaling_lists_4x4));
+  }
+
+  sps->log2_max_frame_num_minus4 = read_exp_golomb(buf);
+
+  sps->pic_order_cnt_type = read_exp_golomb(buf);
+  if (!sps->pic_order_cnt_type)
+    sps->log2_max_pic_order_cnt_lsb_minus4 = read_exp_golomb(buf);
+  else {
+    sps->delta_pic_order_always_zero_flag = read_bits(buf, 1);
+    sps->offset_for_non_ref_pic = read_exp_golomb_s(buf);
+    sps->offset_for_top_to_bottom_field = read_exp_golomb_s(buf);
+    sps->num_ref_frames_in_pic_order_cnt_cycle = read_exp_golomb(buf);
+    int i;
+    for (i = 0; i < sps->num_ref_frames_in_pic_order_cnt_cycle; i++) {
+      sps->offset_for_ref_frame[i] = read_exp_golomb_s(buf);
+    }
+  }
+
+  sps->num_ref_frames = read_exp_golomb(buf);
+  sps->gaps_in_frame_num_value_allowed_flag = read_bits(buf, 1);
+
+  /*sps->pic_width_in_mbs_minus1 = read_exp_golomb(buf);
+   sps->pic_height_in_map_units_minus1 = read_exp_golomb(buf);*/
+  sps->pic_width = 16 * (read_exp_golomb(buf) + 1);
+  sps->pic_height = 16 * (read_exp_golomb(buf) + 1);
+
+  sps->frame_mbs_only_flag = read_bits(buf, 1);
+
+  /* compute the height correctly even for interlaced material */
+  sps->pic_height = (2 - sps->frame_mbs_only_flag) * sps->pic_height;
+  if (sps->pic_height == 1088)
+    sps->pic_height = 1080;
+
+  if (!sps->frame_mbs_only_flag)
+    sps->mb_adaptive_frame_field_flag = read_bits(buf, 1);
+
+  sps->direct_8x8_inference_flag = read_bits(buf, 1);
+  sps->frame_cropping_flag = read_bits(buf, 1);
+  if (sps->frame_cropping_flag) {
+    sps->frame_crop_left_offset = read_exp_golomb(buf);
+    sps->frame_crop_right_offset = read_exp_golomb(buf);
+    sps->frame_crop_top_offset = read_exp_golomb(buf);
+    sps->frame_crop_bottom_offset = read_exp_golomb(buf);
+  }
+  sps->vui_parameters_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters_present_flag) {
+    parse_vui_parameters(buf, sps);
+    if(sps->vui_parameters.nal_hrd_parameters_present_flag ||
+        sps->vui_parameters.vc1_hrd_parameters_present_flag) {
+      parser->cpb_dpb_delays_present_flag = 1;
+    } else
+      parser->cpb_dpb_delays_present_flag = 0;
+  } else
+    parser->cpb_dpb_delays_present_flag = 0;
+
+  return 0;
+}
+
+void parse_sei(struct buf_reader *buf, struct nal_parser *parser)
+{
+  struct sei_message *sei = &(parser->current_nal->sei);
+  uint8_t tmp;
+
+  sei->payload_type = 0;
+  while((tmp = read_bits(buf, 8)) == 0xff) {
+    sei->payload_type += 255;
+  }
+  sei->last_payload_type_byte = tmp;
+  sei->payload_type += sei->last_payload_type_byte;
+
+  sei->payload_size = 0;
+  while((tmp = read_bits(buf, 8)) == 0xff) {
+    sei->payload_size += 255;
+  }
+  sei->last_payload_size_byte = tmp;
+  sei->payload_size += sei->last_payload_size_byte;
+
+  /* pic_timing */
+  if(sei->payload_type == 1) {
+    if(parser->cpb_dpb_delays_present_flag) {
+      sei->pic_timing.cpb_removal_delay = read_bits(buf, 5);
+      sei->pic_timing.dpb_output_delay = read_bits(buf, 5);
+      printf("output delay: %d\n", sei->pic_timing.dpb_output_delay);
+    }
+  }
+}
+
+void parse_vui_parameters(struct buf_reader *buf,
+    struct seq_parameter_set_rbsp *sps)
+{
+  sps->vui_parameters.aspect_ration_info_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.aspect_ration_info_present_flag == 1) {
+    sps->vui_parameters.aspect_ratio_idc = read_bits(buf, 8);
+    if (sps->vui_parameters.aspect_ratio_idc == ASPECT_EXTENDED_SAR) {
+      sps->vui_parameters.sar_width = read_bits(buf, 16);
+      sps->vui_parameters.sar_height = read_bits(buf, 16);
+    }
+  }
+
+  sps->vui_parameters.overscan_info_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.overscan_info_present_flag) {
+    sps->vui_parameters.overscan_appropriate_flag = read_bits(buf, 1);
+  }
+
+  sps->vui_parameters.video_signal_type_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.video_signal_type_present_flag) {
+    sps->vui_parameters.video_format = read_bits(buf, 3);
+    sps->vui_parameters.video_full_range_flag = read_bits(buf, 1);
+    sps->vui_parameters.colour_description_present = read_bits(buf, 1);
+    if (sps->vui_parameters.colour_description_present) {
+      sps->vui_parameters.colour_primaries = read_bits(buf, 8);
+      sps->vui_parameters.transfer_characteristics = read_bits(buf, 8);
+      sps->vui_parameters.matrix_coefficients = read_bits(buf, 8);
+    }
+  }
+
+  sps->vui_parameters.chroma_loc_info_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.chroma_loc_info_present_flag) {
+    sps->vui_parameters.chroma_sample_loc_type_top_field = read_exp_golomb(buf);
+    sps->vui_parameters.chroma_sample_loc_type_bottom_field = read_exp_golomb(
+        buf);
+  }
+
+  sps->vui_parameters.timing_info_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.timing_info_present_flag) {
+    uint32_t num_units_in_tick = read_bits(buf, 32);
+    uint32_t time_scale = read_bits(buf, 32);
+    sps->vui_parameters.num_units_in_tick = num_units_in_tick;
+    sps->vui_parameters.time_scale = time_scale;
+    sps->vui_parameters.fixed_frame_rate_flag = read_bits(buf, 1);
+  }
+
+  sps->vui_parameters.nal_hrd_parameters_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.nal_hrd_parameters_present_flag)
+    parse_hrd_parameters(buf, &sps->vui_parameters.nal_hrd_parameters);
+
+  sps->vui_parameters.vc1_hrd_parameters_present_flag = read_bits(buf, 1);
+  if (sps->vui_parameters.vc1_hrd_parameters_present_flag)
+    parse_hrd_parameters(buf, &sps->vui_parameters.vc1_hrd_parameters);
+
+  if (sps->vui_parameters.nal_hrd_parameters_present_flag
+      || sps->vui_parameters.vc1_hrd_parameters_present_flag)
+    sps->vui_parameters.low_delay_hrd_flag = read_bits(buf, 1);
+
+  sps->vui_parameters.pic_struct_present_flag = read_bits(buf, 1);
+  sps->vui_parameters.bitstream_restriction_flag = read_bits(buf, 1);
+
+  if (sps->vui_parameters.bitstream_restriction_flag) {
+    sps->vui_parameters.motion_vectors_over_pic_boundaries = read_bits(buf, 1);
+    sps->vui_parameters.max_bytes_per_pic_denom = read_exp_golomb(buf);
+    sps->vui_parameters.max_bits_per_mb_denom = read_exp_golomb(buf);
+    sps->vui_parameters.log2_max_mv_length_horizontal = read_exp_golomb(buf);
+    sps->vui_parameters.log2_max_mv_length_vertical = read_exp_golomb(buf);
+    sps->vui_parameters.num_reorder_frames = read_exp_golomb(buf);
+    sps->vui_parameters.max_dec_frame_buffering = read_exp_golomb(buf);
+    printf("Max_dec_frame_buffering: %d\n", sps->vui_parameters.max_dec_frame_buffering);
+  }
+}
+
+void parse_hrd_parameters(struct buf_reader *buf, struct hrd_parameters *hrd)
+{
+  hrd->cpb_cnt_minus1 = read_exp_golomb(buf);
+  hrd->bit_rate_scale = read_bits(buf, 4);
+  hrd->cpb_size_scale = read_bits(buf, 4);
+
+  int i;
+  for (i = 0; i <= hrd->cpb_cnt_minus1; i++) {
+    hrd->bit_rate_value_minus1[i] = read_exp_golomb(buf);
+    hrd->cpb_size_value_minus1[i] = read_exp_golomb(buf);
+    hrd->cbr_flag[i] = read_bits(buf, 1);
+  }
+
+  hrd->initial_cpb_removal_delay_length_minus1 = read_bits(buf, 5);
+  hrd->cpb_removal_delay_length_minus1 = read_bits(buf, 5);
+  hrd->dpb_output_delay_length_minus1 = read_bits(buf, 5);
+  hrd->time_offset_length = read_bits(buf, 5);
+}
+
+uint8_t parse_pps(struct buf_reader *buf, struct pic_parameter_set_rbsp *pps,
+    struct seq_parameter_set_rbsp *sps)
+{
+  pps->pic_parameter_set_id = read_exp_golomb(buf);
+  pps->seq_parameter_set_id = read_exp_golomb(buf);
+  pps->entropy_coding_mode_flag = read_bits(buf, 1);
+  pps->pic_order_present_flag = read_bits(buf, 1);
+
+  pps->num_slice_groups_minus1 = read_exp_golomb(buf);
+  if (pps->num_slice_groups_minus1 > 0) {
+    pps->slice_group_map_type = read_exp_golomb(buf);
+    if (pps->slice_group_map_type == 0) {
+      int i_group;
+      for (i_group = 0; i_group <= pps->num_slice_groups_minus1; i_group++) {
+        if (i_group < 64)
+          pps->run_length_minus1[i_group] = read_exp_golomb(buf);
+        else { // FIXME: skips if more than 64 groups exist
+          fprintf(stderr, "Error: Only 64 slice_groups are supported\n");
+          read_exp_golomb(buf);
+        }
+      }
+    }
+    else if (pps->slice_group_map_type == 3 || pps->slice_group_map_type == 4
+        || pps->slice_group_map_type == 5) {
+      pps->slice_group_change_direction_flag = read_bits(buf, 1);
+      pps->slice_group_change_rate_minus1 = read_exp_golomb(buf);
+    }
+    else if (pps->slice_group_map_type == 6) {
+      pps->pic_size_in_map_units_minus1 = read_exp_golomb(buf);
+      int i_group;
+      for (i_group = 0; i_group <= pps->num_slice_groups_minus1; i_group++) {
+        pps->slice_group_id[i_group] = read_bits(buf, ceil(log(
+            pps->num_slice_groups_minus1 + 1)));
+      }
+    }
+  }
+
+  pps->num_ref_idx_l0_active_minus1 = read_exp_golomb(buf);
+  pps->num_ref_idx_l1_active_minus1 = read_exp_golomb(buf);
+  pps->weighted_pred_flag = read_bits(buf, 1);
+  pps->weighted_bipred_idc = read_bits(buf, 2);
+  pps->pic_init_qp_minus26 = read_exp_golomb_s(buf);
+  pps->pic_init_qs_minus26 = read_exp_golomb_s(buf);
+  pps->chroma_qp_index_offset = read_exp_golomb_s(buf);
+  pps->deblocking_filter_control_present_flag = read_bits(buf, 1);
+  pps->constrained_intra_pred_flag = read_bits(buf, 1);
+  pps->redundant_pic_cnt_present_flag = read_bits(buf, 1);
+
+  if (!rbsp_trailing_bits(buf)) {
+    pps->transform_8x8_mode_flag = read_bits(buf, 1);
+    pps->pic_scaling_matrix_present_flag = read_bits(buf, 1);
+    if (pps->pic_scaling_matrix_present_flag) {
+      int i;
+      for (i = 0; i < 6 + 2 * pps->transform_8x8_mode_flag; i++) {
+        pps->pic_scaling_list_present_flag[i] = read_bits(buf, 1);
+
+        if (pps->pic_scaling_list_present_flag[i]) {
+          if (i < 6)
+            parse_scaling_list(buf, pps->scaling_lists_4x4[i], 16, i);
+          else
+            parse_scaling_list(buf, pps->scaling_lists_8x8[i - 6], 64, i);
+        }
+      }
+    }
+
+    pps->second_chroma_qp_index_offset = read_exp_golomb_s(buf);
+  }
+
+  if (!pps->pic_scaling_matrix_present_flag && sps != NULL) {
+    //printf("MEMCPY SCALING LIST\n");
+    memcpy(pps->scaling_lists_4x4, sps->scaling_lists_4x4,
+        sizeof(pps->scaling_lists_4x4));
+    memcpy(pps->scaling_lists_8x8, sps->scaling_lists_8x8,
+        sizeof(pps->scaling_lists_8x8));
+  }
+  /*else if (sps == NULL) {
+    printf("sPS MISSING\n");
+  }*/
+
+  return 0;
+}
+
+uint8_t parse_slice_header(struct buf_reader *buf, struct nal_parser *parser)
+{
+  struct nal_unit *nal = parser->current_nal;
+
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  if (!sps || !pps)
+    return -1;
+
+  slc->first_mb_in_slice = read_exp_golomb(buf);
+  /* we do some parsing on the slice type, because the list is doubled */
+  slc->slice_type = slice_type(read_exp_golomb(buf));
+  //print_slice_type(slc->slice_type);
+  slc->pic_parameter_set_id = read_exp_golomb(buf);
+  slc->frame_num = read_bits(buf, sps->log2_max_frame_num_minus4 + 4);
+  if (!sps->frame_mbs_only_flag) {
+    slc->field_pic_flag = read_bits(buf, 1);
+    if (slc->field_pic_flag)
+      slc->bottom_field_flag = read_bits(buf, 1);
+    else
+      slc->bottom_field_flag = 0;
+  }
+  else {
+    slc->field_pic_flag = 0;
+    slc->bottom_field_flag = 0;
+  }
+
+  if (slc->field_pic_flag == 0)
+    nal->curr_pic_num = slc->frame_num;
+  else
+    nal->curr_pic_num = 2 * slc->frame_num + 1;
+
+  if (nal->nal_unit_type == NAL_SLICE_IDR)
+    slc->idr_pic_id = read_exp_golomb(buf);
+
+  if (!sps->pic_order_cnt_type) {
+    slc->pic_order_cnt_lsb = read_bits(buf,
+        sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+    if (pps->pic_order_present_flag && !slc->field_pic_flag)
+      slc->delta_pic_order_cnt_bottom = read_exp_golomb_s(buf);
+  }
+  else if (sps->pic_order_cnt_type == 1) {
+    slc->delta_pic_order_cnt[0] = read_exp_golomb_s(buf);
+    if (pps->pic_order_present_flag && !slc->field_pic_flag)
+      slc->delta_pic_order_cnt[1] = read_exp_golomb_s(buf);
+  }
+
+  if (pps->redundant_pic_cnt_present_flag == 1) {
+    slc->redundant_pic_cnt = read_exp_golomb(buf);
+  }
+
+  if (slc->slice_type == SLICE_B)
+    slc->direct_spatial_mv_pred_flag = read_bits(buf, 1);
+
+  if (slc->slice_type == SLICE_P || slc->slice_type == SLICE_SP
+      || slc->slice_type == SLICE_B) {
+    slc->num_ref_idx_active_override_flag = read_bits(buf, 1);
+
+    if (slc->num_ref_idx_active_override_flag == 1) {
+      slc->num_ref_idx_l0_active_minus1 = read_exp_golomb(buf);
+
+      if (slc->slice_type == SLICE_B) {
+        slc->num_ref_idx_l1_active_minus1 = read_exp_golomb(buf);
+      }
+    }
+  }
+
+  /* --- ref_pic_list_reordering --- */
+  parse_ref_pic_list_reordering(buf, nal);
+
+  /* --- pred_weight_table --- */
+  if ((pps->weighted_pred_flag && (slc->slice_type == SLICE_P
+      || slc->slice_type == SLICE_SP)) || (pps->weighted_bipred_idc == 1
+      && slc->slice_type == SLICE_B)) {
+    parse_pred_weight_table(buf, nal);
+  }
+
+  /* --- dec_ref_pic_marking --- */
+  if (nal->nal_ref_idc != 0)
+    parse_dec_ref_pic_marking(buf, parser);
+
+  return 0;
+}
+
+void parse_ref_pic_list_reordering(struct buf_reader *buf, struct nal_unit *nal)
+{
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  if (!sps || !pps)
+    return;
+
+  if (slc->slice_type != SLICE_I && slc->slice_type != SLICE_SI) {
+    slc->ref_pic_list_reordering.ref_pic_list_reordering_flag_l0 = read_bits(
+        buf, 1);
+
+    if (slc->ref_pic_list_reordering.ref_pic_list_reordering_flag_l0 == 1) {
+      do {
+        slc->ref_pic_list_reordering.reordering_of_pic_nums_idc
+            = read_exp_golomb(buf);
+
+        if (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 0
+            || slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 1) {
+          slc->ref_pic_list_reordering.abs_diff_pic_num_minus1
+              = read_exp_golomb(buf);
+        }
+        else if (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 2) {
+          slc->ref_pic_list_reordering.long_term_pic_num = read_exp_golomb(buf);
+        }
+      } while (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc != 3);
+    }
+  }
+
+  if (slc->slice_type == SLICE_B) {
+    slc->ref_pic_list_reordering.ref_pic_list_reordering_flag_l1 = read_bits(
+        buf, 1);
+
+    if (slc->ref_pic_list_reordering.ref_pic_list_reordering_flag_l1 == 1) {
+      do {
+        slc->ref_pic_list_reordering.reordering_of_pic_nums_idc
+            = read_exp_golomb(buf);
+
+        if (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 0
+            || slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 1) {
+          slc->ref_pic_list_reordering.abs_diff_pic_num_minus1
+              = read_exp_golomb(buf);
+        }
+        else if (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc == 2) {
+          slc->ref_pic_list_reordering.long_term_pic_num = read_exp_golomb(buf);
+        }
+      } while (slc->ref_pic_list_reordering.reordering_of_pic_nums_idc != 3);
+    }
+  }
+}
+
+void parse_pred_weight_table(struct buf_reader *buf, struct nal_unit *nal)
+{
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  if (!sps || !pps)
+    return;
+
+  nal->slc->pred_weight_table.luma_log2_weight_denom = read_exp_golomb(buf);
+
+  if (sps->chroma_format_idc != 0)
+    nal->slc->pred_weight_table.chroma_log2_weight_denom = read_exp_golomb(buf);
+
+  int i;
+  for (i = 0; i <= pps->num_ref_idx_l0_active_minus1; i++) {
+    uint8_t luma_weight_l0_flag = read_bits(buf, 1);
+
+    if (luma_weight_l0_flag == 1) {
+      nal->slc->pred_weight_table.luma_weight_l0[i] = read_exp_golomb_s(buf);
+      nal->slc->pred_weight_table.luma_offset_l0[i] = read_exp_golomb_s(buf);
+    }
+
+    if (sps->chroma_format_idc != 0) {
+      uint8_t chroma_weight_l0_flag = read_bits(buf, 1);
+
+      if (chroma_weight_l0_flag == 1) {
+        int j;
+        for (j = 0; j < 2; j++) {
+          nal->slc->pred_weight_table.chroma_weight_l0[i][j]
+              = read_exp_golomb_s(buf);
+          nal->slc->pred_weight_table.chroma_offset_l0[i][j]
+              = read_exp_golomb_s(buf);
+        }
+      }
+    }
+  }
+
+  if (slc->slice_type == SLICE_B) {
+    for (i = 0; i <= pps->num_ref_idx_l1_active_minus1; i++) {
+      uint8_t luma_weight_l1_flag = read_bits(buf, 1);
+
+      if (luma_weight_l1_flag == 1) {
+        nal->slc->pred_weight_table.luma_weight_l1[i] = read_exp_golomb_s(buf);
+        nal->slc->pred_weight_table.luma_offset_l1[i] = read_exp_golomb_s(buf);
+      }
+
+      if (sps->chroma_format_idc != 0) {
+        uint8_t chroma_weight_l1_flag = read_bits(buf, 1);
+
+        if (chroma_weight_l1_flag == 1) {
+          int j;
+          for (j = 0; j < 2; j++) {
+            nal->slc->pred_weight_table.chroma_weight_l1[i][j]
+                = read_exp_golomb_s(buf);
+            nal->slc->pred_weight_table.chroma_offset_l1[i][j]
+                = read_exp_golomb_s(buf);
+          }
+        }
+      }
+    }
+  }
+}
+
+void decode_ref_pic_marking(uint32_t memory_management_control_operation,
+    struct nal_parser *parser)
+{
+  struct nal_unit *nal = parser->current_nal;
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  struct dpb *dpb = &parser->dpb;
+  if (!sps || !pps || !slc)
+    return;
+
+  if (memory_management_control_operation == 1) {
+    // short-term -> unused for reference
+    uint32_t pic_num_x = nal->curr_pic_num
+        - (slc->dec_ref_pic_marking.difference_of_pic_nums_minus1 + 1);
+    struct decoded_picture* pic = dpb_get_picture(dpb, pic_num_x);
+    if (pic != NULL) {
+      if (pic->nal->slc->field_pic_flag == 0)
+        dpb_set_unused_ref_picture(dpb, pic_num_x);
+      else {
+        dpb_set_unused_ref_picture(dpb, pic_num_x);
+        printf("FIXME: We might need do delete more from the DPB...\n");
+        // FIXME: some more handling needed here?! See 8.2.5.4.1, p. 120
+      }
+    }
+  }
+  else if (memory_management_control_operation == 2) {
+    // long-term -> unused for reference
+    struct decoded_picture* pic = dpb_get_picture_by_ltpn(dpb,
+        slc->dec_ref_pic_marking.long_term_pic_num);
+    if (pic != NULL) {
+      if (pic->nal->slc->field_pic_flag == 0)
+        dpb_set_unused_ref_picture(dpb,
+            slc->dec_ref_pic_marking.long_term_pic_num);
+      else {
+        dpb_set_unused_ref_picture(dpb,
+            slc->dec_ref_pic_marking.long_term_pic_num);
+        printf("FIXME: We might need do delete more from the DPB...\n");
+      }
+    }
+  }
+  else if (memory_management_control_operation == 3) {
+    // short-term -> long-term, set long-term frame index
+    uint32_t pic_num_x = nal->curr_pic_num
+        - (slc->dec_ref_pic_marking.difference_of_pic_nums_minus1 + 1);
+    struct decoded_picture* pic = dpb_get_picture_by_ltidx(dpb,
+        slc->dec_ref_pic_marking.long_term_pic_num);
+    if (pic != NULL)
+      dpb_set_unused_ref_picture_bylidx(dpb,
+          slc->dec_ref_pic_marking.long_term_frame_idx);
+
+    pic = dpb_get_picture(dpb, pic_num_x);
+    if (pic) {
+      if (pic->nal->slc->field_pic_flag == 0) {
+        pic = dpb_get_picture(dpb, pic_num_x);
+        pic->nal->long_term_frame_idx
+            = slc->dec_ref_pic_marking.long_term_frame_idx;
+      }
+      else
+        printf("FIXME: B Set frame %d to long-term ref\n", pic_num_x);
+    }
+    else {
+      printf("memory_management_control_operation: 3 failed. No such picture.");
+    }
+
+  }
+  else if (memory_management_control_operation == 4) {
+    // set max-long-term frame index,
+    // mark all long-term pictures with long-term frame idx
+    // greater max-long-term farme idx as unused for ref
+    if (slc->dec_ref_pic_marking.max_long_term_frame_idx_plus1 == 0)
+      dpb_set_unused_ref_picture_lidx_gt(dpb, 0);
+    else
+      dpb_set_unused_ref_picture_lidx_gt(dpb,
+          slc->dec_ref_pic_marking.max_long_term_frame_idx_plus1 - 1);
+  }
+  else if (memory_management_control_operation == 5) {
+    // mark all ref pics as unused for reference,
+    // set max-long-term frame index = no long-term frame idxs
+    dpb_flush(dpb);
+    parser->prev_pic_order_cnt_lsb = 0;
+    parser->prev_pic_order_cnt_msb = 0;
+  }
+  else if (memory_management_control_operation == 6) {
+    // mark current picture as used for long-term ref,
+    // assing long-term frame idx to it
+    struct decoded_picture* pic = dpb_get_picture_by_ltidx(dpb,
+        slc->dec_ref_pic_marking.long_term_frame_idx);
+    if (pic != NULL)
+      dpb_set_unused_ref_picture_bylidx(dpb,
+          slc->dec_ref_pic_marking.long_term_frame_idx);
+
+    nal->long_term_frame_idx = slc->dec_ref_pic_marking.long_term_frame_idx;
+
+    if (slc->field_pic_flag == 0) {
+      nal->used_for_long_term_ref = 1;
+    }
+    else
+      printf("FIXME: BY Set frame to long-term ref\n");
+  }
+}
+
+void parse_dec_ref_pic_marking(struct buf_reader *buf,
+    struct nal_parser *parser)
+{
+  struct nal_unit *nal = parser->current_nal;
+  struct seq_parameter_set_rbsp *sps = nal->sps;
+  struct pic_parameter_set_rbsp *pps = nal->pps;
+  struct slice_header *slc = nal->slc;
+  if (!sps || !pps)
+    return;
+
+  if (nal->nal_unit_type == NAL_SLICE_IDR) {
+    slc->dec_ref_pic_marking.no_output_of_prior_pics_flag = read_bits(buf, 1);
+    slc->dec_ref_pic_marking.long_term_reference_flag = read_bits(buf, 1);
+  }
+  else {
+    slc->dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag = read_bits(
+        buf, 1);
+
+    if (slc->dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag) {
+      do {
+        slc->dec_ref_pic_marking.memory_management_control_operation
+            = read_exp_golomb(buf);
+
+        if (slc->dec_ref_pic_marking.memory_management_control_operation == 1
+            || slc->dec_ref_pic_marking.memory_management_control_operation
+                == 3)
+          slc->dec_ref_pic_marking.difference_of_pic_nums_minus1
+              = read_exp_golomb(buf);
+
+        if (slc->dec_ref_pic_marking.memory_management_control_operation == 2)
+          slc->dec_ref_pic_marking.long_term_pic_num = read_exp_golomb(buf);
+
+        if (slc->dec_ref_pic_marking.memory_management_control_operation == 3
+            || slc->dec_ref_pic_marking.memory_management_control_operation
+                == 6)
+          slc->dec_ref_pic_marking.long_term_frame_idx = read_exp_golomb(buf);
+
+        if (slc->dec_ref_pic_marking.memory_management_control_operation == 4)
+          slc->dec_ref_pic_marking.max_long_term_frame_idx_plus1
+              = read_exp_golomb(buf);
+
+        decode_ref_pic_marking(
+            slc->dec_ref_pic_marking.memory_management_control_operation,
+            parser);
+      } while (slc->dec_ref_pic_marking.memory_management_control_operation
+          != 0);
+    }
+  }
+}
+
+/* ----------------- NAL parser ----------------- */
+
+struct nal_parser* init_parser()
+{
+  struct nal_parser *parser = malloc(sizeof(struct nal_parser));
+  memset(parser->buf, 0x00, MAX_FRAME_SIZE);
+  memset(parser->prebuf, 0x00, MAX_FRAME_SIZE);
+  parser->buf_len = 0;
+  parser->prebuf_len = 0;
+  parser->incomplete_nal = 0;
+  parser->next_nal_position = 0;
+
+  parser->found_sps = 0;
+  parser->found_pps = 0;
+  parser->nal0 = init_nal_unit();
+  parser->nal1 = init_nal_unit();
+  parser->current_nal = parser->nal0;
+  parser->last_nal = parser->nal1;
+
+  parser->last_nal_res = 0;
+  parser->is_idr = 0;
+  parser->slice = 0;
+  parser->slice_cnt = 0;
+  parser->field = -1;
+  parser->have_top = 0;
+
+  /* no idea why we do that. inspired by libavcodec,
+   * as we couldn't figure in the specs....
+   */
+  parser->prev_pic_order_cnt_msb = parser->pic_order_cnt_lsb = 1 << 16;
+
+  parser->cpb_dpb_delays_present_flag = 0;
+
+  return parser;
+}
+
+void free_parser(struct nal_parser *parser)
+{
+  free(parser->nal0);
+  free(parser->nal1);
+  free(parser);
+}
+
+void parse_prebuf()
+{
+
+}
+
+int parse_frame(struct nal_parser *parser, uint8_t *inbuf, int inbuf_len,
+    uint8_t **ret_buf, uint32_t *ret_len, uint32_t *ret_slice_cnt)
+{
+  int32_t next_nal = 0;
+  int parsed_len = 0;
+  int search_offset = 0;
+  uint8_t completed_nal = 0;
+
+  uint8_t *prebuf = parser->prebuf;
+  while ((next_nal = seek_for_nal(inbuf+search_offset, inbuf_len-parsed_len-search_offset)) >= 0) {
+    next_nal += search_offset;
+
+    if(parser->incomplete_nal || completed_nal || next_nal == 0) {
+
+      if (parser->prebuf_len + next_nal > MAX_FRAME_SIZE) {
+        printf("buf underrun!!\n");
+        *ret_len = 0;
+        *ret_buf = NULL;
+        return parsed_len;
+      }
+
+      xine_fast_memcpy(parser->prebuf + parser->prebuf_len, inbuf, next_nal);
+      parser->prebuf_len += next_nal;
+      parser->incomplete_nal = 0;
+
+      parsed_len += next_nal;
+      inbuf += next_nal;
+
+      parser->last_nal_res = parse_nal(prebuf+3, parser->prebuf_len-3, parser);
+      if (parser->last_nal_res == 1 && parser->buf_len > 0) {
+        //printf("Frame complete: %d bytes\n", parser->buf_len);
+        *ret_buf = malloc(parser->buf_len);
+        xine_fast_memcpy(*ret_buf, parser->buf, parser->buf_len);
+        *ret_len = parser->buf_len;
+        *ret_slice_cnt = parser->slice_cnt;
+
+        //memset(parser->buf, 0x00, parser->buf_len);
+        parser->buf_len = 0;
+        parser->last_nal_res = 1;
+        parser->slice_cnt = 1;
+
+        /* this is a SLICE, keep it in the buffer */
+        //printf("slice %d size: %d\n", parser->slice_cnt-1, parser->prebuf_len);
+        xine_fast_memcpy(parser->buf + parser->buf_len, prebuf, parser->prebuf_len);
+        parser->buf_len += parser->prebuf_len;
+        parser->prebuf_len = 0;
+        parser->incomplete_nal = 0;
+
+        if (parser->last_nal->nal_ref_idc) {
+          if (parser->last_nal->slc != NULL)
+            parser->prev_pic_order_cnt_lsb
+                = parser->last_nal->slc->pic_order_cnt_lsb;
+          parser->prev_pic_order_cnt_msb = parser->pic_order_cnt_msb;
+        }
+        return parsed_len;
+      }
+
+      if (parser->last_nal_res != 2) {
+        if (parser->buf_len + parser->prebuf_len > MAX_FRAME_SIZE) {
+          printf("buf underrun!!\n");
+          parser->buf_len = 0;
+          *ret_len = 0;
+          *ret_buf = NULL;
+          return parsed_len;
+        }
+
+        //printf("slice %d size: %d\n", parser->slice_cnt-1, parser->prebuf_len);
+        /* this is a SLICE, keep it in the buffer */
+        xine_fast_memcpy(parser->buf + parser->buf_len, prebuf, parser->prebuf_len);
+        parser->buf_len += parser->prebuf_len;
+      }
+
+      parser->prebuf_len = 0;
+      completed_nal = 1;
+
+    } else {
+      /* most likely we are at the beginning of the stream here
+       * which starts not with a nal-boundardy but with some garbage
+       * -> throw it away
+       */
+      parsed_len += next_nal;
+      inbuf += next_nal;
+    }
+
+
+    search_offset = 3;
+  }
+
+  /* if inbuf does not end with the start of a new nal
+   * copy the left data into prebuf
+   */
+  if(parsed_len < inbuf_len) {
+    parser->incomplete_nal = 1;
+    xine_fast_memcpy(parser->prebuf + parser->prebuf_len, inbuf, inbuf_len-parsed_len);
+    parser->prebuf_len += inbuf_len-parsed_len;
+    parsed_len += inbuf_len-parsed_len;
+    inbuf += inbuf_len-parsed_len;
+
+    /* now check if prebuf contains a second slice header
+     * this might happen if the nal start sequence is split
+     * over the buf-boundary - if this is the case we
+     */
+    if(parsed_len > 2 &&
+        (next_nal = seek_for_nal(prebuf+3, parser->prebuf_len)) >= 0) {
+      inbuf -= parser->prebuf_len-next_nal-3;
+      parsed_len -= parser->prebuf_len-next_nal-3;
+      parser->prebuf_len = next_nal+3;
+    }
+  }
+
+  *ret_len = 0;
+  *ret_buf = NULL;
+  return parsed_len;
+}
+
+int parse_nal(uint8_t *buf, int buf_len, struct nal_parser *parser)
+{
+  struct buf_reader bufr;
+
+  bufr.buf = buf;
+  bufr.cur_pos = buf;
+  bufr.cur_offset = 8;
+  bufr.len = buf_len;
+
+  struct nal_unit *nal = parser->current_nal;
+  struct nal_unit *last_nal = parser->last_nal;
+
+  int res = parse_nal_header(&bufr, parser);
+  if (res == NAL_SLICE_IDR) {
+    parser->is_idr = 1;
+  }
+
+  calculate_pic_order(parser);
+
+  if (res >= NAL_SLICE && res <= NAL_SLICE_IDR) {
+    // now detect if it's a new frame!
+    int ret = 0;
+    uint8_t reason = 0;
+    if (nal->slc->field_pic_flag == 1)
+      parser->field = nal->slc->bottom_field_flag;
+    else {
+      parser->have_top = 1;
+      parser->field = -1;
+    }
+
+    if (nal->slc->field_pic_flag == 1 && nal->slc->bottom_field_flag == 0)
+      parser->have_top = 1;
+
+    parser->slice = 1;
+
+    if (nal->slc == NULL || last_nal->slc == NULL) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->slc && last_nal->slc && (nal->slc->frame_num
+        != last_nal->slc->frame_num)) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->slc && last_nal->slc && (nal->slc->pic_parameter_set_id
+        != last_nal->slc->pic_parameter_set_id)) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->slc && last_nal->slc && (nal->slc->field_pic_flag
+        != last_nal->slc->field_pic_flag)) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->slc && last_nal->slc && nal->slc->bottom_field_flag
+        != last_nal->slc->bottom_field_flag) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->nal_ref_idc != last_nal->nal_ref_idc && (nal->nal_ref_idc == 0
+        || last_nal->nal_ref_idc == 0)) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->sps && nal->slc && last_nal->slc && (nal->sps->pic_order_cnt_type
+        == 0 && last_nal->sps->pic_order_cnt_type == 0
+        && (nal->slc->pic_order_cnt_lsb != last_nal->slc->pic_order_cnt_lsb
+            || nal->slc->delta_pic_order_cnt_bottom
+                != last_nal->slc->delta_pic_order_cnt_bottom))) {
+      ret = 1;
+      reason++;
+      /*printf("C: Reason: %d, %d, %d\n", res, nal->slc->pic_order_cnt_lsb,
+          last_nal->slc->pic_order_cnt_lsb);*/
+    }
+    if (nal->slc && last_nal->slc && (nal->sps->pic_order_cnt_type == 1
+        && last_nal->sps->pic_order_cnt_type == 1
+        && (nal->slc->delta_pic_order_cnt[0]
+            != last_nal->slc->delta_pic_order_cnt[0]
+            || nal->slc->delta_pic_order_cnt[1]
+                != last_nal->slc->delta_pic_order_cnt[1]))) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->nal_unit_type != last_nal->nal_unit_type && (nal->nal_unit_type
+        == 5 || last_nal->nal_unit_type == 5)) {
+      ret = 1;
+      reason++;
+    }
+    if (nal->slc && last_nal->slc && (nal->nal_unit_type == 5
+        && last_nal->nal_unit_type == 5 && nal->slc->idr_pic_id
+        != last_nal->slc->idr_pic_id)) {
+      ret = 1;
+      reason++;
+    }
+
+    if (parser->current_nal == parser->nal0) {
+      parser->current_nal = parser->nal1;
+      parser->last_nal = parser->nal0;
+    }
+    else {
+      parser->current_nal = parser->nal0;
+      parser->last_nal = parser->nal1;
+    }
+
+    if (parser->current_nal->sps == NULL)
+      parser->current_nal->sps = parser->last_nal->sps;
+    if (parser->current_nal->pps == NULL)
+      parser->current_nal->pps = parser->last_nal->pps;
+
+    /* increase the slice_cnt until a new frame is detected */
+    if (!ret)
+      parser->slice_cnt++;
+
+    return ret;
+  }
+  else if (res == NAL_PPS || res == NAL_SPS) {
+    return 2;
+  }
+  else if (res >= NAL_SEI) {
+    return 2;
+  }
+
+  return 0;
+}
+
+int seek_for_nal(uint8_t *buf, int buf_len)
+{
+  int i;
+  for (i = 0; i < buf_len - 2; i++) {
+    if (buf[i] == 0x00 && buf[i + 1] == 0x00 && buf[i + 2] == 0x01) {
+      //printf("found nal at: %d\n", i);
+      return i;
+    }
+  }
+
+  return -1;
+}
diff -Naur xine-lib-1.1.15-old/src/libvdpau/h264_parser.h xine-lib-1.1.15-new/src/libvdpau/h264_parser.h
--- xine-lib-1.1.15-old/src/libvdpau/h264_parser.h	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/h264_parser.h	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,85 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * h264_parser.h: Almost full-features H264 NAL-Parser
+ */
+
+#ifndef NAL_PARSER_H_
+#define NAL_PARSER_H_
+
+#include <stdlib.h>
+
+#include "xine_internal.h"
+#include "nal.h"
+#include "dpb.h"
+
+#define MAX_FRAME_SIZE  1024*1024
+
+struct nal_parser {
+    uint8_t buf[MAX_FRAME_SIZE];
+    uint32_t buf_len;
+
+    /* prebuf is used to store the currently
+     * processed nal unit */
+    uint8_t prebuf[MAX_FRAME_SIZE];
+    uint32_t prebuf_len;
+    uint32_t next_nal_position;
+    uint8_t incomplete_nal;
+
+    uint8_t found_sps;
+    uint8_t found_pps;
+    uint8_t last_nal_res;
+
+    uint8_t is_idr;
+
+    int field; /* 0=top, 1=bottom, -1=both */
+    int slice;
+    int slice_cnt;
+
+    uint8_t have_top;
+    uint8_t have_frame;
+
+    struct nal_unit *nal0;
+    struct nal_unit *nal1;
+    struct nal_unit *current_nal;
+    struct nal_unit *last_nal;
+
+    uint8_t cpb_dpb_delays_present_flag;
+
+    uint32_t pic_order_cnt_lsb;
+    uint32_t pic_order_cnt_msb;
+    uint32_t prev_pic_order_cnt_lsb;
+    uint32_t prev_pic_order_cnt_msb;
+
+    /* this is dpb used for reference frame
+     * heading to vdpau + unordered frames
+     */
+    struct dpb dpb;
+};
+
+int parse_nal(uint8_t *buf, int buf_len, struct nal_parser *parser);
+
+int seek_for_nal(uint8_t *buf, int buf_len);
+
+struct nal_parser* init_parser();
+void free_parser(struct nal_parser *parser);
+int parse_frame(struct nal_parser *parser, uint8_t *inbuf, int inbuf_len,
+                uint8_t **ret_buf, uint32_t *ret_len, uint32_t *ret_slice_cnt);
+
+#endif
diff -Naur xine-lib-1.1.15-old/src/libvdpau/Makefile.am xine-lib-1.1.15-new/src/libvdpau/Makefile.am
--- xine-lib-1.1.15-old/src/libvdpau/Makefile.am	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/Makefile.am	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,22 @@
+include $(top_srcdir)/misc/Makefile.common
+
+AM_CFLAGS = $(VISIBILITY_FLAG)
+AM_LDFLAGS = $(xineplug_ldflags)
+
+if HAVE_VDPAU
+vdpau_h264_module = xineplug_decode_vdpau_h264.la
+VDPAU_CFLAGS = -D_ISOC99_SOURCE
+
+vdpau_mpeg12_module = xineplug_decode_vdpau_mpeg12.la
+endif
+
+xineplug_LTLIBRARIES = $(vdpau_h264_module) $(vdpau_mpeg12_module)
+
+xineplug_decode_vdpau_h264_la_SOURCES = nal.c dpb.c h264_parser.c vdpau_h264.c
+xineplug_decode_vdpau_h264_la_CFLAGS = $(AM_CFLAGS) $(VDPAU_CFLAGS)
+xineplug_decode_vdpau_h264_la_LIBADD = $(XINE_LIB) $(DYNAMIC_LD_LIBS) -lm
+
+xineplug_decode_vdpau_mpeg12_la_SOURCES = vdpau_mpeg12.c
+xineplug_decode_vdpau_mpeg12_la_CFLAGS = $(AM_CFLAGS)
+xineplug_decode_vdpau_mpeg12_la_LIBADD = $(XINE_LIB) $(DYNAMIC_LD_LIBS)
+
diff -Naur xine-lib-1.1.15-old/src/libvdpau/nal.c xine-lib-1.1.15-new/src/libvdpau/nal.c
--- xine-lib-1.1.15-old/src/libvdpau/nal.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/nal.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,73 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * nal.c: nal-structure utility functions
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "nal.h"
+#include "xine_internal.h"
+
+struct nal_unit* init_nal_unit()
+{
+  struct nal_unit *nal = malloc(sizeof(struct nal_unit));
+  memset(nal, 0x00, sizeof(struct nal_unit));
+
+  /*nal->sps = malloc(sizeof(struct seq_parameter_set_rbsp));
+  memset(nal->sps, 0x00, sizeof(struct seq_parameter_set_rbsp));
+  nal->pps = malloc(sizeof(struct pic_parameter_set_rbsp));
+  memset(nal->pps, 0x00, sizeof(struct pic_parameter_set_rbsp));
+  nal->slc = malloc(sizeof(struct slice_header));
+  memset(nal->slc, 0x00, sizeof(struct slice_header));*/
+
+  return nal;
+}
+
+void free_nal_unit(struct nal_unit *nal)
+{
+  free(nal->sps);
+  free(nal->pps);
+  free(nal->slc);
+  free(nal);
+}
+
+void copy_nal_unit(struct nal_unit *dest, struct nal_unit *src)
+{
+  /* size without pps, sps and slc units: */
+  int size = sizeof(struct nal_unit) - sizeof(struct seq_parameter_set_rbsp*)
+      - sizeof(struct pic_parameter_set_rbsp*) - sizeof(struct slice_header*);
+
+  xine_fast_memcpy(dest, src, size);
+
+  if(!dest->sps)
+    dest->sps = malloc(sizeof(struct seq_parameter_set_rbsp));
+
+  if(!dest->pps)
+    dest->pps = malloc(sizeof(struct pic_parameter_set_rbsp));
+
+  if(!dest->slc)
+    dest->slc = malloc(sizeof(struct slice_header));
+
+  xine_fast_memcpy(dest->sps, src->sps, sizeof(struct seq_parameter_set_rbsp));
+  xine_fast_memcpy(dest->pps, src->pps, sizeof(struct pic_parameter_set_rbsp));
+  xine_fast_memcpy(dest->slc, src->slc, sizeof(struct slice_header));
+}
diff -Naur xine-lib-1.1.15-old/src/libvdpau/nal.h xine-lib-1.1.15-new/src/libvdpau/nal.h
--- xine-lib-1.1.15-old/src/libvdpau/nal.h	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/nal.h	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,410 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * nal.h: H264 NAL structures
+ */
+
+#ifndef NAL_H_
+#define NAL_H_
+#include <stdint.h>
+#include <vdpau/vdpau.h>
+
+enum nal_unit_types
+{
+  NAL_UNSPECIFIED = 0,
+  NAL_SLICE,
+  NAL_PART_A,
+  NAL_PART_B,
+  NAL_PART_C,
+  NAL_SLICE_IDR,
+  NAL_SEI,
+  NAL_SPS,
+  NAL_PPS,
+  NAL_AU_DELIMITER,
+  NAL_END_OF_SEQUENCE,
+  NAL_END_OF_STREAM,
+  NAL_FILLER_DATA,
+  NAL_SPS_EXT
+};
+
+/* slice types repeat from 5-9, we
+ * need a helper function for comparison
+ */
+enum slice_types
+{
+  SLICE_P = 0, SLICE_B, SLICE_I, SLICE_SP, SLICE_SI
+};
+
+enum aspect_ratio
+{
+  ASPECT_UNSPECIFIED = 0,
+  ASPECT_1_1,
+  ASPECT_12_11,
+  ASPECT_10_11,
+  ASPECT_16_11,
+  ASPECT_40_33,
+  ASPECT_24_11,
+  ASPECT_20_11,
+  ASPECT_32_11,
+  ASPECT_80_33,
+  ASPECT_18_11,
+  ASPECT_15_11,
+  ASPECT_64_33,
+  ASPECT_160_99,
+  ASPECT_4_3,
+  ASPECT_3_2,
+  ASPECT_2_1,
+  ASPECT_RESERVED,
+  ASPECT_EXTENDED_SAR=255
+};
+
+static inline uint32_t slice_type(uint32_t slice_type)
+{
+  return (slice_type < 10 ? slice_type % 5 : slice_type);
+}
+
+static inline void print_slice_type(uint32_t slice_type)
+{
+  switch(slice_type) {
+    case SLICE_P:
+      printf("SLICE_P\n");
+      break;
+    case SLICE_B:
+      printf("SLICE_B\n");
+      break;
+    case SLICE_I:
+      printf("SLICE_I\n");
+      break;
+    case SLICE_SP:
+      printf("SLICE_SP\n");
+      break;
+    case SLICE_SI:
+      printf("SLICE_SI\n");
+      break;
+    default:
+      printf("Unknown SLICE\n");
+  }
+}
+
+struct hrd_parameters
+{
+  uint32_t cpb_cnt_minus1;
+  uint8_t bit_rate_scale;
+  uint8_t cpb_size_scale;
+
+  uint32_t bit_rate_value_minus1[32];
+  uint32_t cpb_size_value_minus1[32];
+  uint8_t cbr_flag[32];
+
+  uint8_t initial_cpb_removal_delay_length_minus1;
+  uint8_t cpb_removal_delay_length_minus1;
+  uint8_t dpb_output_delay_length_minus1;
+  uint8_t time_offset_length;
+};
+
+struct seq_parameter_set_rbsp
+{
+  uint8_t profile_idc; // 0xff
+  uint8_t constraint_setN_flag; // 0x0f
+  uint8_t level_idc; // 0xff
+  uint32_t seq_parameter_set_id;
+  uint32_t chroma_format_idc;
+  uint8_t residual_colour_transform_flag; // 0x01
+  uint32_t bit_depth_luma_minus8;
+  uint32_t bit_depth_chroma_minus8;
+  uint8_t qpprime_y_zero_transform_bypass_flag;
+  uint8_t seq_scaling_matrix_present_flag;
+
+  /* if(seq_scaling_matrix_present_flag) */
+  uint8_t seq_scaling_list_present_flag[8];
+
+  uint8_t scaling_lists_4x4[6][16];
+  uint8_t scaling_lists_8x8[2][64];
+  /* endif */
+
+  uint32_t log2_max_frame_num_minus4;
+  uint32_t pic_order_cnt_type;
+  // if pic_order_cnt_type==0
+  uint32_t log2_max_pic_order_cnt_lsb_minus4;
+  // else
+  uint8_t delta_pic_order_always_zero_flag;
+  int32_t offset_for_non_ref_pic;
+  int32_t offset_for_top_to_bottom_field;
+  uint8_t num_ref_frames_in_pic_order_cnt_cycle;
+  int32_t offset_for_ref_frame[256];
+  // TODO: some more ignored here
+  uint32_t num_ref_frames;
+  uint8_t gaps_in_frame_num_value_allowed_flag;
+  /*uint32_t    pic_width_in_mbs_minus1;
+   uint32_t    pic_height_in_map_units_minus1;*/
+  uint32_t pic_width;
+  uint32_t pic_height;
+  uint8_t frame_mbs_only_flag;
+  uint8_t mb_adaptive_frame_field_flag;
+  uint8_t direct_8x8_inference_flag;
+  uint8_t frame_cropping_flag;
+  uint32_t frame_crop_left_offset;
+  uint32_t frame_crop_right_offset;
+  uint32_t frame_crop_top_offset;
+  uint32_t frame_crop_bottom_offset;
+  uint8_t vui_parameters_present_flag;
+
+  /* vui_parameters */
+  struct
+  {
+    uint8_t aspect_ration_info_present_flag;
+
+    /* aspect_ration_info_present_flag == 1 */
+    uint8_t aspect_ratio_idc;
+    uint16_t sar_width;
+    uint16_t sar_height;
+
+    uint8_t overscan_info_present_flag;
+    /* overscan_info_present_flag == 1 */
+    uint8_t overscan_appropriate_flag;
+
+    uint8_t video_signal_type_present_flag;
+    /* video_signal_type_present_flag == 1 */
+    uint8_t video_format;
+    uint8_t video_full_range_flag;
+    uint8_t colour_description_present;
+    /* colour_description_present == 1 */
+    uint8_t colour_primaries;
+    uint8_t transfer_characteristics;
+    uint8_t matrix_coefficients;
+
+    uint8_t chroma_loc_info_present_flag;
+    /* chroma_loc_info_present_flag == 1 */
+    uint8_t chroma_sample_loc_type_top_field;
+    uint8_t chroma_sample_loc_type_bottom_field;
+
+    uint8_t timing_info_present_flag;
+    /* timing_info_present_flag == 1 */
+    uint32_t num_units_in_tick;
+    uint32_t time_scale;
+    uint8_t fixed_frame_rate_flag;
+
+    uint8_t nal_hrd_parameters_present_flag;
+    struct hrd_parameters nal_hrd_parameters;
+
+    uint8_t vc1_hrd_parameters_present_flag;
+    struct hrd_parameters vc1_hrd_parameters;
+
+    uint8_t low_delay_hrd_flag;
+
+    uint8_t pic_struct_present_flag;
+    uint8_t bitstream_restriction_flag;
+
+    /* bitstream_restriction_flag == 1 */
+    uint8_t motion_vectors_over_pic_boundaries;
+    uint32_t max_bytes_per_pic_denom;
+    uint32_t max_bits_per_mb_denom;
+    uint32_t log2_max_mv_length_horizontal;
+    uint32_t log2_max_mv_length_vertical;
+    uint32_t num_reorder_frames;
+    uint32_t max_dec_frame_buffering;
+  } vui_parameters;
+
+};
+
+struct pic_parameter_set_rbsp
+{
+  uint32_t pic_parameter_set_id;
+  uint32_t seq_parameter_set_id;
+  uint8_t entropy_coding_mode_flag;
+  uint8_t pic_order_present_flag;
+
+  uint32_t num_slice_groups_minus1;
+
+  /* num_slice_groups_minus1 > 0 */
+  uint32_t slice_group_map_type;
+
+  /* slice_group_map_type == 1 */
+  uint32_t run_length_minus1[64];
+
+  /* slice_group_map_type == 2 */
+  uint32_t top_left[64];
+  uint32_t bottom_right[64];
+
+  /* slice_group_map_type == 3,4,5 */
+  uint8_t slice_group_change_direction_flag;
+  uint32_t slice_group_change_rate_minus1;
+
+  /* slice_group_map_type == 6 */
+  uint32_t pic_size_in_map_units_minus1;
+  uint8_t slice_group_id[64];
+
+  uint32_t num_ref_idx_l0_active_minus1;
+  uint32_t num_ref_idx_l1_active_minus1;
+  uint8_t weighted_pred_flag;
+  uint8_t weighted_bipred_idc;
+  int32_t pic_init_qp_minus26;
+  int32_t pic_init_qs_minus26;
+  int32_t chroma_qp_index_offset;
+  uint8_t deblocking_filter_control_present_flag;
+  uint8_t constrained_intra_pred_flag;
+  uint8_t redundant_pic_cnt_present_flag;
+
+  /* if(more_rbsp_data) */
+  uint8_t transform_8x8_mode_flag;
+  uint8_t pic_scaling_matrix_present_flag;
+
+  /* if(pic_scaling_matrix_present_flag) */
+  uint8_t pic_scaling_list_present_flag[8];
+
+  uint8_t scaling_lists_4x4[6][16];
+  uint8_t scaling_lists_8x8[2][64];
+
+  int32_t second_chroma_qp_index_offset;
+};
+
+/* sei contains several additional info, we do
+ * only care for pic_timing, to handle display
+ * reordering
+ */
+struct sei_message
+{
+  uint32_t payload_type;
+  uint8_t last_payload_type_byte;
+  uint32_t payload_size;
+  uint8_t last_payload_size_byte;
+
+  struct
+  {
+    /* cpb_dpb_delays_present_flag == 1 */
+    uint8_t cpb_removal_delay;
+    uint8_t dpb_output_delay;
+
+    /* ignore the rest */
+  } pic_timing;
+};
+
+struct slice_header
+{
+  uint32_t first_mb_in_slice;
+  uint32_t slice_type;
+  uint32_t pic_parameter_set_id;
+  uint32_t frame_num;
+  uint8_t field_pic_flag;
+  uint8_t bottom_field_flag;
+  uint32_t idr_pic_id;
+
+  /* sps->pic_order_cnt_type == 0 */
+  uint32_t pic_order_cnt_lsb;
+  int32_t delta_pic_order_cnt_bottom;
+  /* sps->pic_order_cnt_type == 1 && !sps->delta_pic_order_always_zero_flag */
+  int32_t delta_pic_order_cnt[2];
+
+  /* pps->redundant_pic_cnt_present_flag == 1 */
+  int32_t redundant_pic_cnt;
+
+  /* slice_type == B */
+  uint8_t direct_spatial_mv_pred_flag;
+
+  /* slice_type == P, SP, B */
+  uint8_t num_ref_idx_active_override_flag;
+  /* num_ref_idx_active_override_flag == 1 */
+  uint32_t num_ref_idx_l0_active_minus1;
+  /* slice type == B */
+  uint32_t num_ref_idx_l1_active_minus1;
+
+  /* ref_pic_list_reordering */
+  struct
+  {
+    /* slice_type != I && slice_type != SI */
+    uint8_t ref_pic_list_reordering_flag_l0;
+
+    /* slice_type == B */
+    uint8_t ref_pic_list_reordering_flag_l1;
+
+    /* ref_pic_list_reordering_flag_l0 == 1 */
+    uint32_t reordering_of_pic_nums_idc;
+
+    /* reordering_of_pic_nums_idc == 0, 1 */
+    uint32_t abs_diff_pic_num_minus1;
+
+    /* reordering_of_pic_nums_idc == 2) */
+    uint32_t long_term_pic_num;
+  } ref_pic_list_reordering;
+
+  /* pred_weight_table */
+  struct
+  {
+    uint32_t luma_log2_weight_denom;
+
+    /* chroma_format_idc != 0 */
+    uint32_t chroma_log2_weight_denom;
+
+    int32_t luma_weight_l0[32];
+    int32_t luma_offset_l0[32];
+
+    int32_t chroma_weight_l0[32][2];
+    int32_t chroma_offset_l0[32][2];
+
+    int32_t luma_weight_l1[32];
+    int32_t luma_offset_l1[32];
+
+    int32_t chroma_weight_l1[32][2];
+    int32_t chroma_offset_l1[32][2];
+  } pred_weight_table;
+
+  /* def_rec_pic_marking */
+  struct
+  {
+
+    /* nal_unit_type == NAL_SLICE_IDR */
+    uint8_t no_output_of_prior_pics_flag;
+    uint8_t long_term_reference_flag;
+
+    /* else */
+    uint8_t adaptive_ref_pic_marking_mode_flag;
+    uint32_t memory_management_control_operation;
+
+    uint32_t difference_of_pic_nums_minus1;
+    uint32_t long_term_pic_num;
+    uint32_t long_term_frame_idx;
+    uint32_t max_long_term_frame_idx_plus1;
+  } dec_ref_pic_marking;
+};
+
+struct nal_unit
+{
+  uint8_t nal_ref_idc; // 0x03
+  uint8_t nal_unit_type; // 0x1f
+
+  uint32_t curr_pic_num;
+  uint8_t used_for_long_term_ref;
+  uint32_t long_term_pic_num;
+  uint32_t long_term_frame_idx;
+
+  uint32_t top_field_order_cnt;
+  uint32_t bottom_field_order_cnt;
+
+  struct sei_message sei;
+
+  struct seq_parameter_set_rbsp *sps;
+  struct pic_parameter_set_rbsp *pps;
+  struct slice_header *slc;
+};
+
+struct nal_unit* init_nal_unit();
+void free_nal_unit(struct nal_unit *nal);
+void copy_nal_unit(struct nal_unit *dest, struct nal_unit *src);
+
+#endif /* NAL_H_ */
diff -Naur xine-lib-1.1.15-old/src/libvdpau/vdpau_h264.c xine-lib-1.1.15-new/src/libvdpau/vdpau_h264.c
--- xine-lib-1.1.15-old/src/libvdpau/vdpau_h264.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/vdpau_h264.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,707 @@
+/*
+ * Copyright (C) 2008 Julian Scheel
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * vdpau_h264.c: H264 Video Decoder utilizing nvidia VDPAU engine
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <vdpau/vdpau.h>
+
+#include "xine_internal.h"
+#include "video_out.h"
+#include "buffer.h"
+#include "xineutils.h"
+#include "bswap.h"
+#include "accel_vdpau.h"
+#include "h264_parser.h"
+#include "dpb.h"
+
+#define VIDEOBUFSIZE 128*1024
+
+typedef struct {
+  video_decoder_class_t   decoder_class;
+} vdpau_h264_class_t;
+
+typedef struct vdpau_h264_decoder_s {
+  video_decoder_t   video_decoder;  /* parent video decoder structure */
+
+  vdpau_h264_class_t *class;
+  xine_stream_t    *stream;
+
+  /* these are traditional variables in a video decoder object */
+  uint64_t          video_step;  /* frame duration in pts units */
+  int               decoder_started;  /* current decoder status */
+  int               decoder_initialized; /* vdpau init state */
+  int               skipframes;
+
+  unsigned char    *buf;         /* the accumulated buffer data */
+  int               bufsize;     /* the maximum size of buf */
+  int               size;        /* the current size of buf */
+
+  int               width;       /* the width of a video frame */
+  int               height;      /* the height of a video frame */
+  double            ratio;       /* the width to height ratio */
+
+
+  struct nal_parser *nal_parser;  /* h264 nal parser. extracts stream data for vdpau */
+  uint8_t           wait_for_bottom_field;
+  struct decoded_picture *last_ref_pic;
+  uint32_t          last_top_field_order_cnt;
+
+  VdpDecoder        decoder;
+
+  VdpDecoderProfile profile;
+  VdpPictureInfoH264 vdp_picture_info;
+  vdpau_accel_t     *vdpau_accel;
+
+  xine_t            *xine;
+
+  int64_t           last_pts;
+  int64_t           tmp_pts;
+
+} vdpau_h264_decoder_t;
+
+/**************************************************************************
+ * vdpau_h264 specific decode functions
+ *************************************************************************/
+
+/**************************************************************************
+ * xine video plugin functions
+ *************************************************************************/
+
+
+static inline void dump_pictureinfo_h264(VdpPictureInfoH264 *pic)
+{
+  printf("C: slice_count: %d\n", pic->slice_count);
+  printf("C: field_order_cnt[0]: %d\n", pic->field_order_cnt[0]);
+  printf("C: field_order_cnt[1]: %d\n", pic->field_order_cnt[1]);
+  printf("C: is_reference: %d\n", pic->is_reference);
+  printf("C: frame_num: %d\n", pic->frame_num);
+  printf("C: field_pic_flag: %d\n", pic->field_pic_flag);
+  printf("C: bottom_field_flag: %d\n", pic->bottom_field_flag);
+  printf("C: num_ref_frames: %d\n", pic->num_ref_frames);
+  printf("C: mb_adaptive_frame_field_flag: %d\n", pic->mb_adaptive_frame_field_flag);
+  printf("C: constrained_intra_pred_flag: %d\n", pic->constrained_intra_pred_flag);
+  printf("C: weighted_pred_flag: %d\n", pic->weighted_pred_flag);
+  printf("C: weighted_bipred_idc: %d\n", pic->weighted_bipred_idc);
+  printf("C: frame_mbs_only_flag: %d\n", pic->frame_mbs_only_flag);
+  printf("C: transform_8x8_mode_flag: %d\n", pic->transform_8x8_mode_flag);
+  printf("C: chroma_qp_index_offset: %d\n", pic->chroma_qp_index_offset);
+  printf("C: second_chroma_qp_index_offset: %d\n", pic->second_chroma_qp_index_offset);
+  printf("C: pic_init_qp_minus26: %d\n", pic->pic_init_qp_minus26);
+  printf("C: num_ref_idx_l0_active_minus1: %d\n", pic->num_ref_idx_l0_active_minus1);
+  printf("C: num_ref_idx_l1_active_minus1: %d\n", pic->num_ref_idx_l1_active_minus1);
+  printf("C: log2_max_frame_num_minus4: %d\n", pic->log2_max_frame_num_minus4);
+  printf("C: pic_order_cnt_type: %d\n", pic->pic_order_cnt_type);
+  printf("C: log2_max_pic_order_cnt_lsb_minus4: %d\n", pic->log2_max_pic_order_cnt_lsb_minus4);
+  printf("C: delta_pic_order_always_zero_flag: %d\n", pic->delta_pic_order_always_zero_flag);
+  printf("C: direct_8x8_inference_flag: %d\n", pic->direct_8x8_inference_flag);
+  printf("C: entropy_coding_mode_flag: %d\n", pic->entropy_coding_mode_flag);
+  printf("C: pic_order_present_flag: %d\n", pic->pic_order_present_flag);
+  printf("C: deblocking_filter_control_present_flag: %d\n", pic->deblocking_filter_control_present_flag);
+  printf("C: redundant_pic_cnt_present_flag: %d\n", pic->redundant_pic_cnt_present_flag);
+
+  /*int i, j;
+  for(i = 0; i < 6; i++) {
+    printf("scalint_list4x4[%d]: ", i);
+    for(j = 0; j < 16; j++) {
+      printf("[%d] ", pic->scaling_lists_4x4[i][j]);
+      if(j%8 == 0)
+        printf("\n");
+    }
+    printf("\n");
+  }
+  for(i = 0; i < 2; i++) {
+    printf("scalint_list4x4[%d]: ", i);
+    for(j = 0; j < 64; j++) {
+      printf("[%d] ", pic->scaling_lists_4x4[i][j]);
+      if(j%8 == 0)
+        printf("\n");
+    }
+    printf("\n");
+  }*/
+
+  int i;
+  for(i = 0; i < 16; i++) {
+    if(pic->referenceFrames[i].surface != VDP_INVALID_HANDLE) {
+    printf("C: -------------------\n");
+      printf("C: Reference Frame %d:\n", i);
+    printf("C: frame_idx: %d\n", pic->referenceFrames[i].frame_idx);
+    printf("C: field_order_cnt[0]: %d\n", pic->referenceFrames[i].field_order_cnt[0]);
+    printf("C: field_order_cnt[1]: %d\n", pic->referenceFrames[i].field_order_cnt[0]);
+    printf("C: is_long_term: %d\n", pic->referenceFrames[i].is_long_term);
+    printf("C: top_is_reference: %d\n", pic->referenceFrames[i].top_is_reference);
+    printf("C: bottom_is_reference: %d\n", pic->referenceFrames[i].bottom_is_reference);
+    }
+  }
+  printf("C: ---------------------------------------------------------------\n");
+  /*memcpy(pic.scaling_lists_4x4, pps->scaling_lists_4x4, 6*16);
+  memcpy(pic.scaling_lists_8x8, pps->scaling_lists_8x8, 2*64);
+  memcpy(pic.referenceFrames, this->reference_frames, sizeof(this->reference_frames));*/
+
+}
+
+/*
+ * This function receives a buffer of data from the demuxer layer and
+ * figures out how to handle it based on its header flags.
+ */
+static void vdpau_h264_decode_data (video_decoder_t *this_gen,
+  buf_element_t *buf) {
+
+  vdpau_h264_decoder_t *this = (vdpau_h264_decoder_t *) this_gen;
+
+  VdpBitstreamBuffer vdp_buffer;
+  vdp_buffer.struct_version = VDP_BITSTREAM_BUFFER_VERSION;
+
+  vo_frame_t *img; /* video out frame */
+
+  /* a video decoder does not care about this flag (?) */
+  if (buf->decoder_flags & BUF_FLAG_PREVIEW)
+    return;
+
+  if (buf->decoder_flags & BUF_FLAG_FRAMERATE) {
+    this->video_step = buf->decoder_info[0];
+    printf("Videostep: %d\n", this->video_step);
+    _x_stream_info_set(this->stream, XINE_STREAM_INFO_FRAME_DURATION, this->video_step);
+  }
+
+  if (buf->decoder_flags & BUF_FLAG_STDHEADER) { /* need to initialize */
+    return;
+  } else {
+
+    /* parse the first nal packages to retrieve profile type */
+    int len = 0;
+    uint32_t slice_count;
+
+    while(len < buf->size) {
+      len += parse_frame(this->nal_parser, buf->content + len, buf->size - len,
+          (void*)&vdp_buffer.bitstream, &vdp_buffer.bitstream_bytes, &slice_count);
+
+      if(!this->decoder_initialized &&
+          this->nal_parser->current_nal != NULL &&
+          this->nal_parser->current_nal->sps != NULL &&
+          this->nal_parser->current_nal->sps->pic_width > 0 &&
+          this->nal_parser->current_nal->sps->pic_height > 0) {
+
+        this->width = this->nal_parser->current_nal->sps->pic_width;
+        this->height = this->nal_parser->current_nal->sps->pic_height;
+
+        /* FIXME: ratio should be calculated in some other way to
+         * support anamorph codings...
+         */
+        this->ratio = (double)this->width / (double)this->height;
+        if(this->nal_parser->current_nal->sps->vui_parameters.aspect_ration_info_present_flag) {
+          switch(this->nal_parser->current_nal->sps->vui_parameters.aspect_ratio_idc) {
+            case ASPECT_1_1:
+              this->ratio = 1 * this->ratio;
+              break;
+            case ASPECT_12_11:
+              this->ratio *= 12.0/11.0;
+              break;
+            case ASPECT_10_11:
+              this->ratio *= 10.0/11.0;
+              break;
+            case ASPECT_16_11:
+              this->ratio *= 16.0/11.0;
+              break;
+            case ASPECT_40_33:
+              this->ratio *= 40.0/33.0;
+              break;
+            case ASPECT_24_11:
+              this->ratio *= 24.0/11.0;
+              break;
+            case ASPECT_20_11:
+              this->ratio *= 20.0/11.0;
+              break;
+            case ASPECT_32_11:
+              this->ratio *= 32.0/11.0;
+              break;
+            case ASPECT_80_33:
+              this->ratio *= 80.0/33.0;
+              break;
+            case ASPECT_18_11:
+              this->ratio *= 18.0/11.0;
+              break;
+            case ASPECT_15_11:
+              this->ratio *= 15.0/11.0;
+              break;
+            case ASPECT_64_33:
+              this->ratio *= 64.0/33.0;
+              break;
+            case ASPECT_160_99:
+              this->ratio *= 160.0/99.0;
+              break;
+            case ASPECT_4_3:
+              this->ratio *= 4.0/3.0;
+              break;
+            case ASPECT_3_2:
+              this->ratio *= 3.0/2.0;
+              break;
+            case ASPECT_2_1:
+              this->ratio *= 2.0/1.0;
+              break;
+            case ASPECT_EXTENDED_SAR:
+              this->ratio *=
+                (double)this->nal_parser->current_nal->sps->vui_parameters.sar_width/
+                (double)this->nal_parser->current_nal->sps->vui_parameters.sar_height;
+              break;
+          }
+        }
+
+        _x_stream_info_set( this->stream, XINE_STREAM_INFO_VIDEO_WIDTH, this->width );
+        _x_stream_info_set( this->stream, XINE_STREAM_INFO_VIDEO_HEIGHT, this->height );
+        _x_stream_info_set( this->stream, XINE_STREAM_INFO_VIDEO_RATIO, ((double)10000*this->ratio) );
+        _x_stream_info_set( this->stream, XINE_STREAM_INFO_FRAME_DURATION, this->video_step );
+        _x_meta_info_set_utf8( this->stream, XINE_META_INFO_VIDEOCODEC, "H264/AVC (vdpau)" );
+        xine_event_t event;
+        xine_format_change_data_t data;
+        event.type = XINE_EVENT_FRAME_FORMAT_CHANGE;
+        event.stream = this->stream;
+        event.data = &data;
+        event.data_length = sizeof(data);
+        data.width = this->width;
+        data.height = this->height;
+        data.aspect = this->ratio;
+        xine_event_send( this->stream, &event );
+
+        switch(this->nal_parser->current_nal->sps->profile_idc) {
+          case 100:
+            this->profile = VDP_DECODER_PROFILE_H264_HIGH;
+            break;
+          case 77:
+            this->profile = VDP_DECODER_PROFILE_H264_MAIN;
+            break;
+          case 66:
+          default:
+            // nvidia's VDPAU doesn't support BASELINE. But most (every?) streams marked BASELINE do not use BASELINE specifics,
+            // so, just force MAIN.
+            //this->profile = VDP_DECODER_PROFILE_H264_BASELINE;
+            this->profile = VDP_DECODER_PROFILE_H264_MAIN;
+            break;
+        }
+
+        /* get the vdpau context from vo */
+        //(this->stream->video_out->open) (this->stream->video_out, this->stream);
+        img = this->stream->video_out->get_frame (this->stream->video_out,
+                                          this->width, this->height,
+                                          this->ratio,
+                                          XINE_IMGFMT_VDPAU, VO_BOTH_FIELDS);
+
+         this->vdpau_accel = (vdpau_accel_t*)img->accel_data;
+
+         /*VdpBool is_supported;
+         uint32_t max_level, max_references, max_width, max_height;*/
+         xprintf(this->xine, XINE_VERBOSITY_LOG,
+             "Create decoder: vdp_device: %d, profile: %d, res: %dx%d\n",
+             this->vdpau_accel->vdp_device, this->profile, this->width, this->height);
+
+         VdpStatus status = this->vdpau_accel->vdp_decoder_create(this->vdpau_accel->vdp_device,
+             this->profile, this->width, this->height, 16, &this->decoder);
+
+         if(status != VDP_STATUS_OK)
+           xprintf(this->xine, XINE_VERBOSITY_LOG, "vdpau_h264: ERROR: VdpDecoderCreate returned status != OK (%s)\n", this->vdpau_accel->vdp_get_error_string(status));
+         else
+           this->decoder_initialized = 1;
+
+         img->free(img);
+         img = NULL;
+      }
+
+      if(this->decoder_initialized) {
+        if(vdp_buffer.bitstream_bytes > 0 &&
+            this->nal_parser->current_nal->slc != NULL &&
+            this->nal_parser->current_nal->sps != NULL &&
+            this->nal_parser->current_nal->pps != NULL) {
+
+          if(this->last_pts == 0)
+            this->last_pts = buf->pts;
+
+          struct pic_parameter_set_rbsp *pps = this->nal_parser->current_nal->pps;
+          struct seq_parameter_set_rbsp *sps = this->nal_parser->current_nal->sps;
+          struct slice_header *slc = this->nal_parser->current_nal->slc;
+
+          if(sps->vui_parameters_present_flag &&
+              sps->vui_parameters.timing_info_present_flag &&
+              this->video_step == 0) {
+            this->video_step = 2*90000/(1/((double)sps->vui_parameters.num_units_in_tick/(double)sps->vui_parameters.time_scale));
+            printf("Videostep: %d\n", this->video_step);
+          }
+
+          /* flush the DPB if this frame was an IDR */
+          //printf("is_idr: %d\n", this->nal_parser->is_idr);
+          if(this->nal_parser->current_nal->nal_unit_type == NAL_SLICE_IDR) {
+            printf("IDR Slice, flush\n");
+            dpb_flush(&(this->nal_parser->dpb));
+          }
+          this->nal_parser->is_idr = 0;
+
+          /* go and decode a frame */
+          VdpPictureInfoH264 pic;
+
+          pic.slice_count = slice_count;
+          pic.field_order_cnt[0] = this->nal_parser->current_nal->top_field_order_cnt;
+          pic.field_order_cnt[1] = this->nal_parser->current_nal->bottom_field_order_cnt;
+          pic.is_reference =
+            (this->nal_parser->current_nal->nal_ref_idc != 0) ? VDP_TRUE : VDP_FALSE;
+          pic.frame_num = slc->frame_num;
+          pic.field_pic_flag = slc->field_pic_flag;
+          pic.bottom_field_flag = slc->bottom_field_flag;
+          pic.num_ref_frames = sps->num_ref_frames;
+          pic.mb_adaptive_frame_field_flag = sps->mb_adaptive_frame_field_flag;
+          pic.constrained_intra_pred_flag = pps->constrained_intra_pred_flag;
+          pic.weighted_pred_flag = pps->weighted_pred_flag;
+          pic.weighted_bipred_idc = pps->weighted_bipred_idc;
+          pic.frame_mbs_only_flag = sps->frame_mbs_only_flag;
+          pic.transform_8x8_mode_flag = pps->transform_8x8_mode_flag;
+          pic.chroma_qp_index_offset = pps->chroma_qp_index_offset;
+          pic.second_chroma_qp_index_offset = pps->second_chroma_qp_index_offset;
+          pic.pic_init_qp_minus26 = pps->pic_init_qp_minus26;
+          pic.num_ref_idx_l0_active_minus1 = pps->num_ref_idx_l0_active_minus1;
+          pic.num_ref_idx_l1_active_minus1 = pps->num_ref_idx_l1_active_minus1;
+          pic.log2_max_frame_num_minus4 = sps->log2_max_frame_num_minus4;
+          pic.pic_order_cnt_type = sps->pic_order_cnt_type;
+          pic.log2_max_pic_order_cnt_lsb_minus4 = sps->log2_max_pic_order_cnt_lsb_minus4;
+          pic.delta_pic_order_always_zero_flag = sps->delta_pic_order_always_zero_flag;
+          pic.direct_8x8_inference_flag = sps->direct_8x8_inference_flag;
+          pic.entropy_coding_mode_flag = pps->entropy_coding_mode_flag;
+          pic.pic_order_present_flag = pps->pic_order_present_flag;
+          pic.deblocking_filter_control_present_flag = pps->deblocking_filter_control_present_flag;
+          pic.redundant_pic_cnt_present_flag = pps->redundant_pic_cnt_present_flag;
+          memcpy(pic.scaling_lists_4x4, pps->scaling_lists_4x4, sizeof(pic.scaling_lists_4x4));
+          memcpy(pic.scaling_lists_8x8, pps->scaling_lists_8x8, sizeof(pic.scaling_lists_8x8));
+
+          /* set num_ref_frames to the number of actually available reference frames,
+           * if this is not set generation 3 decoders will fail. */
+          pic.num_ref_frames = fill_vdpau_reference_list(&(this->nal_parser->dpb), pic.referenceFrames);
+
+          if(this->decoder_started || pic.is_reference) {
+            if(!this->decoder_started)
+              this->decoder_started = 1;
+
+            //dump_pictureinfo_h264(&pic);
+
+            /*int i;
+            printf("Decode data: \n");
+            for(i = 0; i < ((vdp_buffer.bitstream_bytes < 20) ? vdp_buffer.bitstream_bytes : 20); i++) {
+              printf("%02x ", ((uint8_t*)vdp_buffer.bitstream)[i]);
+              if((i+1) % 10 == 0)
+                printf("\n");
+            }
+            printf("\n...\n");
+            for(i = vdp_buffer.bitstream_bytes - 20; i < vdp_buffer.bitstream_bytes; i++) {
+              printf("%02x ", ((uint8_t*)vdp_buffer.bitstream)[i]);
+              if((i+1) % 10 == 0)
+                printf("\n");
+            }*/
+
+
+            if(img == NULL) {
+              fflush(stdout);
+              img = this->stream->video_out->get_frame (this->stream->video_out,
+                                                        this->width, this->height,
+                                                        this->ratio,
+                                                        XINE_IMGFMT_VDPAU, VO_BOTH_FIELDS);
+              this->vdpau_accel = (vdpau_accel_t*)img->accel_data;
+            }
+
+            VdpVideoSurface surface = this->vdpau_accel->surface;
+
+            /*if(surface == VDP_INVALID_HANDLE) {
+              VdpStatus status = this->vdpau_accel->vdp_video_surface_create(this->vdpau_accel->vdp_device,
+                  VDP_CHROMA_TYPE_420, this->width, this->height,
+                  &surface);
+              this->vdpau_accel->surface = surface;
+              if(status != VDP_STATUS_OK)
+                xprintf(this->xine, XINE_VERBOSITY_LOG, "vdpau_h264: Surface creation failed: %s\n", this->vdpau_accel->vdp_get_error_string(status));
+            }*/
+
+            //printf("Decode: NUM: %d, REF: %d, BYTES: %d, PTS: %lld\n", pic.frame_num, pic.is_reference, vdp_buffer.bitstream_bytes, buf->pts);
+            VdpStatus status = this->vdpau_accel->vdp_decoder_render(this->decoder,
+                surface, (VdpPictureInfo*)&pic, 1, &vdp_buffer);
+
+            // FIXME: do we really hit all cases here?
+            if(((uint8_t*)vdp_buffer.bitstream) != NULL) {
+              free((uint8_t*)vdp_buffer.bitstream);
+            }
+
+            if(status != VDP_STATUS_OK)
+              xprintf(this->xine, XINE_VERBOSITY_LOG, "vdpau_h264: Decoder failure: %s\n",  this->vdpau_accel->vdp_get_error_string(status));
+            else {
+
+              img->duration  = this->video_step;
+              if(this->nal_parser->current_nal->nal_unit_type == NAL_SLICE_IDR)
+                img->pts = buf->pts;
+              else
+                img->pts       = 0;
+
+              img->bad_frame = 0;
+
+              struct decoded_picture *decoded_pic = NULL;
+              if(pic.is_reference) {
+                if(!slc->field_pic_flag || !this->wait_for_bottom_field) {
+                  decoded_pic = init_decoded_picture(this->nal_parser->current_nal, surface, img);
+                  this->last_ref_pic = decoded_pic;
+                  decoded_pic->used_for_reference = 1;
+                  dpb_add_picture(&(this->nal_parser->dpb), decoded_pic, sps->num_ref_frames);
+                } else if(slc->field_pic_flag && this->wait_for_bottom_field) {
+                  if(this->last_ref_pic) {
+                    decoded_pic = this->last_ref_pic;
+                    //copy_nal_unit(decoded_pic->nal, this->nal_parser->current_nal);
+                    decoded_pic->nal->bottom_field_order_cnt = this->nal_parser->current_nal->bottom_field_order_cnt;
+                    this->last_ref_pic->bottom_is_reference = 1;
+                  }
+                }
+              }
+
+              if(!slc->field_pic_flag ||
+                  (slc->field_pic_flag && slc->bottom_field_flag && this->wait_for_bottom_field)) {
+                if(!decoded_pic) {
+                  decoded_pic = init_decoded_picture(this->nal_parser->current_nal, surface, img);
+                  decoded_pic->delayed_output = 1;
+                  dpb_add_picture(&(this->nal_parser->dpb), decoded_pic, sps->num_ref_frames);
+                  if(decoded_pic->nal->slc->bottom_field_flag)
+                    decoded_pic->nal->top_field_order_cnt = this->last_top_field_order_cnt;
+                } else
+                  decoded_pic->delayed_output = 1;
+
+                if(this->wait_for_bottom_field && slc->bottom_field_flag)
+                  decoded_pic->nal->bottom_field_order_cnt = this->nal_parser->current_nal->bottom_field_order_cnt;
+                img = NULL;
+
+                /* now retrieve the next output frame */
+                decoded_pic = dpb_get_next_out_picture(&(this->nal_parser->dpb));
+                if(decoded_pic) {
+                  if(decoded_pic->nal->nal_unit_type == NAL_SLICE_IDR &&
+                      decoded_pic->img->pts != 0) {
+                    this->last_pts = decoded_pic->img->pts;
+                  }
+
+                  decoded_pic->img->pts = this->last_pts;
+                  this->tmp_pts = decoded_pic->img->pts;
+                  this->last_pts += this->video_step;
+                  //printf("poc: %d, %d, pts: %lld\n", decoded_pic->nal->top_field_order_cnt, decoded_pic->nal->bottom_field_order_cnt, decoded_pic->img->pts);
+                  decoded_pic->img->draw(decoded_pic->img, this->stream);
+                  dpb_set_output_picture(&(this->nal_parser->dpb), decoded_pic);
+                }
+
+                this->wait_for_bottom_field = 0;
+
+                /*img->draw(img, this->stream);
+                this->wait_for_bottom_field = 0;
+
+                if(!pic.is_reference)
+                  img->free(img);
+                img = NULL;*/
+              } else if(slc->field_pic_flag && !slc->bottom_field_flag) {
+                // don't draw yet, second field is missing.
+                this->last_top_field_order_cnt = this->nal_parser->current_nal->top_field_order_cnt;
+                this->wait_for_bottom_field = 1;
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+/*
+ * This function is called when xine needs to flush the system.
+ */
+static void vdpau_h264_flush (video_decoder_t *this_gen) {
+}
+
+/*
+ * This function resets the video decoder.
+ */
+static void vdpau_h264_reset (video_decoder_t *this_gen) {
+  vdpau_h264_decoder_t *this = (vdpau_h264_decoder_t *) this_gen;
+
+  printf("vdpau_h264_reset\n");
+
+  this->size = 0;
+
+  dpb_free_all( &(this->nal_parser->dpb) );
+
+  if (this->decoder_initialized)
+    this->vdpau_accel->vdp_decoder_destroy( this->decoder );
+
+  this->decoder_started    = 0;
+  this->decoder_initialized = 0;
+  this->nal_parser = init_parser();
+  this->buf           = NULL;
+  this->wait_for_bottom_field = 0;
+  this->video_step = 0;
+  this->last_pts = 0;
+  this->tmp_pts = 0;
+}
+
+/*
+ * The decoder should forget any stored pts values here.
+ */
+static void vdpau_h264_discontinuity (video_decoder_t *this_gen) {
+  vdpau_h264_decoder_t *this = (vdpau_h264_decoder_t *) this_gen;
+  
+  this->last_pts = 0;
+  this->tmp_pts = 0;
+
+}
+
+/*
+ * This function frees the video decoder instance allocated to the decoder.
+ */
+static void vdpau_h264_dispose (video_decoder_t *this_gen) {
+
+  vdpau_h264_decoder_t *this = (vdpau_h264_decoder_t *) this_gen;
+
+  if (this->buf) {
+    free (this->buf);
+    this->buf = NULL;
+  }
+
+  dpb_free_all( &(this->nal_parser->dpb) );
+
+  if (this->decoder_initialized) {
+    this->vdpau_accel->vdp_decoder_destroy( this->decoder );
+    this->decoder_initialized = 0;
+  }
+
+  this->stream->video_out->close( this->stream->video_out, this->stream );
+
+  free (this_gen);
+}
+
+/*
+ * This function allocates, initializes, and returns a private video
+ * decoder structure.
+ */
+static video_decoder_t *open_plugin (video_decoder_class_t *class_gen, xine_stream_t *stream) {
+
+  vdpau_h264_decoder_t  *this ;
+
+  /* the videoout must be vdpau-capable to support this decoder */
+  if ( !(stream->video_driver->get_capabilities(stream->video_driver) & VO_CAP_VDPAU_H264) )
+	  return NULL;
+
+  this = (vdpau_h264_decoder_t *) calloc(1, sizeof(vdpau_h264_decoder_t));
+
+  this->video_decoder.decode_data         = vdpau_h264_decode_data;
+  this->video_decoder.flush               = vdpau_h264_flush;
+  this->video_decoder.reset               = vdpau_h264_reset;
+  this->video_decoder.discontinuity       = vdpau_h264_discontinuity;
+  this->video_decoder.dispose             = vdpau_h264_dispose;
+  this->size                              = 0;
+
+  this->stream                            = stream;
+  this->xine                              = stream->xine;
+  this->class                             = (vdpau_h264_class_t *) class_gen;
+
+  this->decoder_started    = 0;
+  this->decoder_initialized = 0;
+  this->nal_parser = init_parser();
+  this->buf           = NULL;
+  this->wait_for_bottom_field = 0;
+  this->video_step = 0;
+  this->last_pts = 0;
+  this->tmp_pts = 0;
+
+  (this->stream->video_out->open) (this->stream->video_out, this->stream);
+
+  return &this->video_decoder;
+}
+
+/*
+ * This function returns a brief string that describes (usually with the
+ * decoder's most basic name) the video decoder plugin.
+ */
+static char *get_identifier (video_decoder_class_t *this) {
+  return "vdpau_h264";
+}
+
+/*
+ * This function returns a slightly longer string describing the video
+ * decoder plugin.
+ */
+static char *get_description (video_decoder_class_t *this) {
+  return "vdpau_h264: h264 decoder plugin using VDPAU hardware decoding.\n"
+	  "Must be used along with video_out_vdpau.";
+}
+
+/*
+ * This function frees the video decoder class and any other memory that was
+ * allocated.
+ */
+static void dispose_class (video_decoder_class_t *this) {
+  free (this);
+}
+
+/*
+ * This function allocates a private video decoder class and initializes
+ * the class's member functions.
+ */
+static void *init_plugin (xine_t *xine, void *data) {
+
+  vdpau_h264_class_t *this;
+
+  this = (vdpau_h264_class_t *) calloc(1, sizeof(vdpau_h264_class_t));
+
+  this->decoder_class.open_plugin     = open_plugin;
+  this->decoder_class.get_identifier  = get_identifier;
+  this->decoder_class.get_description = get_description;
+  this->decoder_class.dispose         = dispose_class;
+
+  return this;
+}
+
+/*
+ * This is a list of all of the internal xine video buffer types that
+ * this decoder is able to handle. Check src/xine-engine/buffer.h for a
+ * list of valid buffer types (and add a new one if the one you need does
+ * not exist). Terminate the list with a 0.
+ */
+static const uint32_t video_types[] = {
+  /* BUF_VIDEO_FOOVIDEO, */
+  BUF_VIDEO_H264,
+  0
+};
+
+/*
+ * This data structure combines the list of supported xine buffer types and
+ * the priority that the plugin should be given with respect to other
+ * plugins that handle the same buffer type. A plugin with priority (n+1)
+ * will be used instead of a plugin with priority (n).
+ */
+static const decoder_info_t dec_info_video = {
+  video_types,         /* supported types */
+  7                    /* priority        */
+};
+
+/*
+ * The plugin catalog entry. This is the only information that this plugin
+ * will export to the public.
+ */
+const plugin_info_t xine_plugin_info[] EXPORTED = {
+  /* { type, API, "name", version, special_info, init_function } */
+  { PLUGIN_VIDEO_DECODER, 18, "vdpau_h264", XINE_VERSION_CODE, &dec_info_video, init_plugin },
+  { PLUGIN_NONE, 0, "", 0, NULL, NULL }
+};
diff -Naur xine-lib-1.1.15-old/src/libvdpau/vdpau_mpeg12.c xine-lib-1.1.15-new/src/libvdpau/vdpau_mpeg12.c
--- xine-lib-1.1.15-old/src/libvdpau/vdpau_mpeg12.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/libvdpau/vdpau_mpeg12.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,952 @@
+/*
+ * Copyright (C) 2008 Christophe Thommeret <hftom@free.fr>
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ * vdpau_mpeg12.c, a mpeg1/2 video stream parser using VDPAU hardware decoder
+ *
+ */
+
+//#define LOG 
+#define LOG_MODULE "vdpau_mpeg12"
+
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include "xine_internal.h"
+#include "video_out.h"
+#include "buffer.h"
+#include "xineutils.h"
+#include "accel_vdpau.h"
+
+#include <vdpau/vdpau.h>
+
+
+
+#define sequence_header_code    0xb3
+#define sequence_error_code     0xb4
+#define sequence_end_code       0xb7
+#define group_start_code        0xb8
+#define extension_start_code    0xb5
+#define user_data_start_code    0xb2
+#define picture_start_code      0x00
+#define begin_slice_start_code  0x01
+#define end_slice_start_code    0xaf
+
+#define sequence_ext_sc         1
+#define quant_matrix_ext_sc     3
+#define picture_coding_ext_sc   8
+#define sequence_display_ext_sc 2
+
+#define I_FRAME   1
+#define P_FRAME   2
+#define B_FRAME   3
+
+#define PICTURE_TOP     1
+#define PICTURE_BOTTOM  2
+#define PICTURE_FRAME   3
+
+#define WANT_HEADER 1
+#define WANT_EXT    2
+#define WANT_SLICE  3
+
+
+
+/* default intra quant matrix, in zig-zag order */
+static const uint8_t default_intra_quantizer_matrix[64] = {
+    8,
+    16, 16,
+    19, 16, 19,
+    22, 22, 22, 22,
+    22, 22, 26, 24, 26,
+    27, 27, 27, 26, 26, 26,
+    26, 27, 27, 27, 29, 29, 29,
+    34, 34, 34, 29, 29, 29, 27, 27,
+    29, 29, 32, 32, 34, 34, 37,
+    38, 37, 35, 35, 34, 35,
+    38, 38, 40, 40, 40,
+    48, 48, 46, 46,
+    56, 56, 58,
+    69, 69,
+    83
+};
+
+uint8_t mpeg2_scan_norm[64] = {
+    /* Zig-Zag scan pattern */
+     0, 1, 8,16, 9, 2, 3,10,
+    17,24,32,25,18,11, 4, 5,
+    12,19,26,33,40,48,41,34,
+    27,20,13, 6, 7,14,21,28,
+    35,42,49,56,57,50,43,36,
+    29,22,15,23,30,37,44,51,
+    58,59,52,45,38,31,39,46,
+    53,60,61,54,47,55,62,63
+};
+
+uint8_t mpeg2_scan_alt[64] = {
+    /* Alternate scan pattern */
+    0,8,16,24,1,9,2,10,17,25,32,40,48,56,57,49,
+    41,33,26,18,3,11,4,12,19,27,34,42,50,58,35,43,
+    51,59,20,28,5,13,6,14,21,29,36,44,52,60,37,45,
+    53,61,22,30,7,15,23,31,38,46,54,62,39,47,55,63
+};
+
+
+typedef struct {
+  VdpPictureInfoMPEG1Or2  vdp_infos; /* first field, also used for frame */
+  VdpPictureInfoMPEG1Or2  vdp_infos2; /* second field */
+  int                     slices_count, slices_count2;
+  uint8_t                 *slices;
+  int                     slices_size;
+  int                     slices_pos, slices_pos_top;
+
+  int                     state;
+} picture_t;
+
+
+
+typedef struct {
+  uint32_t    coded_width;
+  uint32_t    coded_height;
+  uint32_t    display_width;
+  uint32_t    display_height;
+  uint64_t    video_step; /* frame duration in pts units */
+  double      ratio;
+  VdpDecoderProfile profile;
+  int         chroma;
+
+  int         have_header;
+  
+  uint8_t     *buf; /* accumulate data */
+  int         bufseek;
+  uint32_t    bufsize;
+  uint32_t    bufpos;
+  int         start;
+  
+  picture_t   picture;
+  vo_frame_t  *forward_ref;
+  vo_frame_t  *backward_ref;
+  
+  int64_t    seq_pts;
+	int64_t    cur_pts;
+  
+  vdpau_accel_t *accel_vdpau;
+	
+} sequence_t;
+
+
+typedef struct {
+  video_decoder_class_t   decoder_class;
+} vdpau_mpeg12_class_t;
+
+
+typedef struct vdpau_mpeg12_decoder_s {
+  video_decoder_t         video_decoder;  /* parent video decoder structure */
+
+  vdpau_mpeg12_class_t    *class;
+  xine_stream_t           *stream;
+
+  sequence_t              sequence;
+  
+  VdpDecoder              decoder;
+  VdpDecoderProfile       decoder_profile;
+  uint32_t                decoder_width;
+  uint32_t                decoder_height;  
+  
+} vdpau_mpeg12_decoder_t;
+
+
+
+static void reset_picture( picture_t *pic )
+{
+  lprintf( "reset_picture\n" );
+  pic->vdp_infos.picture_structure = 0;
+  pic->vdp_infos2.intra_dc_precision = pic->vdp_infos.intra_dc_precision = 0;
+  pic->vdp_infos2.frame_pred_frame_dct = pic->vdp_infos.frame_pred_frame_dct = 1;
+  pic->vdp_infos2.concealment_motion_vectors = pic->vdp_infos.concealment_motion_vectors = 0;
+  pic->vdp_infos2.intra_vlc_format = pic->vdp_infos.intra_vlc_format = 0;
+  pic->vdp_infos2.alternate_scan = pic->vdp_infos.alternate_scan = 0;
+  pic->vdp_infos2.q_scale_type = pic->vdp_infos.q_scale_type = 0;
+  pic->vdp_infos2.top_field_first = pic->vdp_infos.top_field_first = 0;
+  pic->slices_count = 0;
+  pic->slices_count2 = 0;
+  pic->slices_pos = 0;
+  pic->slices_pos_top = 0;
+  pic->state = WANT_HEADER;
+}
+
+
+
+static void init_picture( picture_t *pic )
+{
+  pic->slices_size = 2048;
+  pic->slices = (uint8_t*)malloc(pic->slices_size);
+  reset_picture( pic );
+}
+
+
+
+static void reset_sequence( sequence_t *sequence )
+{
+  lprintf( "reset_sequence\n" );
+  sequence->have_header = 0;
+  sequence->bufpos = 0;
+  sequence->bufseek = 0;
+  sequence->start = -1;
+	sequence->seq_pts = sequence->cur_pts = 0;
+  sequence->profile = VDP_DECODER_PROFILE_MPEG1;
+  sequence->chroma = 0;
+	//sequence->ratio = 1.0;
+	sequence->video_step = 3600;
+  if ( sequence->forward_ref )
+    sequence->forward_ref->free( sequence->forward_ref );
+  sequence->forward_ref = NULL;
+  if ( sequence->backward_ref )
+    sequence->backward_ref->free( sequence->backward_ref );
+  sequence->backward_ref = NULL;
+}
+  
+
+
+static uint32_t get_bits( uint8_t *b, int offbits, int nbits )
+{
+  int i, nbytes;
+  uint32_t ret = 0;
+  uint8_t *buf;
+
+  buf = b+(offbits/8);
+  offbits %=8;
+  nbytes = (offbits+nbits)/8;
+  if ( ((offbits+nbits)%8)>0 )
+    nbytes++;
+  for ( i=0; i<nbytes; i++ )
+    ret += buf[i]<<((nbytes-i-1)*8);
+  i = (4-nbytes)*8+offbits;
+  ret = ((ret<<i)>>i)>>((nbytes*8)-nbits-offbits);
+
+  return ret;
+}
+
+
+
+static void sequence_header( vdpau_mpeg12_decoder_t *this_gen, uint8_t *buf, int len )
+{
+  sequence_t *sequence = (sequence_t*)&this_gen->sequence;
+  
+  int i, j, off=0;
+	if ( sequence->cur_pts ) {
+		sequence->seq_pts = sequence->cur_pts;
+	}	
+  sequence->coded_width = get_bits( buf,0,12 );
+  lprintf( "coded_width: %d\n", get_bits( buf,0,12 ) );
+  sequence->coded_height = get_bits( buf,12,12 );
+  lprintf( "coded_height: %d\n", get_bits( buf,12,12 ) );
+  switch ( get_bits( buf+3,0,4 ) ) {
+    case 1: sequence->ratio = 1.0; break;
+    case 2: sequence->ratio = 4.0/3.0; break;
+    case 3: sequence->ratio = 16.0/9.0; break;
+    case 4: sequence->ratio = 2.21; break;
+    default: sequence->ratio = (double)sequence->coded_width/(double)sequence->coded_height;
+  }
+  lprintf( "ratio: %d\n", get_bits( buf+3,0,4 ) );
+  switch ( get_bits( buf+3,4,4 ) ) {
+    case 1: sequence->video_step = 3913; break; /* 23.976.. */
+    case 2: sequence->video_step = 3750; break; /* 24 */
+    case 3: sequence->video_step = 3600; break; /* 25 */
+    case 4: sequence->video_step = 3003; break; /* 29.97.. */
+    case 5: sequence->video_step = 3000; break; /* 30 */
+    case 6: sequence->video_step = 1800; break; /* 50 */
+    case 7: sequence->video_step = 1525; break; /* 59.94.. */
+    case 8: sequence->video_step = 1509; break; /* 60 */
+  }
+  lprintf( "frame_rate: %d\n", get_bits( buf+3,4,4 ) );
+  lprintf( "bit_rate_value: %d\n", get_bits( buf+4,0,18 ) );
+  lprintf( "marker_bit: %d\n", get_bits( buf+6,2,1 ) );
+  lprintf( "vbv_buffer_size_value: %d\n", get_bits( buf+6,3,10 ) );
+  lprintf( "constrained_parameters_flag: %d\n", get_bits( buf+7,5,1 ) );
+  i = get_bits( buf+7,6,1 );
+  lprintf( "load_intra_quantizer_matrix: %d\n", i );
+  if ( i ) {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.intra_quantizer_matrix[mpeg2_scan_norm[j]] = get_bits( buf+7+j,7,8 );
+    }
+    off = 64;
+  }
+  else {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.intra_quantizer_matrix[mpeg2_scan_norm[j]] = default_intra_quantizer_matrix[j];
+    }
+  }
+  
+  i = get_bits( buf+7+off,7,1 );
+  lprintf( "load_non_intra_quantizer_matrix: %d\n", i );
+  if ( i ) {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.non_intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.non_intra_quantizer_matrix[mpeg2_scan_norm[j]] = get_bits( buf+8+off+j,0,8 );
+    }
+  }
+  else {
+    memset( sequence->picture.vdp_infos.non_intra_quantizer_matrix, 16, 64 );
+    memset( sequence->picture.vdp_infos2.non_intra_quantizer_matrix, 16, 64 );
+  }
+
+  if ( !sequence->have_header ) {
+    sequence->have_header = 1;
+    _x_stream_info_set( this_gen->stream, XINE_STREAM_INFO_VIDEO_WIDTH, sequence->coded_width );
+    _x_stream_info_set( this_gen->stream, XINE_STREAM_INFO_VIDEO_HEIGHT, sequence->coded_height );
+    _x_stream_info_set( this_gen->stream, XINE_STREAM_INFO_VIDEO_RATIO, ((double)10000*sequence->ratio) );
+    _x_stream_info_set( this_gen->stream, XINE_STREAM_INFO_FRAME_DURATION, sequence->video_step );
+    _x_meta_info_set_utf8( this_gen->stream, XINE_META_INFO_VIDEOCODEC, "MPEG1/2 (vdpau)" );
+    xine_event_t event;
+    xine_format_change_data_t data;
+    event.type = XINE_EVENT_FRAME_FORMAT_CHANGE;
+    event.stream = this_gen->stream;
+    event.data = &data;
+    event.data_length = sizeof(data);
+    data.width = sequence->coded_width;
+    data.height = sequence->coded_height;
+    data.aspect = sequence->ratio;
+    xine_event_send( this_gen->stream, &event );
+  }
+}
+
+
+
+static void picture_header( sequence_t *sequence, uint8_t *buf, int len )
+{
+  if ( sequence->picture.state!=WANT_HEADER )
+    return;
+  
+  if ( sequence->profile==VDP_DECODER_PROFILE_MPEG1 )
+    sequence->picture.vdp_infos.picture_structure = PICTURE_FRAME;
+  
+  VdpPictureInfoMPEG1Or2 *infos = &sequence->picture.vdp_infos;
+  
+  if ( sequence->picture.vdp_infos.picture_structure && sequence->picture.slices_count2 )
+      reset_picture( &sequence->picture );
+  
+  if ( sequence->picture.vdp_infos.picture_structure==PICTURE_FRAME ) {
+    reset_picture( &sequence->picture );
+  }
+  else if ( sequence->picture.vdp_infos.picture_structure ) {
+    infos = &sequence->picture.vdp_infos2;
+  }
+    
+  lprintf( "temporal_reference: %d\n", get_bits( buf,0,10 ) );
+  infos->picture_coding_type = get_bits( buf,10,3 );
+  lprintf( "picture_coding_type: %d\n", get_bits( buf,10,3 ) );
+  infos->forward_reference = VDP_INVALID_HANDLE;
+  infos->backward_reference = VDP_INVALID_HANDLE;
+  if ( infos->picture_coding_type > I_FRAME ) {
+    infos->full_pel_forward_vector = get_bits( buf+2,13,1 );
+    infos->f_code[0][0] = infos->f_code[0][1] = get_bits( buf+2,14,3 );
+    if ( infos->picture_coding_type==B_FRAME ) {
+      infos->full_pel_backward_vector = get_bits( buf+2,17,1 );
+      infos->f_code[1][0] = infos->f_code[1][1] = get_bits( buf+2,18,3 );
+    }
+  }
+  else {
+    infos->full_pel_forward_vector = 0;
+    infos->full_pel_backward_vector = 0;
+  }
+  if ( sequence->profile==VDP_DECODER_PROFILE_MPEG1 )
+    sequence->picture.state = WANT_SLICE;
+  else
+    sequence->picture.state = WANT_EXT;
+}
+
+
+
+static void sequence_extension( sequence_t *sequence, uint8_t *buf, int len )
+{
+  lprintf( "extension_start_code_identifier: %d\n", get_bits( buf,0,4 ) );
+  switch ( get_bits( buf,5,3 ) ) {
+    case 5: sequence->profile = VDP_DECODER_PROFILE_MPEG2_SIMPLE; break;
+    default: sequence->profile = VDP_DECODER_PROFILE_MPEG2_MAIN;
+  }
+  lprintf( "profile_and_level_indication: %d\n", get_bits( buf,4,8 ) );
+  lprintf( "progressive_sequence: %d\n", get_bits( buf,12,1 ) );
+  if ( get_bits( buf,13,2 )==2 )
+    sequence->chroma = VO_CHROMA_422;
+  lprintf( "chroma_format: %d\n", get_bits( buf,13,2 ) );
+  lprintf( "horizontal_size_extension: %d\n", get_bits( buf,15,2 ) );
+  lprintf( "vertical_size_extension: %d\n", get_bits( buf,17,2 ) );
+  lprintf( "bit_rate_extension: %d\n", get_bits( buf,19,12 ) );
+  lprintf( "marker_bit: %d\n", get_bits( buf,31,1 ) );
+  lprintf( "vbv_buffer_size_extension: %d\n", get_bits( buf+4,0,8 ) );
+  lprintf( "low_delay: %d\n", get_bits( buf+5,0,1 ) );
+  lprintf( "frame_rate_extension_n: %d\n", get_bits( buf+5,1,2 ) );
+  lprintf( "frame_rate_extension_d: %d\n", get_bits( buf+5,3,5 ) );
+}
+
+
+
+static void picture_coding_extension( sequence_t *sequence, uint8_t *buf, int len )
+{
+  if ( sequence->picture.state!=WANT_EXT )
+    return;
+  
+  VdpPictureInfoMPEG1Or2 *infos = &sequence->picture.vdp_infos;
+  if ( infos->picture_structure && infos->picture_structure!=PICTURE_FRAME )
+    infos = &sequence->picture.vdp_infos2;
+  
+  infos->f_code[0][0] = get_bits( buf,4,4 );
+  infos->f_code[0][1] = get_bits( buf,8,4 );
+  infos->f_code[1][0] = get_bits( buf,12,4 );
+  infos->f_code[1][1] = get_bits( buf,16,4 );
+  lprintf( "extension_start_code_identifier: %d\n", get_bits( buf,0,4 ) );
+  lprintf( "f_code_0_0: %d\n", get_bits( buf,4,4 ) );
+  lprintf( "f_code_0_1: %d\n", get_bits( buf,8,4 ) );
+  lprintf( "f_code_1_0: %d\n", get_bits( buf,12,4 ) );
+  lprintf( "f_code_1_1: %d\n", get_bits( buf,16,4 ) );
+  infos->intra_dc_precision = get_bits( buf,20,2 );
+  lprintf( "intra_dc_precision: %d\n", get_bits( buf,20,2 ) );
+  infos->picture_structure = get_bits( buf,22,2 );
+  lprintf( "picture_structure: %d\n", get_bits( buf,22,2 ) );
+  infos->top_field_first = get_bits( buf,24,1 );
+  lprintf( "top_field_first: %d\n", get_bits( buf,24,1 ) );
+  infos->frame_pred_frame_dct = get_bits( buf,25,1 );
+  lprintf( "frame_pred_frame_dct: %d\n", get_bits( buf,25,1 ) );
+  infos->concealment_motion_vectors = get_bits( buf,26,1 );
+  lprintf( "concealment_motion_vectors: %d\n", get_bits( buf,26,1 ) );
+  infos->q_scale_type = get_bits( buf,27,1 );
+  lprintf( "q_scale_type: %d\n", get_bits( buf,27,1 ) );
+  infos->intra_vlc_format = get_bits( buf,28,1 );
+  lprintf( "intra_vlc_format: %d\n", get_bits( buf,28,1 ) );
+  infos->alternate_scan = get_bits( buf,29,1 );
+  lprintf( "alternate_scan: %d\n", get_bits( buf,29,1 ) );
+  lprintf( "repeat_first_field: %d\n", get_bits( buf,30,1 ) );
+  lprintf( "chroma_420_type: %d\n", get_bits( buf,31,1 ) );
+  lprintf( "progressive_frame: %d\n", get_bits( buf,32,1 ) );
+  sequence->picture.state = WANT_SLICE;
+}
+
+
+
+static void quant_matrix_extension( sequence_t *sequence, uint8_t *buf, int len )
+{
+  int i, j, off;
+  
+  i = get_bits( buf,4,1 );
+  lprintf( "load_intra_quantizer_matrix: %d\n", i );
+  if ( i ) {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.intra_quantizer_matrix[mpeg2_scan_norm[j]] = get_bits( buf+j,5,8 );
+    }
+    off = 64;
+  }
+  else {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.intra_quantizer_matrix[mpeg2_scan_norm[j]] = default_intra_quantizer_matrix[j];
+    }
+  }
+  
+  i = get_bits( buf+off,5,1 );
+  lprintf( "load_non_intra_quantizer_matrix: %d\n", i );
+  if ( i ) {
+    for ( j=0; j<64; ++j ) {
+      sequence->picture.vdp_infos2.non_intra_quantizer_matrix[mpeg2_scan_norm[j]] = sequence->picture.vdp_infos.non_intra_quantizer_matrix[mpeg2_scan_norm[j]] = get_bits( buf+off+j,6,8 );
+    }
+  }
+  else {
+    memset( sequence->picture.vdp_infos.non_intra_quantizer_matrix, 16, 64 );
+    memset( sequence->picture.vdp_infos2.non_intra_quantizer_matrix, 16, 64 );
+  }
+}
+
+
+
+static void copy_slice( sequence_t *sequence, uint8_t *buf, int len )
+{
+  int size = sequence->picture.slices_pos+len;
+  if ( sequence->picture.slices_size < size ) {
+    sequence->picture.slices_size = size+1024;
+    sequence->picture.slices = realloc( sequence->picture.slices, sequence->picture.slices_size );
+  }
+  xine_fast_memcpy( sequence->picture.slices+sequence->picture.slices_pos, buf, len );
+  sequence->picture.slices_pos += len;
+  if ( sequence->picture.slices_pos_top )
+    sequence->picture.slices_count2++;
+  else
+    sequence->picture.slices_count++;
+}
+
+
+
+static int parse_code( vdpau_mpeg12_decoder_t *this_gen, uint8_t *buf, int len )
+{
+  sequence_t *sequence = (sequence_t*)&this_gen->sequence;
+  
+  if ( !sequence->have_header && buf[3]!=sequence_header_code )
+    return 0;
+  
+  if ( (buf[3] >= begin_slice_start_code) && (buf[3] <= end_slice_start_code) ) {
+    lprintf( " ----------- slice_start_code\n" );
+    if ( sequence->picture.state==WANT_SLICE )
+      copy_slice( sequence, buf, len );
+    return 0;
+  }
+  else if ( sequence->picture.state==WANT_SLICE && sequence->picture.slices_count ) {
+    if ( !sequence->picture.slices_count2 ) {
+      sequence->picture.slices_pos_top = sequence->picture.slices_pos;
+    }
+    /* no more slices, decode */
+    return 1;
+  }
+  
+  switch ( buf[3] ) {
+    case sequence_header_code:
+      lprintf( " ----------- sequence_header_code\n" );
+      sequence_header( this_gen, buf+4, len-4 );
+      break;
+    case extension_start_code: {
+      switch ( get_bits( buf+4,0,4 ) ) {
+        case sequence_ext_sc:
+          lprintf( " ----------- sequence_extension_start_code\n" );
+          sequence_extension( sequence, buf+4, len-4 );
+          break;
+        case quant_matrix_ext_sc:
+          lprintf( " ----------- quant_matrix_extension_start_code\n" );
+          quant_matrix_extension( sequence, buf+4, len-4 );
+          break;
+        case picture_coding_ext_sc:
+          lprintf( " ----------- picture_coding_extension_start_code\n" );
+          picture_coding_extension( sequence, buf+4, len-4 );
+          break;
+        case sequence_display_ext_sc:
+          lprintf( " ----------- sequence_display_extension_start_code\n" );
+          //sequence_display_extension( sequence, buf+4, len-4 );
+          break;
+      }
+      break;
+      }
+    case user_data_start_code:
+      lprintf( " ----------- user_data_start_code\n" );
+      break;
+    case group_start_code:
+      lprintf( " ----------- group_start_code\n" );
+      break;
+    case picture_start_code:
+      lprintf( " ----------- picture_start_code\n" );
+      //slice_count = 0;
+      picture_header( sequence, buf+4, len-4 );
+      break;
+    case sequence_error_code:
+      lprintf( " ----------- sequence_error_code\n" );
+      break;
+    case sequence_end_code:
+      lprintf( " ----------- sequence_end_code\n" );
+      break;
+  }
+  return 0;
+}
+
+
+
+static void decode_render( vdpau_mpeg12_decoder_t *vd, vdpau_accel_t *accel )
+{
+  sequence_t *seq = (sequence_t*)&vd->sequence;
+  picture_t *pic = (picture_t*)&seq->picture;
+  
+  pic->vdp_infos.slice_count = pic->slices_count;
+  pic->vdp_infos2.slice_count = pic->slices_count2;
+  
+  VdpStatus st;
+  if ( vd->decoder==VDP_INVALID_HANDLE || vd->decoder_profile!=seq->profile || vd->decoder_width!=seq->coded_width || vd->decoder_height!=seq->coded_height ) {
+    if ( vd->decoder!=VDP_INVALID_HANDLE ) {
+      accel->vdp_decoder_destroy( vd->decoder );
+      vd->decoder = VDP_INVALID_HANDLE;
+    }
+    st = accel->vdp_decoder_create( accel->vdp_device, seq->profile, seq->coded_width, seq->coded_height, 2, &vd->decoder);
+    if ( st!=VDP_STATUS_OK )
+      lprintf( "failed to create decoder !! %s\n", accel->vdp_get_error_string( st ) );
+    else {
+      vd->decoder_profile = seq->profile;
+      vd->decoder_width = seq->coded_width;
+      vd->decoder_height = seq->coded_height;
+    }
+  }
+  /*if ( accel->surface==VDP_INVALID_HANDLE ) {
+    st = accel->vdp_video_surface_create( accel->vdp_device, VDP_CHROMA_TYPE_420, seq->coded_width, seq->coded_height, &accel->surface);
+    if ( st!=VDP_STATUS_OK )
+      lprintf( "failed to create surface !! %s\n", accel->vdp_get_error_string( st ) );
+  }*/
+    
+  VdpBitstreamBuffer vbit;
+  vbit.struct_version = VDP_BITSTREAM_BUFFER_VERSION;
+  vbit.bitstream = pic->slices;
+  vbit.bitstream_bytes = (pic->vdp_infos.picture_structure==PICTURE_FRAME)? pic->slices_pos : pic->slices_pos_top;
+  st = accel->vdp_decoder_render( vd->decoder, accel->surface, (VdpPictureInfo*)&pic->vdp_infos, 1, &vbit );
+  if ( st!=VDP_STATUS_OK )
+    lprintf( "decoder failed : %d!! %s\n", st, accel->vdp_get_error_string( st ) );
+  else {
+    lprintf( "DECODER SUCCESS : frame_type:%d, slices=%d, slices_bytes=%d, current=%d, forwref:%d, backref:%d, pts:%lld\n",
+              pic->vdp_infos.picture_coding_type, pic->vdp_infos.slice_count, vbit.bitstream_bytes, accel->surface, pic->vdp_infos.forward_reference, pic->vdp_infos.backward_reference, seq->seq_pts );
+    VdpPictureInfoMPEG1Or2 *info = &pic->vdp_infos;
+    lprintf("%d %d %d %d %d %d %d %d %d %d %d %d %d\n", info->intra_dc_precision, info->frame_pred_frame_dct, info->concealment_motion_vectors, info->intra_vlc_format, info->alternate_scan, info->q_scale_type, info->top_field_first, info->full_pel_forward_vector, info->full_pel_backward_vector, info->f_code[0][0], info->f_code[0][1], info->f_code[1][0], info->f_code[1][1] );
+  }
+              
+  if ( pic->vdp_infos.picture_structure != PICTURE_FRAME ) {
+    pic->vdp_infos2.backward_reference = VDP_INVALID_HANDLE;
+    pic->vdp_infos2.forward_reference = VDP_INVALID_HANDLE;
+    if ( pic->vdp_infos2.picture_coding_type==P_FRAME ) {
+      pic->vdp_infos2.backward_reference = VDP_INVALID_HANDLE;
+      if ( pic->vdp_infos.picture_coding_type==I_FRAME )
+        pic->vdp_infos2.forward_reference = accel->surface;
+      else
+        pic->vdp_infos2.forward_reference = pic->vdp_infos.forward_reference;
+    }
+    else if ( pic->vdp_infos.picture_coding_type==B_FRAME ) {
+      pic->vdp_infos2.forward_reference = pic->vdp_infos.forward_reference;
+      pic->vdp_infos2.backward_reference = pic->vdp_infos.backward_reference;
+    }
+    vbit.struct_version = VDP_BITSTREAM_BUFFER_VERSION;
+    vbit.bitstream = pic->slices+pic->slices_pos_top;
+    vbit.bitstream_bytes = pic->slices_pos-pic->slices_pos_top;
+    st = accel->vdp_decoder_render( vd->decoder, accel->surface, (VdpPictureInfo*)&pic->vdp_infos2, 1, &vbit );
+    if ( st!=VDP_STATUS_OK )
+      lprintf( "decoder failed : %d!! %s\n", st, accel->vdp_get_error_string( st ) );
+    else
+      lprintf( "DECODER SUCCESS : frame_type:%d, slices=%d, current=%d, forwref:%d, backref:%d, pts:%lld\n",
+                pic->vdp_infos2.picture_coding_type, pic->vdp_infos2.slice_count, accel->surface, pic->vdp_infos2.forward_reference, pic->vdp_infos2.backward_reference, seq->seq_pts );
+  }
+  
+  //printf( "vdpau_meg12:  forwref:%d, backref:%d\n", seq->forward_ref, seq->backward_ref );
+}
+
+
+
+static void decode_picture( vdpau_mpeg12_decoder_t *vd )
+{
+  sequence_t *seq = (sequence_t*)&vd->sequence;
+  picture_t *pic = (picture_t*)&seq->picture;
+  vdpau_accel_t *ref_accel;
+  
+  pic->state = WANT_HEADER;
+  
+  if ( seq->profile == VDP_DECODER_PROFILE_MPEG1 )
+    pic->vdp_infos.picture_structure=PICTURE_FRAME;
+  
+  if ( pic->vdp_infos.picture_structure!=PICTURE_FRAME && !pic->slices_count2 ) {
+    lprintf("********************* no slices_count2 **********************\n");
+    return;
+  }
+
+  if ( pic->vdp_infos.picture_coding_type==P_FRAME ) {
+    if ( seq->backward_ref ) {
+      ref_accel = (vdpau_accel_t*)seq->backward_ref->accel_data;
+      pic->vdp_infos.forward_reference = ref_accel->surface;
+    }
+    else
+      return;
+  }
+  else if ( pic->vdp_infos.picture_coding_type==B_FRAME ) {
+    if ( seq->forward_ref ) {
+      ref_accel = (vdpau_accel_t*)seq->forward_ref->accel_data;
+      pic->vdp_infos.forward_reference = ref_accel->surface;
+    }
+    else
+      return;
+    if ( seq->backward_ref ) {
+      ref_accel = (vdpau_accel_t*)seq->backward_ref->accel_data;
+      pic->vdp_infos.backward_reference = ref_accel->surface;
+    }
+    else
+      return;
+  }
+
+  //printf("vdpau_mpeg12: get image ..\n");
+  vo_frame_t *img = vd->stream->video_out->get_frame( vd->stream->video_out, seq->coded_width, seq->coded_height,
+                                                      seq->ratio, XINE_IMGFMT_VDPAU, VO_BOTH_FIELDS|seq->chroma );
+  vdpau_accel_t *accel = (vdpau_accel_t*)img->accel_data;
+  if ( !seq->accel_vdpau )
+    seq->accel_vdpau = accel;
+                                                      
+  img->drawn = 0;                                                        
+  //printf("vdpau_mpeg12: .. got image %d\n", img);
+
+  decode_render( vd, accel );
+  
+  img->bad_frame = 0;
+  img->duration = seq->video_step;
+  
+  if ( pic->vdp_infos.picture_coding_type!=B_FRAME ) {
+    if ( pic->vdp_infos.picture_coding_type==I_FRAME && !seq->backward_ref ) {
+      img->pts = 0;
+      img->draw( img, vd->stream );
+      ++img->drawn;
+    }
+    if ( seq->forward_ref ) {
+      seq->forward_ref->drawn = 0;
+      seq->forward_ref->free( seq->forward_ref );
+      //printf("vdpau_mpeg12: freed image %d\n", seq->forward_ref );
+    }
+    seq->forward_ref = seq->backward_ref;
+    if ( seq->forward_ref && !seq->forward_ref->drawn ) {
+      seq->forward_ref->pts = seq->seq_pts;
+      seq->forward_ref->draw( seq->forward_ref, vd->stream );
+      //printf( "vdpau_mpeg12: drawn reference image with pts=%lld\n", seq->forward_ref->pts );
+    }
+    seq->backward_ref = img;
+  }
+  else {
+    img->pts = seq->seq_pts;
+    img->draw( img, vd->stream );
+    //printf( "vdpau_mpeg12: drawn image with pts=%lld\n", img->pts );
+    img->free( img );
+    //printf("vdpau_mpeg12: freed B image %d\n", img );
+  }
+  
+  seq->seq_pts +=seq->video_step;
+}
+    
+
+
+/*
+ * This function receives a buffer of data from the demuxer layer and
+ * figures out how to handle it based on its header flags.
+ */
+static void vdpau_mpeg12_decode_data (video_decoder_t *this_gen, buf_element_t *buf)
+{
+  vdpau_mpeg12_decoder_t *this = (vdpau_mpeg12_decoder_t *) this_gen;
+  sequence_t *seq = (sequence_t*)&this->sequence;
+
+  /* a video decoder does not care about this flag (?) */
+  if (buf->decoder_flags & BUF_FLAG_PREVIEW) {
+    return;
+  }
+
+  if (buf->decoder_flags & BUF_FLAG_FRAMERATE) {
+    //this->video_step = buf->decoder_info[0];
+    //_x_stream_info_set(this->stream, XINE_STREAM_INFO_FRAME_DURATION, this->video_step);
+  }
+  
+  if ( !buf->size )
+    return;
+  
+  seq->cur_pts = buf->pts;
+  //printf("vdpau_mpeg12_decode_data: new pts : %lld\n", buf->pts );
+
+  int size = seq->bufpos+buf->size;
+  if ( seq->bufsize < size ) {
+    seq->bufsize = size+1024;
+    seq->buf = realloc( seq->buf, seq->bufsize );
+    //printf("sequence buffer realloced = %d\n", seq->bufsize );
+  }        
+  xine_fast_memcpy( seq->buf+seq->bufpos, buf->content, buf->size );
+  seq->bufpos += buf->size;
+
+  while ( seq->bufseek < seq->bufpos-4 ) {
+    uint8_t *buf = seq->buf+seq->bufseek;
+    if ( buf[0]==0 && buf[1]==0 && buf[2]==1 ) {
+      if ( seq->start<0 ) {
+        seq->start = seq->bufseek;
+      }
+      else {
+        if ( parse_code( this, seq->buf+seq->start, seq->bufseek-seq->start ) ) {
+          decode_picture( this );
+          parse_code( this, seq->buf+seq->start, seq->bufseek-seq->start );
+        }
+        uint8_t *tmp = (uint8_t*)malloc(seq->bufsize);
+        xine_fast_memcpy( tmp, seq->buf+seq->bufseek, seq->bufpos-seq->bufseek );
+        seq->bufpos -= seq->bufseek;
+        seq->start = -1;
+        seq->bufseek = -1;
+        free( seq->buf );
+        seq->buf = tmp;
+      }
+    }
+    ++seq->bufseek;
+  }
+
+}
+
+/*
+ * This function is called when xine needs to flush the system.
+ */
+static void vdpau_mpeg12_flush (video_decoder_t *this_gen) {
+  vdpau_mpeg12_decoder_t *this = (vdpau_mpeg12_decoder_t *) this_gen;
+  
+  printf( "vdpau_mpeg12: vdpau_mpeg12_flush\n" );
+  reset_sequence( &this->sequence );
+}
+
+/*
+ * This function resets the video decoder.
+ */
+static void vdpau_mpeg12_reset (video_decoder_t *this_gen) {
+  vdpau_mpeg12_decoder_t *this = (vdpau_mpeg12_decoder_t *) this_gen;
+  
+  printf( "vdpau_mpeg12: vdpau_mpeg12_reset\n" );
+  reset_sequence( &this->sequence );
+
+  //this->size = 0;
+}
+
+/*
+ * The decoder should forget any stored pts values here.
+ */
+static void vdpau_mpeg12_discontinuity (video_decoder_t *this_gen) {
+  vdpau_mpeg12_decoder_t *this = (vdpau_mpeg12_decoder_t *) this_gen;
+  
+  printf( "vdpau_mpeg12: vdpau_mpeg12_discontinuity\n" );
+  reset_sequence( &this->sequence );
+
+}
+
+/*
+ * This function frees the video decoder instance allocated to the decoder.
+ */
+static void vdpau_mpeg12_dispose (video_decoder_t *this_gen) {
+
+  vdpau_mpeg12_decoder_t *this = (vdpau_mpeg12_decoder_t *) this_gen;
+  
+  printf( "vdpau_mpeg12: vdpau_mpeg12_dispose\n" );
+  
+  if ( this->decoder!=VDP_INVALID_HANDLE && this->sequence.accel_vdpau ) {
+      this->sequence.accel_vdpau->vdp_decoder_destroy( this->decoder );
+      this->decoder = VDP_INVALID_HANDLE;
+    }
+    
+  reset_sequence( &this->sequence );
+  
+  this->stream->video_out->close( this->stream->video_out, this->stream );
+
+  free( this->sequence.picture.slices );
+  free( this->sequence.buf );
+  free( this_gen );
+}
+
+/*
+ * This function allocates, initializes, and returns a private video
+ * decoder structure.
+ */
+static video_decoder_t *open_plugin (video_decoder_class_t *class_gen, xine_stream_t *stream) {
+
+  vdpau_mpeg12_decoder_t  *this ;
+
+  /* the videoout must be vdpau-capable to support this decoder */
+  if ( !(stream->video_driver->get_capabilities(stream->video_driver) & VO_CAP_VDPAU_MPEG12) )
+    return NULL;
+  
+  printf( "vdpau_mpeg12: open_plugin\n" );
+  
+  this = (vdpau_mpeg12_decoder_t *) calloc(1, sizeof(vdpau_mpeg12_decoder_t));
+
+  this->video_decoder.decode_data         = vdpau_mpeg12_decode_data;
+  this->video_decoder.flush               = vdpau_mpeg12_flush;
+  this->video_decoder.reset               = vdpau_mpeg12_reset;
+  this->video_decoder.discontinuity       = vdpau_mpeg12_discontinuity;
+  this->video_decoder.dispose             = vdpau_mpeg12_dispose;
+
+  this->stream                            = stream;
+  this->class                             = (vdpau_mpeg12_class_t *) class_gen;
+
+  this->sequence.bufsize = 1024;
+  this->sequence.buf = (uint8_t*)malloc(this->sequence.bufsize);
+  this->sequence.forward_ref = 0;
+  this->sequence.backward_ref = 0;
+  reset_sequence( &this->sequence );
+  
+  init_picture( &this->sequence.picture );
+  
+  this->decoder = VDP_INVALID_HANDLE;
+  this->sequence.accel_vdpau = NULL;
+  
+  (stream->video_out->open)(stream->video_out, stream);
+
+  return &this->video_decoder;
+}
+
+/*
+ * This function returns a brief string that describes (usually with the
+ * decoder's most basic name) the video decoder plugin.
+ */
+static char *get_identifier (video_decoder_class_t *this) {
+  return "vdpau_mpeg12";
+}
+
+/*
+ * This function returns a slightly longer string describing the video
+ * decoder plugin.
+ */
+static char *get_description (video_decoder_class_t *this) {
+  return "vdpau_mpeg12: mpeg1/2 decoder plugin using VDPAU hardware decoding.\n"
+    "Must be used along with video_out_vdpau.";
+}
+
+/*
+ * This function frees the video decoder class and any other memory that was
+ * allocated.
+ */
+static void dispose_class (video_decoder_class_t *this) {
+  free (this);
+}
+
+/*
+ * This function allocates a private video decoder class and initializes
+ * the class's member functions.
+ */
+static void *init_plugin (xine_t *xine, void *data) {
+
+  vdpau_mpeg12_class_t *this;
+
+  this = (vdpau_mpeg12_class_t *) calloc(1, sizeof(vdpau_mpeg12_class_t));
+
+  this->decoder_class.open_plugin     = open_plugin;
+  this->decoder_class.get_identifier  = get_identifier;
+  this->decoder_class.get_description = get_description;
+  this->decoder_class.dispose         = dispose_class;
+
+  return this;
+}
+
+/*
+ * This is a list of all of the internal xine video buffer types that
+ * this decoder is able to handle. Check src/xine-engine/buffer.h for a
+ * list of valid buffer types (and add a new one if the one you need does
+ * not exist). Terminate the list with a 0.
+ */
+static const uint32_t video_types[] = { 
+  BUF_VIDEO_MPEG,
+  0
+};
+
+/*
+ * This data structure combines the list of supported xine buffer types and
+ * the priority that the plugin should be given with respect to other
+ * plugins that handle the same buffer type. A plugin with priority (n+1)
+ * will be used instead of a plugin with priority (n).
+ */
+static const decoder_info_t dec_info_video = {
+  video_types,         /* supported types */
+  8                    /* priority        */
+};
+
+/*
+ * The plugin catalog entry. This is the only information that this plugin
+ * will export to the public.
+ */
+const plugin_info_t xine_plugin_info[] EXPORTED = {
+  /* { type, API, "name", version, special_info, init_function } */
+  { PLUGIN_VIDEO_DECODER, 18, "vdpau_mpeg12", XINE_VERSION_CODE, &dec_info_video, init_plugin },
+  { PLUGIN_NONE, 0, "", 0, NULL, NULL }
+};
diff -Naur xine-lib-1.1.15-old/src/Makefile.am xine-lib-1.1.15-new/src/Makefile.am
--- xine-lib-1.1.15-old/src/Makefile.am	2008-04-17 09:54:28.000000000 -0700
+++ xine-lib-1.1.15-new/src/Makefile.am	2008-12-22 09:11:43.000000000 -0800
@@ -25,5 +25,6 @@
 	libreal \
 	libfaad \
         libmusepack \
+    libvdpau \
 	post \
 	combined
diff -Naur xine-lib-1.1.15-old/src/video_out/Makefile.am xine-lib-1.1.15-new/src/video_out/Makefile.am
--- xine-lib-1.1.15-old/src/video_out/Makefile.am	2008-06-25 06:04:09.000000000 -0700
+++ xine-lib-1.1.15-new/src/video_out/Makefile.am	2008-12-22 09:11:43.000000000 -0800
@@ -36,6 +36,10 @@
 endif
 endif
 
+if HAVE_VDPAU
+vdpau_module = xineplug_vo_out_vdpau.la
+endif
+
 if HAVE_XCB
 XCBOSD = xcbosd.c
 if HAVE_XCBSHM
@@ -100,9 +104,14 @@
 		  $(xxmc_module) \
 		  $(xcbshm_module) \
 		  $(xcbxv_module) \
+      $(vdpau_module) \
                   xineplug_vo_out_raw.la \
                   xineplug_vo_out_none.la
 
+xineplug_vo_out_vdpau_la_SOURCES = yuv2rgb.c yuv2rgb_mmx.c yuv2rgb_mlib.c video_out_vdpau.c
+xineplug_vo_out_vdpau_la_LIBADD = $(XINE_LIB) $(MLIB_LIBS) $(PTHREAD_LIBS) $(X_LIBS) $(LTLIBINTL) -lvdpau
+xineplug_vo_out_vdpau_la_CFLAGS = $(VISIBILITY_FLAG) $(MLIB_CFLAGS) $(X_CFLAGS)
+
 xineplug_vo_out_xcbshm_la_SOURCES = yuv2rgb.c yuv2rgb_mmx.c yuv2rgb_mlib.c video_out_xcbshm.c $(XCBOSD)
 xineplug_vo_out_xcbshm_la_LIBADD = $(XINE_LIB) $(MLIB_LIBS) $(PTHREAD_LIBS) $(XCB_LIBS) $(XCBSHM_LIBS) $(LTLIBINTL)
 xineplug_vo_out_xcbshm_la_CFLAGS = $(VISIBILITY_FLAG) $(MLIB_CFLAGS) $(XCB_CFLAGS) $(XCBSHM_CFLAGS)
diff -Naur xine-lib-1.1.15-old/src/video_out/video_out_raw.c xine-lib-1.1.15-new/src/video_out/video_out_raw.c
--- xine-lib-1.1.15-old/src/video_out/video_out_raw.c	2008-06-14 16:15:00.000000000 -0700
+++ xine-lib-1.1.15-new/src/video_out/video_out_raw.c	2008-12-22 09:11:43.000000000 -0800
@@ -278,10 +278,14 @@
 
   frame->yuv2rgb->dispose (frame->yuv2rgb);
 
-  free (frame->chunk[0]);
-  free (frame->chunk[1]);
-  free (frame->chunk[2]);
-  free (frame->chunk[3]);
+  if ( frame->chunk[0] )
+    free (frame->chunk[0]);
+  if ( frame->chunk[1] )
+    free (frame->chunk[1]);
+  if ( frame->chunk[2] )
+    free (frame->chunk[2]);
+  if ( frame->chunk[3] )
+    free (frame->chunk[3]);
   free (frame);
 }
 
@@ -296,6 +300,9 @@
 
   if (!frame)
     return NULL;
+  
+  frame->chunk[0] = frame->chunk[1] = frame->chunk[2] = frame->chunk[3] = NULL;
+  frame->width = frame->height = frame->format = frame->flags = 0;
 
   pthread_mutex_init (&frame->vo_frame.mutex, NULL);
 
@@ -330,13 +337,16 @@
       || (frame->flags  != flags)) {
 /*     lprintf ("updating frame to %d x %d (ratio=%g, format=%08x)\n", width, height, ratio, format); */
 
-    flags &= VO_BOTH_FIELDS;
-
     /* (re-) allocate render space */
-    free (frame->chunk[0]);
-    free (frame->chunk[1]);
-    free (frame->chunk[2]);
-    free (frame->chunk[3]);
+    if ( frame->chunk[0] )
+      free (frame->chunk[0]);
+    if ( frame->chunk[1] )
+      free (frame->chunk[1]);
+    if ( frame->chunk[2] )
+      free (frame->chunk[2]);
+    if ( frame->chunk[3] )
+      free (frame->chunk[3]);
+    frame->chunk[0] = frame->chunk[1] = frame->chunk[2] = frame->chunk[3] = NULL;   
 
     if (format == XINE_IMGFMT_YV12) {
       frame->vo_frame.pitches[0] = 8*((width + 7) / 8);
@@ -355,7 +365,7 @@
 				       (void **) &frame->chunk[3]);
 
     /* set up colorspace converter */
-    switch (flags) {
+    switch (flags & VO_BOTH_FIELDS) {
     case VO_TOP_FIELD:
     case VO_BOTTOM_FIELD:
       frame->yuv2rgb->configure (frame->yuv2rgb,
@@ -382,6 +392,7 @@
     frame->width = width;
     frame->height = height;
     frame->format = format;
+    frame->flags = flags;
 
     raw_frame_field ((vo_frame_t *)frame, flags);
   }
diff -Naur xine-lib-1.1.15-old/src/video_out/video_out_vdpau.c xine-lib-1.1.15-new/src/video_out/video_out_vdpau.c
--- xine-lib-1.1.15-old/src/video_out/video_out_vdpau.c	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/video_out/video_out_vdpau.c	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,1343 @@
+/*
+ * Copyright (C) 2008 Christophe Thommeret <hftom@free.fr>
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA
+ *
+ *
+ * video_out_vdpau.c, a video output plugin using VDPAU (Video Decode and Presentation Api for Unix)
+ *
+ *
+ */
+
+/* #define LOG */
+#define LOG_MODULE "video_out_vdpau"
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <string.h>
+#include <math.h>
+#include <errno.h>
+#include <ctype.h>
+#include <pthread.h>
+
+#include "xine.h"
+#include "video_out.h"
+#include "vo_scale.h"
+#include "xine_internal.h"
+#include "yuv2rgb.h"
+#include "xineutils.h"
+
+#include <vdpau/vdpau_x11.h>
+#include "accel_vdpau.h"
+
+#define NUM_FRAMES_BACK 1
+
+
+VdpOutputSurfaceRenderBlendState blend = { VDP_OUTPUT_SURFACE_RENDER_BLEND_STATE_VERSION,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_FACTOR_ONE ,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_FACTOR_ONE_MINUS_SRC_COLOR,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_FACTOR_ONE,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_EQUATION_ADD,
+          VDP_OUTPUT_SURFACE_RENDER_BLEND_EQUATION_ADD };
+
+
+
+VdpDevice vdp_device;
+VdpPresentationQueue vdp_queue;
+VdpPresentationQueueTarget vdp_queue_target;
+
+VdpGetProcAddress *vdp_get_proc_address;
+
+VdpGetApiVersion *vdp_get_api_version;
+VdpGetInformationString *vdp_get_information_string;
+VdpGetErrorString *vdp_get_error_string;
+
+VdpVideoSurfaceQueryGetPutBitsYCbCrCapabilities *vdp_video_surface_query_get_put_bits_ycbcr_capabilities;
+VdpVideoSurfaceCreate *vdp_video_surface_create;
+VdpVideoSurfaceDestroy *vdp_video_surface_destroy;
+VdpVideoSurfacePutBitsYCbCr *vdp_video_surface_putbits_ycbcr;
+VdpVideoSurfaceGetBitsYCbCr *vdp_video_surface_getbits_ycbcr;
+
+VdpOutputSurfaceCreate *vdp_output_surface_create;
+VdpOutputSurfaceDestroy *vdp_output_surface_destroy;
+VdpOutputSurfaceRenderBitmapSurface *vdp_output_surface_render_bitmap_surface;
+VdpOutputSurfacePutBitsNative *vdp_output_surface_put_bits;
+
+VdpVideoMixerCreate *vdp_video_mixer_create;
+VdpVideoMixerDestroy *vdp_video_mixer_destroy;
+VdpVideoMixerRender *vdp_video_mixer_render;
+VdpVideoMixerSetAttributeValues *vdp_video_mixer_set_attribute_values;
+
+VdpGenerateCSCMatrix *vdp_generate_csc_matrix;
+
+VdpPresentationQueueTargetCreateX11 *vdp_queue_target_create_x11;
+VdpPresentationQueueTargetDestroy *vdp_queue_target_destroy;
+VdpPresentationQueueCreate *vdp_queue_create;
+VdpPresentationQueueDestroy *vdp_queue_destroy;
+VdpPresentationQueueDisplay *vdp_queue_display;
+VdpPresentationQueueBlockUntilSurfaceIdle *vdp_queue_block;
+VdpPresentationQueueSetBackgroundColor *vdp_queue_set_backgroung_color;
+VdpPresentationQueueGetTime *vdp_queue_get_time;
+
+VdpBitmapSurfacePutBitsNative *vdp_bitmap_put_bits;
+VdpBitmapSurfaceCreate  *vdp_bitmap_create;
+VdpBitmapSurfaceDestroy *vdp_bitmap_destroy;
+
+VdpDecoderQueryCapabilities *vdp_decoder_query_capabilities;
+VdpDecoderCreate *vdp_decoder_create;
+VdpDecoderDestroy *vdp_decoder_destroy;
+VdpDecoderRender *vdp_decoder_render;
+
+
+
+typedef struct {
+  VdpBitmapSurface ovl_bitmap;
+  uint32_t  bitmap_width, bitmap_height;
+  int ovl_w, ovl_h; /* overlay's width and height */
+  int ovl_x, ovl_y; /* overlay's top-left display position */
+  int unscaled;
+} vdpau_overlay_t;
+
+
+typedef struct {
+  vo_frame_t         vo_frame;
+
+  int                width, height, format, flags;
+  double             ratio;
+  uint8_t           *chunk[3]; /* mem alloc by xmalloc_aligned           */
+
+  vdpau_accel_t     vdpau_accel_data;
+} vdpau_frame_t;
+
+
+typedef struct {
+  vo_driver_t        vo_driver;
+  vo_scale_t         sc;
+  
+  Display           *display;
+  int                screen;
+  Drawable           drawable;
+
+  config_values_t   *config;
+
+  int ovl_changed;
+  vdpau_overlay_t     overlays[XINE_VORAW_MAX_OVL];
+  yuv2rgb_factory_t   *yuv2rgb_factory;
+  yuv2rgb_t           *ovl_yuv2rgb;
+  VdpOutputSurface    overlay_output;
+  uint32_t            overlay_output_width;
+  uint32_t            overlay_output_height;
+  int                 has_overlay;
+  
+  VdpOutputSurface    overlay_unscaled;
+  uint32_t            overlay_unscaled_width;
+  uint32_t            overlay_unscaled_height;
+  int                 has_unscaled;
+  
+  VdpVideoSurface soft_surface;
+  uint32_t             soft_surface_width;
+  uint32_t             soft_surface_height;
+  int                  soft_surface_format;
+  
+  VdpOutputSurface output_surface[2];
+  uint8_t             current_output_surface;
+  uint32_t             output_surface_width[2];
+  uint32_t             output_surface_height[2];
+  uint8_t              init_queue;
+  
+  VdpVideoMixer        video_mixer;
+  VdpChromaType        video_mixer_chroma;
+  uint32_t             video_mixer_width;
+  uint32_t             video_mixer_height;
+  
+  vdpau_frame_t        *back_frame[ NUM_FRAMES_BACK ];
+
+  uint32_t          capabilities;
+  xine_t            *xine;
+  
+  int               hue;
+  int               saturation;
+  int               brightness;
+  int               contrast;
+  
+  int               allocated_surfaces;
+
+} vdpau_driver_t;
+
+
+typedef struct {
+  video_driver_class_t driver_class;
+  xine_t              *xine;
+} vdpau_class_t;
+
+
+
+static void vdpau_overlay_clut_yuv2rgb(vdpau_driver_t  *this, vo_overlay_t *overlay, vdpau_frame_t *frame)
+{
+  int i;
+  clut_t* clut = (clut_t*) overlay->color;
+
+  if (!overlay->rgb_clut) {
+    for ( i=0; i<sizeof(overlay->color)/sizeof(overlay->color[0]); i++ ) {
+      *((uint32_t *)&clut[i]) = this->ovl_yuv2rgb->yuv2rgb_single_pixel_fun(this->ovl_yuv2rgb, clut[i].y, clut[i].cb, clut[i].cr);
+    }
+    overlay->rgb_clut++;
+  }
+  if (!overlay->hili_rgb_clut) {
+    clut = (clut_t*) overlay->hili_color;
+    for ( i=0; i<sizeof(overlay->color)/sizeof(overlay->color[0]); i++) {
+      *((uint32_t *)&clut[i]) = this->ovl_yuv2rgb->yuv2rgb_single_pixel_fun(this->ovl_yuv2rgb, clut[i].y, clut[i].cb, clut[i].cr);
+    }
+    overlay->hili_rgb_clut++;
+  }
+}
+
+
+
+static int vdpau_process_ovl( vdpau_driver_t *this_gen, vo_overlay_t *overlay )
+{
+  vdpau_overlay_t *ovl = &this_gen->overlays[this_gen->ovl_changed-1];
+
+  if ( overlay->width<=0 || overlay->height<=0 )
+    return 0;
+
+  if ( (ovl->bitmap_width < overlay->width ) || (ovl->bitmap_height < overlay->height) || (ovl->ovl_bitmap == VDP_INVALID_HANDLE) ) {
+    if (ovl->ovl_bitmap != VDP_INVALID_HANDLE) {
+      vdp_bitmap_destroy( ovl->ovl_bitmap );
+    }
+    VdpStatus st = vdp_bitmap_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, overlay->width, overlay->height, 0, &ovl->ovl_bitmap );
+    if ( st != VDP_STATUS_OK ) {
+      printf( "vdpau_process_ovl: vdp_bitmap_create failed : %s\n", vdp_get_error_string(st) );
+    }
+    ovl->bitmap_width = overlay->width;
+    ovl->bitmap_height = overlay->height;
+  }
+  ovl->ovl_w = overlay->width;
+  ovl->ovl_h = overlay->height;
+  ovl->ovl_x = overlay->x;
+  ovl->ovl_y = overlay->y;
+  ovl->unscaled = overlay->unscaled;
+  uint32_t *buf = (uint32_t*)malloc(ovl->ovl_w*ovl->ovl_h*4);
+  if ( !buf )
+    return 0;
+
+  int num_rle = overlay->num_rle;
+  rle_elem_t *rle = overlay->rle;
+  uint32_t *rgba = buf;
+  uint32_t red, green, blue, alpha;
+  clut_t *low_colors = (clut_t*)overlay->color;
+  clut_t *hili_colors = (clut_t*)overlay->hili_color;
+  uint8_t *low_trans = overlay->trans;
+  uint8_t *hili_trans = overlay->hili_trans;
+  clut_t *colors;
+  uint8_t *trans;
+  int rlelen = 0;
+  uint8_t clr = 0;
+  int i, pos=0, x, y;
+
+  while ( num_rle>0 ) {
+    x = pos%ovl->ovl_w;
+    y = pos/ovl->ovl_w;
+    if ( (x>=overlay->hili_left && x<=overlay->hili_right) && (y>=overlay->hili_top && y<=overlay->hili_bottom) ) {
+      colors = hili_colors;
+      trans = hili_trans;
+    }
+    else {
+      colors = low_colors;
+      trans = low_trans;
+    }
+    rlelen = rle->len;
+    clr = rle->color;
+    for ( i=0; i<rlelen; ++i ) {
+      red = colors[clr].y; /* red */
+      green = colors[clr].cr; /* green */
+      blue = colors[clr].cb; /* blue */
+      alpha = trans[clr]*255/15;
+      *rgba = (alpha<<24) | (red<<16) | (green<<8) | blue;
+      rgba++;
+      ++pos;
+    }
+    ++rle;
+    --num_rle;
+  }
+  uint32_t pitch = ovl->ovl_w*4;
+  VdpRect dest = { 0, 0, ovl->ovl_w, ovl->ovl_h };
+  VdpStatus st = vdp_bitmap_put_bits( ovl->ovl_bitmap, &buf, &pitch, &dest);
+  if ( st != VDP_STATUS_OK ) {
+    printf( "vdpau_process_ovl: vdp_bitmap_put_bits failed : %s\n", vdp_get_error_string(st) );
+  }
+  free(buf);
+  return 1;
+}
+
+
+static void vdpau_overlay_begin (vo_driver_t *this_gen, vo_frame_t *frame_gen, int changed)
+{
+  vdpau_driver_t  *this = (vdpau_driver_t *) this_gen;
+
+  if ( !changed )
+    return;
+
+  ++this->ovl_changed;
+}
+
+
+static void vdpau_overlay_blend (vo_driver_t *this_gen, vo_frame_t *frame_gen, vo_overlay_t *overlay)
+{
+  vdpau_driver_t  *this = (vdpau_driver_t *) this_gen;
+  vdpau_frame_t *frame = (vdpau_frame_t *) frame_gen;
+
+  if ( !this->ovl_changed || this->ovl_changed>XINE_VORAW_MAX_OVL )
+    return;
+
+  if (overlay->rle) {
+    if (!overlay->rgb_clut || !overlay->hili_rgb_clut)
+      vdpau_overlay_clut_yuv2rgb (this, overlay, frame);
+    if ( vdpau_process_ovl( this, overlay ) )
+      ++this->ovl_changed;
+  }
+}
+
+
+static void vdpau_overlay_end (vo_driver_t *this_gen, vo_frame_t *frame)
+{
+  vdpau_driver_t  *this = (vdpau_driver_t *) this_gen;
+  int i;
+  VdpStatus st;
+
+  if ( !this->ovl_changed )
+    return;
+  
+  if ( !(this->ovl_changed-1) ) {
+    this->ovl_changed = 0;
+    this->has_overlay = 0;
+    return;
+  }
+
+  int w=0, h=0;
+  for ( i=0; i<this->ovl_changed-1; ++i ) {
+    if ( this->overlays[i].unscaled )
+      continue;
+    if ( w < (this->overlays[i].ovl_x+this->overlays[i].ovl_w) )
+      w = this->overlays[i].ovl_x+this->overlays[i].ovl_w;
+    if ( h < (this->overlays[i].ovl_y+this->overlays[i].ovl_h) )
+      h = this->overlays[i].ovl_y+this->overlays[i].ovl_h;
+  }
+
+  int out_w = (w>frame->width) ? w : frame->width;
+  int out_h = (h>frame->height) ? h : frame->height;
+  
+  if ( (this->overlay_output_width!=out_w || this->overlay_output_height!=out_h) && this->overlay_output != VDP_INVALID_HANDLE ) {
+    st = vdp_output_surface_destroy( this->overlay_output );
+    if ( st != VDP_STATUS_OK ) {
+      printf( "vdpau_overlay_end: vdp_output_surface_destroy failed : %s\n", vdp_get_error_string(st) );
+    }
+    this->overlay_output = VDP_INVALID_HANDLE;
+  }
+  
+  this->overlay_output_width = out_w;
+  this->overlay_output_height = out_h;
+  
+  w = 64; h = 64;
+  for ( i=0; i<this->ovl_changed-1; ++i ) {
+    if ( !this->overlays[i].unscaled )
+      continue;
+    if ( w < (this->overlays[i].ovl_x+this->overlays[i].ovl_w) )
+      w = this->overlays[i].ovl_x+this->overlays[i].ovl_w;
+    if ( h < (this->overlays[i].ovl_y+this->overlays[i].ovl_h) )
+      h = this->overlays[i].ovl_y+this->overlays[i].ovl_h;
+  }
+
+  if ( (this->overlay_unscaled_width!=w || this->overlay_unscaled_height!=h) && this->overlay_unscaled != VDP_INVALID_HANDLE ) {
+    st = vdp_output_surface_destroy( this->overlay_unscaled );
+    if ( st != VDP_STATUS_OK ) {
+      printf( "vdpau_overlay_end: vdp_output_surface_destroy failed : %s\n", vdp_get_error_string(st) );
+    }
+    this->overlay_unscaled = VDP_INVALID_HANDLE;
+  }
+
+  this->overlay_unscaled_width = w;
+  this->overlay_unscaled_height = h;
+  
+  if ( this->overlay_unscaled == VDP_INVALID_HANDLE ) {
+    st = vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->overlay_unscaled_width, this->overlay_unscaled_height, &this->overlay_unscaled );
+    if ( st != VDP_STATUS_OK )
+      printf( "vdpau_overlay_end: vdp_output_surface_create failed : %s\n", vdp_get_error_string(st) );
+  }
+  
+  if ( this->overlay_output == VDP_INVALID_HANDLE ) {
+    st = vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->overlay_output_width, this->overlay_output_height, &this->overlay_output );
+    if ( st != VDP_STATUS_OK )
+      printf( "vdpau_overlay_end: vdp_output_surface_create failed : %s\n", vdp_get_error_string(st) );
+  }
+  
+  w = (this->overlay_unscaled_width>this->overlay_output_width) ? this->overlay_unscaled_width : this->overlay_output_width;
+  h = (this->overlay_unscaled_height>this->overlay_output_height) ? this->overlay_unscaled_height : this->overlay_output_height;
+  
+  uint32_t *buf = (uint32_t*)malloc(w*h*4);
+  uint32_t pitch = w*4;
+  memset( buf, 0, w*h*4 );
+  VdpRect clear = { 0, 0, this->overlay_output_width, this->overlay_output_height };
+  st = vdp_output_surface_put_bits( this->overlay_output, &buf, &pitch, &clear );
+  if ( st != VDP_STATUS_OK ) {
+    printf( "vdpau_overlay_end: vdp_output_surface_put_bits (clear) failed : %s\n", vdp_get_error_string(st) );
+  }
+  clear.x1 = this->overlay_unscaled_width; clear.y1 = this->overlay_unscaled_height;
+  st = vdp_output_surface_put_bits( this->overlay_unscaled, &buf, &pitch, &clear );
+  if ( st != VDP_STATUS_OK ) {
+    printf( "vdpau_overlay_end: vdp_output_surface_put_bits (clear) failed : %s\n", vdp_get_error_string(st) );
+  }
+  free(buf);
+    
+  VdpOutputSurface *surface;
+  for ( i=0; i<this->ovl_changed-1; ++i ) {
+    VdpRect dest = { this->overlays[i].ovl_x, this->overlays[i].ovl_y, this->overlays[i].ovl_x+this->overlays[i].ovl_w, this->overlays[i].ovl_y+this->overlays[i].ovl_h };
+    VdpRect src = { 0, 0, this->overlays[i].ovl_w, this->overlays[i].ovl_h };
+    surface = (this->overlays[i].unscaled) ? &this->overlay_unscaled : &this->overlay_output;
+    st = vdp_output_surface_render_bitmap_surface( *surface, &dest, this->overlays[i].ovl_bitmap, &src, 0, &blend, 0 );
+    if ( st != VDP_STATUS_OK ) {
+      printf( "vdpau_overlay_end: vdp_output_surface_render_bitmap_surface failed : %s\n", vdp_get_error_string(st) );
+    }
+  }
+  this->has_overlay = 1;
+  this->ovl_changed = 0;
+}
+
+
+static void vdpau_frame_proc_slice (vo_frame_t *vo_img, uint8_t **src)
+{
+  vdpau_frame_t  *frame = (vdpau_frame_t *) vo_img ;
+
+  vo_img->proc_called = 1;
+}
+
+
+
+static void vdpau_frame_field (vo_frame_t *vo_img, int which_field)
+{
+}
+
+
+
+static void vdpau_frame_dispose (vo_frame_t *vo_img)
+{
+  vdpau_frame_t  *frame = (vdpau_frame_t *) vo_img ;
+
+  if ( frame->chunk[0] )
+    free (frame->chunk[0]);
+  if ( frame->chunk[1] )
+    free (frame->chunk[1]);
+  if ( frame->chunk[2] )
+    free (frame->chunk[2]);
+  if ( frame->vdpau_accel_data.surface != VDP_INVALID_HANDLE )
+    vdp_video_surface_destroy( frame->vdpau_accel_data.surface );
+  free (frame);
+}
+
+
+
+static vo_frame_t *vdpau_alloc_frame (vo_driver_t *this_gen)
+{
+  vdpau_frame_t  *frame;
+  vdpau_driver_t *this = (vdpau_driver_t *) this_gen;
+  
+  printf( "vo_vdpau: vdpau_alloc_frame\n" );
+
+  frame = (vdpau_frame_t *) calloc(1, sizeof(vdpau_frame_t));
+
+  if (!frame)
+    return NULL;
+  
+  frame->chunk[0] = frame->chunk[1] = frame->chunk[2] = NULL;
+  frame->width = frame->height = frame->format = frame->flags = 0;
+  
+  frame->vo_frame.accel_data = &frame->vdpau_accel_data;
+  
+  pthread_mutex_init (&frame->vo_frame.mutex, NULL);
+
+  /*
+   * supply required functions/fields
+   */
+  frame->vo_frame.proc_slice = vdpau_frame_proc_slice;
+  frame->vo_frame.proc_frame = NULL;
+  frame->vo_frame.field      = vdpau_frame_field;
+  frame->vo_frame.dispose    = vdpau_frame_dispose;
+  frame->vo_frame.driver     = this_gen;
+  
+  frame->vdpau_accel_data.vdp_device = vdp_device;
+  frame->vdpau_accel_data.surface = VDP_INVALID_HANDLE;
+  frame->vdpau_accel_data.chroma = VDP_CHROMA_TYPE_420;
+  frame->vdpau_accel_data.vdp_decoder_create = vdp_decoder_create;
+  frame->vdpau_accel_data.vdp_decoder_destroy = vdp_decoder_destroy;
+  frame->vdpau_accel_data.vdp_decoder_render = vdp_decoder_render;
+  frame->vdpau_accel_data.vdp_get_error_string = vdp_get_error_string;
+
+  return (vo_frame_t *) frame;
+}
+
+
+
+static void vdpau_update_frame_format (vo_driver_t *this_gen, vo_frame_t *frame_gen,
+      uint32_t width, uint32_t height, double ratio, int format, int flags)
+{
+  vdpau_driver_t *this = (vdpau_driver_t *) this_gen;
+  vdpau_frame_t   *frame = (vdpau_frame_t *) frame_gen;
+  
+  VdpChromaType chroma = (flags & VO_CHROMA_422) ? VDP_CHROMA_TYPE_422 : VDP_CHROMA_TYPE_420;
+
+  /* Check frame size and format and reallocate if necessary */
+  if ( (frame->width != width) || (frame->height != height) || (frame->format != format) || (frame->format==XINE_IMGFMT_VDPAU && frame->vdpau_accel_data.chroma!=chroma) ) {
+    //printf("vo_vdpau: updating frame to %d x %d (ratio=%g, format=%08X)\n", width, height, ratio, format);
+
+    /* (re-) allocate render space */
+    if ( frame->chunk[0] )
+      free (frame->chunk[0]);
+    if ( frame->chunk[1] )
+      free (frame->chunk[1]);
+    if ( frame->chunk[2] )
+      free (frame->chunk[2]);
+    frame->chunk[0] = frame->chunk[1] = frame->chunk[2] = NULL;    
+
+    if (format == XINE_IMGFMT_YV12) {
+      frame->vo_frame.pitches[0] = 8*((width + 7) / 8);
+      frame->vo_frame.pitches[1] = 8*((width + 15) / 16);
+      frame->vo_frame.pitches[2] = 8*((width + 15) / 16);
+      frame->vo_frame.base[0] = xine_xmalloc_aligned (16, frame->vo_frame.pitches[0] * height,  (void **) &frame->chunk[0]);
+      frame->vo_frame.base[1] = xine_xmalloc_aligned (16, frame->vo_frame.pitches[1] * ((height+1)/2), (void **) &frame->chunk[1]);
+      frame->vo_frame.base[2] = xine_xmalloc_aligned (16, frame->vo_frame.pitches[2] * ((height+1)/2), (void **) &frame->chunk[2]);
+    } else if (format == XINE_IMGFMT_YUY2){
+      frame->vo_frame.pitches[0] = 8*((width + 3) / 4);
+      frame->vo_frame.base[0] = xine_xmalloc_aligned (16, frame->vo_frame.pitches[0] * height, (void **) &frame->chunk[0]);
+      frame->chunk[1] = NULL;
+      frame->chunk[2] = NULL;
+    }
+
+    if ( frame->vdpau_accel_data.surface != VDP_INVALID_HANDLE  ) {
+      if ( (frame->width != width) || (frame->height != height) || (format != XINE_IMGFMT_VDPAU) || frame->vdpau_accel_data.chroma != chroma ) {
+        printf("vo_vdpau: update_frame - destroy surface\n");
+        vdp_video_surface_destroy( frame->vdpau_accel_data.surface );
+        frame->vdpau_accel_data.surface = VDP_INVALID_HANDLE;
+        --this->allocated_surfaces;
+      }
+    }
+
+    if ( (format == XINE_IMGFMT_VDPAU) && (frame->vdpau_accel_data.surface == VDP_INVALID_HANDLE) ) {
+      VdpStatus st = vdp_video_surface_create( vdp_device, chroma, width, height, &frame->vdpau_accel_data.surface );
+      if ( st!=VDP_STATUS_OK )
+        printf( "vo_vdpau: failed to create surface !! %s\n", vdp_get_error_string( st ) );
+      else {
+        frame->vdpau_accel_data.chroma = chroma;
+        ++this->allocated_surfaces;
+      }
+    }
+
+    frame->width = width;
+    frame->height = height;
+    frame->format = format;
+    frame->flags = flags;
+
+    vdpau_frame_field ((vo_frame_t *)frame, flags);
+  }
+  
+  //printf("vo_vdpau: allocated_surfaces=%d\n", this->allocated_surfaces );
+
+  frame->ratio = ratio;
+}
+
+
+
+static int vdpau_redraw_needed (vo_driver_t *this_gen)
+{
+  vdpau_driver_t  *this = (vdpau_driver_t *) this_gen;
+
+  _x_vo_scale_compute_ideal_size( &this->sc );
+  if ( _x_vo_scale_redraw_needed( &this->sc ) ) {
+    _x_vo_scale_compute_output_size( &this->sc );
+    return 1;
+  }
+  return 0;
+}
+
+
+
+static void vdpau_release_back_frames( vo_driver_t *this_gen )
+{
+  vdpau_driver_t  *this  = (vdpau_driver_t *) this_gen;
+  int i;
+  
+  for ( i=0; i<NUM_FRAMES_BACK; ++i ) {
+    if ( this->back_frame[ i ])
+      this->back_frame[ i ]->vo_frame.free( &this->back_frame[ i ]->vo_frame );
+    this->back_frame[ i ] = NULL;
+  }
+}
+  
+
+
+static void vdpau_display_frame (vo_driver_t *this_gen, vo_frame_t *frame_gen)
+{
+  vdpau_driver_t  *this  = (vdpau_driver_t *) this_gen;
+  vdpau_frame_t   *frame = (vdpau_frame_t *) frame_gen;
+  VdpStatus st;
+  VdpVideoSurface surface;
+  VdpChromaType chroma = this->video_mixer_chroma;
+  uint32_t mix_w = this->video_mixer_width;
+  uint32_t mix_h = this->video_mixer_height;
+
+  if ( (frame->width != this->sc.delivered_width) || (frame->height != this->sc.delivered_height) || (frame->ratio != this->sc.delivered_ratio) ) {
+    this->sc.force_redraw = 1;    /* trigger re-calc of output size */
+  }
+  
+  this->sc.delivered_height = frame->height;
+  this->sc.delivered_width  = frame->width;
+  this->sc.delivered_ratio  = frame->ratio;
+  this->sc.crop_left        = frame->vo_frame.crop_left;
+  this->sc.crop_right       = frame->vo_frame.crop_right;
+  this->sc.crop_top         = frame->vo_frame.crop_top;
+  this->sc.crop_bottom      = frame->vo_frame.crop_bottom;
+  
+  vdpau_redraw_needed( this_gen );
+
+  if ( (frame->format == XINE_IMGFMT_YV12) || (frame->format == XINE_IMGFMT_YUY2) ) {
+    //printf( "vo_vdpau: got a yuv image -------------\n" );
+    chroma = ( frame->format==XINE_IMGFMT_YV12 )? VDP_CHROMA_TYPE_420 : VDP_CHROMA_TYPE_422;
+    if ( (frame->width > this->soft_surface_width) || (frame->height > this->soft_surface_height) || (frame->format != this->soft_surface_format) ) {
+      printf( "vo_vdpau: soft_surface size update\n" );
+      /* recreate surface to match frame changes */
+      this->soft_surface_width = frame->width;
+      this->soft_surface_height = frame->height;
+      this->soft_surface_format = frame->format;
+      vdp_video_surface_destroy( this->soft_surface );
+      vdp_video_surface_create( vdp_device, chroma, this->soft_surface_width, this->soft_surface_height, &this->soft_surface );
+    }
+    /* FIXME: have to swap U and V planes to get correct colors !! */
+    uint32_t pitches[] = { frame->vo_frame.pitches[0], frame->vo_frame.pitches[2], frame->vo_frame.pitches[1] };
+    void* data[] = { frame->vo_frame.base[0], frame->vo_frame.base[2], frame->vo_frame.base[1] };
+    if ( frame->format==XINE_IMGFMT_YV12 ) {
+      st = vdp_video_surface_putbits_ycbcr( this->soft_surface, VDP_YCBCR_FORMAT_YV12, &data, pitches );
+      if ( st != VDP_STATUS_OK )
+        printf( "vo_vdpau: vdp_video_surface_putbits_ycbcr YV12 error : %s\n", vdp_get_error_string( st ) );
+    }
+    else {
+      st = vdp_video_surface_putbits_ycbcr( this->soft_surface, VDP_YCBCR_FORMAT_YUYV, &data, pitches );
+      if ( st != VDP_STATUS_OK )
+        printf( "vo_vdpau: vdp_video_surface_putbits_ycbcr YUY2 error : %s\n", vdp_get_error_string( st ) );
+    }
+    surface = this->soft_surface;
+    mix_w = this->soft_surface_width;
+    mix_h = this->soft_surface_height;
+  }
+  else if (frame->format == XINE_IMGFMT_VDPAU) {
+    //printf( "vo_vdpau: got a vdpau image -------------\n" );
+    surface = frame->vdpau_accel_data.surface;
+    mix_w = frame->width;
+    mix_h = frame->height;
+    chroma = (frame->vo_frame.flags & VO_CHROMA_422) ? VDP_CHROMA_TYPE_422 : VDP_CHROMA_TYPE_420;
+  }
+  else {
+    /* unknown format */
+    printf( "vo_vdpau: got an unknown image -------------\n" );
+    frame->vo_frame.free( &frame->vo_frame );
+    return;
+  }
+
+  if ( (mix_w != this->video_mixer_width) || (mix_h != this->video_mixer_height) || (chroma != this->video_mixer_chroma) ) {
+    vdpau_release_back_frames( this_gen ); /* empty past frames array */
+    printf("vo_vdpau: recreate mixer to match frames: width=%d, height=%d, chroma=%d\n", mix_w, mix_h, chroma);
+    vdp_video_mixer_destroy( this->video_mixer );
+    VdpVideoMixerFeature features[] = { VDP_VIDEO_MIXER_FEATURE_DEINTERLACE_TEMPORAL, VDP_VIDEO_MIXER_FEATURE_DEINTERLACE_TEMPORAL_SPATIAL };
+    VdpVideoMixerParameter params[] = { VDP_VIDEO_MIXER_PARAMETER_VIDEO_SURFACE_WIDTH, VDP_VIDEO_MIXER_PARAMETER_VIDEO_SURFACE_HEIGHT, VDP_VIDEO_MIXER_PARAMETER_CHROMA_TYPE, VDP_VIDEO_MIXER_PARAMETER_LAYERS };
+    int num_layers = 2;
+    void const *param_values[] = { &mix_w, &mix_h, &chroma, &num_layers };
+    vdp_video_mixer_create( vdp_device, 2, features, 4, params, param_values, &this->video_mixer );
+    this->video_mixer_chroma = chroma;
+    this->video_mixer_width = mix_w;
+    this->video_mixer_height = mix_h;
+  }
+  
+  if ( (this->sc.gui_width > this->output_surface_width[this->current_output_surface]) || (this->sc.gui_height > this->output_surface_height[this->current_output_surface]) ) {
+    /* recreate output surface to match window size */
+    printf( "vo_vdpau: output_surface size update\n" );
+    this->output_surface_width[this->current_output_surface] = this->sc.gui_width;
+    this->output_surface_height[this->current_output_surface] = this->sc.gui_height;
+
+    vdp_output_surface_destroy( this->output_surface[this->current_output_surface] );
+    vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->output_surface_width[this->current_output_surface], this->output_surface_height[this->current_output_surface], &this->output_surface[this->current_output_surface] );
+  }
+
+  VdpRect vid_source = { this->sc.crop_left, this->sc.crop_top, this->sc.delivered_width-this->sc.crop_right, this->sc.delivered_height-this->sc.crop_bottom };
+  VdpRect out_dest = { 0, 0, this->sc.gui_width, this->sc.gui_height };
+  VdpRect vid_dest = { this->sc.output_xoffset, this->sc.output_yoffset, this->sc.output_xoffset+this->sc.output_width, this->sc.output_yoffset+this->sc.output_height };
+  
+  //printf( "out_dest = %d %d %d %d - vid_dest = %d %d %d %d\n", out_dest.x0, out_dest.y0, out_dest.x1, out_dest.y1, vid_dest.x0, vid_dest.y0, vid_dest.x1, vid_dest.y1 );
+
+  XLockDisplay( this->display );
+  
+  VdpTime last_time;
+  
+  if ( this->init_queue>1 )
+    vdp_queue_block( vdp_queue, this->output_surface[this->current_output_surface], &last_time );
+
+  uint32_t layer_count;
+  VdpLayer layer[2];
+  VdpRect layersrc, unscaledsrc;
+  if ( this->has_overlay ) {
+    //printf("vdpau_display_frame: overlay should be visible !\n");
+    layer_count = 2;
+    layersrc.x0 = 0; layersrc.y0 = 0; layersrc.x1 = this->overlay_output_width; layersrc.y1 = this->overlay_output_height;
+    layer[0].struct_version = VDP_LAYER_VERSION; layer[0].source_surface = this->overlay_output; layer[0].source_rect = &layersrc; layer[0].destination_rect = &vid_dest;
+    unscaledsrc.x0 = 0; unscaledsrc.y0 = 0; unscaledsrc.x1 = this->overlay_unscaled_width; unscaledsrc.y1 = this->overlay_unscaled_height;
+    layer[1].struct_version = VDP_LAYER_VERSION; layer[1].source_surface = this->overlay_unscaled; layer[1].source_rect = &unscaledsrc; layer[1].destination_rect = &unscaledsrc;
+    //printf( "layersrc = %d %d %d %d \n", layersrc.x0, layersrc.y0, layersrc.x1, layersrc.y1 );
+  }
+  else {
+    layer_count = 0;
+  }
+  
+  if ( frame->vo_frame.duration>2500 && frame->format==XINE_IMGFMT_VDPAU ) {
+    VdpTime current_time = 0;
+    VdpVideoSurface past[2];
+    VdpVideoSurface future[1];
+    past[1] = past[0] = (this->back_frame[0] && (this->back_frame[0]->format==XINE_IMGFMT_VDPAU)) ? this->back_frame[0]->vdpau_accel_data.surface : VDP_INVALID_HANDLE;
+    future[0] = surface;
+    st = vdp_video_mixer_render( this->video_mixer, VDP_INVALID_HANDLE, 0, VDP_VIDEO_MIXER_PICTURE_STRUCTURE_TOP_FIELD, 
+                               2, past, surface, 1, future, &vid_source, this->output_surface[this->current_output_surface], &out_dest, &vid_dest, layer_count, layer_count?layer:NULL );
+    if ( st != VDP_STATUS_OK )
+      printf( "vo_vdpau: vdp_video_mixer_render error : %s\n", vdp_get_error_string( st ) );
+
+    vdp_queue_get_time( vdp_queue, &current_time );
+    vdp_queue_display( vdp_queue, this->output_surface[this->current_output_surface], 0, 0, current_time );
+    if ( this->init_queue<2 ) ++this->init_queue;
+    this->current_output_surface ^= 1;
+    if ( this->init_queue>1 )
+      vdp_queue_block( vdp_queue, this->output_surface[this->current_output_surface], &last_time );
+    
+    if ( (this->sc.gui_width > this->output_surface_width[this->current_output_surface]) || (this->sc.gui_height > this->output_surface_height[this->current_output_surface]) ) {
+      /* recreate output surface to match window size */
+      printf( "vo_vdpau: output_surface size update\n" );
+      this->output_surface_width[this->current_output_surface] = this->sc.gui_width;
+      this->output_surface_height[this->current_output_surface] = this->sc.gui_height;
+
+      vdp_output_surface_destroy( this->output_surface[this->current_output_surface] );
+      vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->output_surface_width[this->current_output_surface], this->output_surface_height[this->current_output_surface], &this->output_surface[this->current_output_surface] );
+    }
+    
+    past[0] = surface;
+    future[0] = VDP_INVALID_HANDLE;
+    st = vdp_video_mixer_render( this->video_mixer, VDP_INVALID_HANDLE, 0, VDP_VIDEO_MIXER_PICTURE_STRUCTURE_BOTTOM_FIELD, 
+                               2, past, surface, 1, future, &vid_source, this->output_surface[this->current_output_surface], &out_dest, &vid_dest, layer_count, layer_count?layer:NULL );
+    if ( st != VDP_STATUS_OK )
+      printf( "vo_vdpau: vdp_video_mixer_render error : %s\n", vdp_get_error_string( st ) );
+
+    current_time += frame->vo_frame.duration*100000/18;
+    vdp_queue_display( vdp_queue, this->output_surface[this->current_output_surface], 0, 0, current_time );
+    if ( this->init_queue<2 ) ++this->init_queue;
+    this->current_output_surface ^= 1;
+  }
+  else {
+    st = vdp_video_mixer_render( this->video_mixer, VDP_INVALID_HANDLE, 0, VDP_VIDEO_MIXER_PICTURE_STRUCTURE_FRAME, 
+                               0, 0, surface, 0, 0, &vid_source, this->output_surface[this->current_output_surface], &out_dest, &vid_dest, layer_count, layer_count?layer:NULL );
+    if ( st != VDP_STATUS_OK )
+      printf( "vo_vdpau: vdp_video_mixer_render error : %s\n", vdp_get_error_string( st ) );
+
+    vdp_queue_display( vdp_queue, this->output_surface[this->current_output_surface], 0, 0, 0 );
+    if ( this->init_queue<2 ) ++this->init_queue;
+    this->current_output_surface ^= 1;
+  }
+
+  XUnlockDisplay( this->display );
+  
+  int i;  
+  if ( this->back_frame[NUM_FRAMES_BACK-1]) {
+    this->back_frame[NUM_FRAMES_BACK-1]->vo_frame.free (&this->back_frame[NUM_FRAMES_BACK-1]->vo_frame);
+  }
+  for ( i=NUM_FRAMES_BACK-1; i>0; i-- )
+    this->back_frame[i] = this->back_frame[i-1];
+  this->back_frame[0] = frame;
+}
+
+
+
+static int vdpau_get_property (vo_driver_t *this_gen, int property)
+{
+  vdpau_driver_t *this = (vdpau_driver_t*)this_gen;
+  
+  switch (property) {
+    case VO_PROP_MAX_NUM_FRAMES:
+      return 22;
+    case VO_PROP_WINDOW_WIDTH:
+      return this->sc.gui_width;
+    case VO_PROP_WINDOW_HEIGHT:
+      return this->sc.gui_height;
+    case VO_PROP_OUTPUT_WIDTH:
+      return this->sc.output_width;
+    case VO_PROP_OUTPUT_HEIGHT:
+      return this->sc.output_height;
+    case VO_PROP_OUTPUT_XOFFSET:
+      return this->sc.output_xoffset;
+    case VO_PROP_OUTPUT_YOFFSET:
+      return this->sc.output_yoffset;
+    case VO_PROP_HUE:
+      return 0;
+    case VO_PROP_SATURATION:
+      return 100;
+    case VO_PROP_CONTRAST:
+      return 100;
+    case VO_PROP_BRIGHTNESS:
+      return 0;
+  }
+
+  return -1;
+}
+
+
+
+static void vdpau_update_csc( vdpau_driver_t *this_gen )
+{
+  /*float hue = this_gen->hue/100.0;
+  float saturation = this_gen->saturation/100.0;
+  float contrast = this_gen->contrast/100.0;
+  float brightness = this_gen->brightness/100.0;
+  
+  printf( "vo_vdpau: vdpau_update_csc: hue=%f, saturation=%f, contrast=%f, brightness=%f\n", hue, saturation, contrast, brightness );
+  
+  VdpCSCMatrix matrix;
+  VdpProcamp procamp = { VDP_PROCAMP_VERSION, brightness, contrast, saturation, hue };
+  
+  VdpStatus st = vdp_generate_csc_matrix( &procamp, VDP_COLOR_STANDARD_ITUR_BT_601, &matrix );
+  if ( st != VDP_STATUS_OK ) {
+    printf( "vo_vdpau: error, can't generate csc matrix !!\n" );
+    return;
+  }
+  VdpVideoMixerAttribute attributes [] = { VDP_VIDEO_MIXER_ATTRIBUTE_CSC_MATRIX };
+  void* attribute_values[] = { &matrix };
+  st = vdp_video_mixer_set_attribute_values( this_gen->video_mixer, 1, attributes, attribute_values );
+  if ( st != VDP_STATUS_OK )
+    printf( "vo_vdpau: error, can't set csc matrix !!\n" );*/
+}
+
+
+
+static int vdpau_set_property (vo_driver_t *this_gen, int property, int value)
+{
+  vdpau_driver_t *this = (vdpau_driver_t*)this_gen;
+  
+  printf("vdpau_set_property: property=%d, value=%d\n", property, value );
+  
+  switch (property) {
+    /*case VO_PROP_ZOOM_X:
+      if ((value >= XINE_VO_ZOOM_MIN) && (value <= XINE_VO_ZOOM_MAX)) {
+        this->sc.zoom_factor_x = (double)value / (double)XINE_VO_ZOOM_STEP;
+        _x_vo_scale_compute_ideal_size( &this->sc );
+        this->sc.force_redraw = 1;    //* trigger re-calc of output size
+      }
+      break;
+    case VO_PROP_ZOOM_Y:
+      if ((value >= XINE_VO_ZOOM_MIN) && (value <= XINE_VO_ZOOM_MAX)) {
+        this->sc.zoom_factor_y = (double)value / (double)XINE_VO_ZOOM_STEP;
+        _x_vo_scale_compute_ideal_size( &this->sc );
+        this->sc.force_redraw = 1;    //* trigger re-calc of output size
+      }
+      break;*/
+    case VO_PROP_HUE: this->hue = value; vdpau_update_csc( this ); break;
+    case VO_PROP_SATURATION: this->saturation = value; vdpau_update_csc( this ); break;
+    case VO_PROP_CONTRAST: this->contrast = value; vdpau_update_csc( this ); break;
+    case VO_PROP_BRIGHTNESS: this->brightness = value; vdpau_update_csc( this ); break;
+  }
+  
+  return value;
+}
+
+
+
+static void vdpau_get_property_min_max (vo_driver_t *this_gen, int property, int *min, int *max)
+{
+  switch ( property ) {
+    case VO_PROP_HUE:
+      *max = 314; *min = -314; break;
+    case VO_PROP_SATURATION:
+      *max = 1000; *min = 0; break;
+    case VO_PROP_CONTRAST:
+      *max = 1000; *min = 0; break;
+    case VO_PROP_BRIGHTNESS:
+      *max = 100; *min = -100; break;
+    default:
+      *max = 0; *min = 0;
+  }
+}
+
+
+
+static int vdpau_gui_data_exchange (vo_driver_t *this_gen, int data_type, void *data)
+{
+  vdpau_driver_t *this = (vdpau_driver_t*)this_gen;
+  
+  switch (data_type) {
+#ifndef XINE_DISABLE_DEPRECATED_FEATURES
+    case XINE_GUI_SEND_COMPLETION_EVENT:
+      break;
+#endif
+
+    case XINE_GUI_SEND_EXPOSE_EVENT: {
+      if ( this->init_queue ) {
+        XLockDisplay( this->display );
+        int previous = this->current_output_surface ^ 1;
+        vdp_queue_display( vdp_queue, this->output_surface[previous], 0, 0, 0 );
+        XUnlockDisplay( this->display );
+      }
+      break;
+    }
+  
+    case XINE_GUI_SEND_DRAWABLE_CHANGED: {
+      VdpStatus st;
+      XLockDisplay( this->display );
+      this->drawable = (Drawable) data;
+      vdp_queue_destroy( vdp_queue );
+      vdp_queue_target_destroy( vdp_queue_target );
+      st = vdp_queue_target_create_x11( vdp_device, this->drawable, &vdp_queue_target );
+      if ( st != VDP_STATUS_OK ) {
+        printf( "vo_vdpau: FATAL !! Can't recreate presentation queue target after drawable change !!\n" );
+        XUnlockDisplay( this->display );
+        break;
+      }
+      st = vdp_queue_create( vdp_device, vdp_queue_target, &vdp_queue );
+      if ( st != VDP_STATUS_OK ) {
+        printf( "vo_vdpau: FATAL !! Can't recreate presentation queue after drawable change !!\n" );
+        XUnlockDisplay( this->display );
+        break;
+      }
+      VdpColor backColor;
+      backColor.red = backColor.green = backColor.blue = 0;
+      backColor.alpha = 1;
+      vdp_queue_set_backgroung_color( vdp_queue, &backColor );
+      XUnlockDisplay( this->display );
+      this->sc.force_redraw = 1;
+      break;
+    }
+
+    case XINE_GUI_SEND_TRANSLATE_GUI_TO_VIDEO: {
+      int x1, y1, x2, y2;
+      x11_rectangle_t *rect = data;
+
+      _x_vo_scale_translate_gui2video(&this->sc, rect->x, rect->y, &x1, &y1);
+      _x_vo_scale_translate_gui2video(&this->sc, rect->x + rect->w, rect->y + rect->h, &x2, &y2);
+      rect->x = x1;
+      rect->y = y1;
+      rect->w = x2-x1;
+      rect->h = y2-y1;
+      break;
+    }
+  
+    default:
+      return -1;
+  }
+
+  return 0;
+}
+
+
+
+static uint32_t vdpau_get_capabilities (vo_driver_t *this_gen)
+{
+  vdpau_driver_t *this = (vdpau_driver_t *) this_gen;
+  
+  return this->capabilities;
+}
+
+
+
+static void vdpau_dispose (vo_driver_t *this_gen)
+{
+  vdpau_driver_t *this = (vdpau_driver_t *) this_gen;
+  int i;
+  
+  this->yuv2rgb_factory->dispose (this->yuv2rgb_factory);
+
+  for ( i=0; i<XINE_VORAW_MAX_OVL; ++i ) {
+    if ( this->overlays[i].ovl_bitmap != VDP_INVALID_HANDLE )
+      vdp_bitmap_destroy( this->overlays[i].ovl_bitmap );
+  }
+  
+  if ( this->overlay_unscaled!=VDP_INVALID_HANDLE )
+    vdp_output_surface_destroy( this->overlay_unscaled );
+  if ( this->overlay_output!=VDP_INVALID_HANDLE )
+    vdp_output_surface_destroy( this->overlay_output );
+  if ( this->output_surface[0]!=VDP_INVALID_HANDLE )
+    vdp_output_surface_destroy( this->output_surface[0] );
+  if ( this->output_surface[1]!=VDP_INVALID_HANDLE )
+    vdp_output_surface_destroy( this->output_surface[1] );
+  if ( this->soft_surface != VDP_INVALID_HANDLE )
+    vdp_video_surface_destroy( this->soft_surface );
+  vdp_queue_destroy( vdp_queue );
+  vdp_queue_target_destroy( vdp_queue_target );
+  
+  for ( i=0; i<NUM_FRAMES_BACK; i++ )
+    if ( this->back_frame[i] )
+      this->back_frame[i]->vo_frame.dispose( &this->back_frame[i]->vo_frame );
+
+  free (this);
+}
+
+
+
+static int vdpau_init_error( VdpStatus st, const char *msg, vo_driver_t *driver, int error_string )
+{
+  if ( st != VDP_STATUS_OK ) {
+    if ( error_string )
+      printf( "vo_vdpau: %s : %s\n", msg, vdp_get_error_string( st ) );
+    else
+      printf( "vo_vdpau: %s\n", msg );
+    vdpau_dispose( driver );
+    return 1;
+  }
+  return 0;
+}
+
+
+
+static vo_driver_t *vdpau_open_plugin (video_driver_class_t *class_gen, const void *visual_gen)
+{
+  vdpau_class_t       *class   = (vdpau_class_t *) class_gen;
+  x11_visual_t         *visual  = (x11_visual_t *) visual_gen;
+  vdpau_driver_t      *this;
+  config_values_t      *config  = class->xine->config;
+  int i;
+
+  this = (vdpau_driver_t *) calloc(1, sizeof(vdpau_driver_t));
+
+  if (!this)
+    return NULL;
+  
+  this->display       = visual->display;
+  this->screen        = visual->screen;
+  this->drawable      = visual->d;
+
+  _x_vo_scale_init(&this->sc, 1, 0, config);
+  this->sc.frame_output_cb  = visual->frame_output_cb;
+  this->sc.dest_size_cb     = visual->dest_size_cb;
+  this->sc.user_data        = visual->user_data;
+  this->sc.user_ratio       = XINE_VO_ASPECT_AUTO;
+
+  this->xine                    = class->xine;
+  this->config                  = config;
+  
+  this->vo_driver.get_capabilities     = vdpau_get_capabilities;
+  this->vo_driver.alloc_frame          = vdpau_alloc_frame;
+  this->vo_driver.update_frame_format  = vdpau_update_frame_format;
+  this->vo_driver.overlay_begin        = vdpau_overlay_begin;
+  this->vo_driver.overlay_blend        = vdpau_overlay_blend;
+  this->vo_driver.overlay_end          = vdpau_overlay_end;
+  this->vo_driver.display_frame        = vdpau_display_frame;
+  this->vo_driver.get_property         = vdpau_get_property;
+  this->vo_driver.set_property         = vdpau_set_property;
+  this->vo_driver.get_property_min_max = vdpau_get_property_min_max;
+  this->vo_driver.gui_data_exchange    = vdpau_gui_data_exchange;
+  this->vo_driver.dispose              = vdpau_dispose;
+  this->vo_driver.redraw_needed        = vdpau_redraw_needed;
+
+  for ( i=0; i<XINE_VORAW_MAX_OVL; ++i ) {
+    this->overlays[i].ovl_w = this->overlays[i].ovl_h = 0;
+    this->overlays[i].bitmap_width = this->overlays[i].bitmap_height = 0;
+    this->overlays[i].ovl_bitmap = VDP_INVALID_HANDLE;
+    this->overlays[i].ovl_x = this->overlays[i].ovl_y = 0;
+  }
+  this->overlay_output = VDP_INVALID_HANDLE;
+  this->overlay_output_width = this->overlay_output_height = 0;
+  this->overlay_unscaled = VDP_INVALID_HANDLE;
+  this->overlay_unscaled_width = this->overlay_unscaled_height = 0;
+  this->ovl_changed = 0;
+  this->has_overlay = 0;
+
+  /*  overlay converter */
+  this->yuv2rgb_factory = yuv2rgb_factory_init (MODE_24_BGR, 0, NULL);
+  this->ovl_yuv2rgb = this->yuv2rgb_factory->create_converter( this->yuv2rgb_factory );
+  
+  VdpStatus st = vdp_device_create_x11( visual->display, visual->screen, &vdp_device, &vdp_get_proc_address );
+  if ( st != VDP_STATUS_OK ) {
+    printf( "vo_vdpau: Can't create vdp device : " );
+    if ( st == VDP_STATUS_NO_IMPLEMENTATION )
+      printf( "No vdpau implementation.\n" );
+    else
+      printf( "unsupported GPU?\n" );
+    vdpau_dispose( &this->vo_driver );
+    return NULL;
+  }
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_GET_ERROR_STRING , (void*)&vdp_get_error_string );
+  if ( vdpau_init_error( st, "Can't get GET_ERROR_STRING proc address !!", &this->vo_driver, 0 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_GET_API_VERSION , (void*)&vdp_get_api_version );
+  if ( vdpau_init_error( st, "Can't get GET_API_VERSION proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  uint32_t tmp;
+  vdp_get_api_version( &tmp );
+  printf( "vo_vdpau: vdpau API version : %d\n", tmp );
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_GET_INFORMATION_STRING , (void*)&vdp_get_information_string );
+  if ( vdpau_init_error( st, "Can't get GET_INFORMATION_STRING proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  const char *s;
+  st = vdp_get_information_string( &s );
+  printf( "vo_vdpau: vdpau implementation description : %s\n", s );
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_SURFACE_QUERY_GET_PUT_BITS_Y_CB_CR_CAPABILITIES , (void*)&vdp_video_surface_query_get_put_bits_ycbcr_capabilities );
+  if ( vdpau_init_error( st, "Can't get VIDEO_SURFACE_QUERY_GET_PUT_BITS_Y_CB_CR_CAPABILITIES proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  VdpBool ok;
+  st = vdp_video_surface_query_get_put_bits_ycbcr_capabilities( vdp_device, VDP_CHROMA_TYPE_422, VDP_YCBCR_FORMAT_YUYV, &ok );
+  if ( vdpau_init_error( st, "Failed to check vdpau yuy2 capability", &this->vo_driver, 1 ) )
+    return NULL;
+  if ( !ok ) {
+    printf( "vo_vdpau: VideoSurface doesn't support yuy2, sorry.\n");
+    vdpau_dispose( &this->vo_driver );
+    return NULL;
+  }
+  st = vdp_video_surface_query_get_put_bits_ycbcr_capabilities( vdp_device, VDP_CHROMA_TYPE_420, VDP_YCBCR_FORMAT_YV12, &ok );
+  if ( vdpau_init_error( st, "Failed to check vdpau yv12 capability", &this->vo_driver, 1 ) )
+    return NULL;
+  if ( !ok ) {
+    printf( "vo_vdpau: VideoSurface doesn't support yv12, sorry.\n");
+    vdpau_dispose( &this->vo_driver );
+    return NULL;
+  }
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_SURFACE_CREATE , (void*)&vdp_video_surface_create );
+  if ( vdpau_init_error( st, "Can't get VIDEO_SURFACE_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_SURFACE_DESTROY , (void*)&vdp_video_surface_destroy );
+  if ( vdpau_init_error( st, "Can't get VIDEO_SURFACE_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_SURFACE_PUT_BITS_Y_CB_CR , (void*)&vdp_video_surface_putbits_ycbcr );
+  if ( vdpau_init_error( st, "Can't get VIDEO_SURFACE_PUT_BITS_Y_CB_CR proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_SURFACE_GET_BITS_Y_CB_CR , (void*)&vdp_video_surface_getbits_ycbcr );
+  if ( vdpau_init_error( st, "Can't get VIDEO_SURFACE_GET_BITS_Y_CB_CR proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_OUTPUT_SURFACE_CREATE , (void*)&vdp_output_surface_create );
+  if ( vdpau_init_error( st, "Can't get OUTPUT_SURFACE_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_OUTPUT_SURFACE_DESTROY , (void*)&vdp_output_surface_destroy );
+  if ( vdpau_init_error( st, "Can't get OUTPUT_SURFACE_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_OUTPUT_SURFACE_RENDER_BITMAP_SURFACE , (void*)&vdp_output_surface_render_bitmap_surface );
+  if ( vdpau_init_error( st, "Can't get OUTPUT_SURFACE_RENDER_BITMAP_SURFACE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_OUTPUT_SURFACE_PUT_BITS_NATIVE , (void*)&vdp_output_surface_put_bits );
+  if ( vdpau_init_error( st, "Can't get VDP_FUNC_ID_OUTPUT_SURFACE_PUT_BITS_NATIVE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_MIXER_CREATE , (void*)&vdp_video_mixer_create );
+  if ( vdpau_init_error( st, "Can't get VIDEO_MIXER_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_MIXER_DESTROY , (void*)&vdp_video_mixer_destroy );
+  if ( vdpau_init_error( st, "Can't get VIDEO_MIXER_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_MIXER_RENDER , (void*)&vdp_video_mixer_render );
+  if ( vdpau_init_error( st, "Can't get VIDEO_MIXER_RENDER proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_VIDEO_MIXER_SET_ATTRIBUTE_VALUES , (void*)&vdp_video_mixer_set_attribute_values );
+  if ( vdpau_init_error( st, "Can't get VIDEO_MIXER_SET_ATTRIBUTE_VALUES proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_GENERATE_CSC_MATRIX , (void*)&vdp_generate_csc_matrix );
+  if ( vdpau_init_error( st, "Can't get GENERATE_CSC_MATRIX proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_TARGET_CREATE_X11 , (void*)&vdp_queue_target_create_x11 );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_TARGET_CREATE_X11 proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_TARGET_DESTROY , (void*)&vdp_queue_target_destroy );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_TARGET_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_CREATE , (void*)&vdp_queue_create );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_DESTROY , (void*)&vdp_queue_destroy );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_DISPLAY , (void*)&vdp_queue_display );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_DISPLAY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_BLOCK_UNTIL_SURFACE_IDLE , (void*)&vdp_queue_block );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_BLOCK_UNTIL_SURFACE_IDLE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_SET_BACKGROUND_COLOR , (void*)&vdp_queue_set_backgroung_color );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_SET_BACKGROUND_COLOR proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_PRESENTATION_QUEUE_GET_TIME , (void*)&vdp_queue_get_time );
+  if ( vdpau_init_error( st, "Can't get PRESENTATION_QUEUE_GET_TIME proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_DECODER_QUERY_CAPABILITIES , (void*)&vdp_decoder_query_capabilities );
+  if ( vdpau_init_error( st, "Can't get DECODER_QUERY_CAPABILITIES proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_DECODER_CREATE , (void*)&vdp_decoder_create );
+  if ( vdpau_init_error( st, "Can't get DECODER_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_DECODER_DESTROY , (void*)&vdp_decoder_destroy );
+  if ( vdpau_init_error( st, "Can't get DECODER_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_DECODER_RENDER , (void*)&vdp_decoder_render );
+  if ( vdpau_init_error( st, "Can't get DECODER_RENDER proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_BITMAP_SURFACE_CREATE , (void*)&vdp_bitmap_create );
+  if ( vdpau_init_error( st, "Can't get BITMAP_SURFACE_CREATE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_BITMAP_SURFACE_DESTROY , (void*)&vdp_bitmap_destroy );
+  if ( vdpau_init_error( st, "Can't get BITMAP_SURFACE_DESTROY proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_get_proc_address( vdp_device, VDP_FUNC_ID_BITMAP_SURFACE_PUT_BITS_NATIVE , (void*)&vdp_bitmap_put_bits );
+  if ( vdpau_init_error( st, "Can't get BITMAP_SURFACE_PUT_BITS_NATIVE proc address !!", &this->vo_driver, 1 ) )
+    return NULL;
+
+  st = vdp_queue_target_create_x11( vdp_device, this->drawable, &vdp_queue_target );
+  if ( vdpau_init_error( st, "Can't create presentation queue target !!", &this->vo_driver, 1 ) )
+    return NULL;
+  st = vdp_queue_create( vdp_device, vdp_queue_target, &vdp_queue );
+  if ( vdpau_init_error( st, "Can't create presentation queue !!", &this->vo_driver, 1 ) )
+    return NULL;
+
+  VdpColor backColor = { 0, 0, 0, 1 };
+  vdp_queue_set_backgroung_color( vdp_queue, &backColor );
+
+  this->soft_surface_width = 1280;
+  this->soft_surface_height = 720;
+  this->soft_surface_format = XINE_IMGFMT_YV12;
+  VdpChromaType chroma = VDP_CHROMA_TYPE_420;
+  st = vdp_video_surface_create( vdp_device, chroma, this->soft_surface_width, this->soft_surface_height, &this->soft_surface );
+  if ( vdpau_init_error( st, "Can't create video surface !!", &this->vo_driver, 1 ) )
+    return NULL;
+  
+  this->output_surface_width[0] = this->output_surface_width[1] = 1280;
+  this->output_surface_height[0] = this->output_surface_height[1] = 720;
+  this->current_output_surface = 0;
+  this->init_queue = 0;
+  st = vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->output_surface_width[0], this->output_surface_height[0], &this->output_surface[0] );
+  if ( vdpau_init_error( st, "Can't create first output surface !!", &this->vo_driver, 1 ) ) {
+    vdp_video_surface_destroy( this->soft_surface );
+    return NULL;
+  }
+  st = vdp_output_surface_create( vdp_device, VDP_RGBA_FORMAT_B8G8R8A8, this->output_surface_width[0], this->output_surface_height[0], &this->output_surface[1] );
+  if ( vdpau_init_error( st, "Can't create second output surface !!", &this->vo_driver, 1 ) ) {
+    vdp_video_surface_destroy( this->soft_surface );
+    vdp_output_surface_destroy( this->output_surface[0] );
+    return NULL;
+  }
+
+  this->video_mixer_chroma = chroma;
+  this->video_mixer_width = this->soft_surface_width;
+  this->video_mixer_height = this->soft_surface_height;
+  VdpVideoMixerFeature features[] = { VDP_VIDEO_MIXER_FEATURE_DEINTERLACE_TEMPORAL, VDP_VIDEO_MIXER_FEATURE_DEINTERLACE_TEMPORAL_SPATIAL };
+  VdpVideoMixerParameter params[] = { VDP_VIDEO_MIXER_PARAMETER_VIDEO_SURFACE_WIDTH, VDP_VIDEO_MIXER_PARAMETER_VIDEO_SURFACE_HEIGHT, VDP_VIDEO_MIXER_PARAMETER_CHROMA_TYPE, VDP_VIDEO_MIXER_PARAMETER_LAYERS };
+  int num_layers = 2;
+  void const *param_values[] = { &this->video_mixer_width, &this->video_mixer_height, &chroma, &num_layers };
+  st = vdp_video_mixer_create( vdp_device, 2, features, 4, params, param_values, &this->video_mixer );
+  if ( vdpau_init_error( st, "Can't create video mixer !!", &this->vo_driver, 1 ) ) {
+    vdp_video_surface_destroy( this->soft_surface );
+    vdp_output_surface_destroy( this->output_surface[0] );
+    vdp_output_surface_destroy( this->output_surface[1] );
+    return NULL;
+  }
+  
+  this->capabilities = VO_CAP_YV12 | VO_CAP_YUY2 | VO_CAP_CROP;
+  ok = 0;
+  uint32_t mw, mh, ml, mr;
+  st = vdp_decoder_query_capabilities( vdp_device, VDP_DECODER_PROFILE_H264_MAIN, &ok, &ml, &mr, &mw, &mh );
+  if ( st != VDP_STATUS_OK  )
+    printf( "vo_vdpau: getting h264_supported failed! : %s\n", vdp_get_error_string( st ) );
+  else if ( !ok )
+    printf( "vo_vdpau: no support for h264 ! : no ok\n" );
+  else
+    this->capabilities |= VO_CAP_VDPAU_H264;
+  
+  st = vdp_decoder_query_capabilities( vdp_device, VDP_DECODER_PROFILE_MPEG2_MAIN, &ok, &ml, &mr, &mw, &mh );
+  if ( st != VDP_STATUS_OK  )
+    printf( "vo_vdpau: getting mpeg12_supported failed! : %s\n", vdp_get_error_string( st ) );
+  else if ( !ok )
+    printf( "vo_vdpau: no support for mpeg1/2 ! : no ok\n" );
+  else
+    this->capabilities |= VO_CAP_VDPAU_MPEG12;
+  
+  this->capabilities |= VO_CAP_UNSCALED_OVERLAY;
+    
+  for ( i=0; i<NUM_FRAMES_BACK; i++)
+    this->back_frame[i] = NULL;
+  
+  this->hue = 0;
+  this->saturation = 100;
+  this->contrast = 100;
+  this->brightness = 0;
+  
+  this->allocated_surfaces = 0;
+  
+  return &this->vo_driver;
+}
+
+/*
+ * class functions
+ */
+
+static char* vdpau_get_identifier (video_driver_class_t *this_gen)
+{
+  return "vdpau";
+}
+
+
+
+static char* vdpau_get_description (video_driver_class_t *this_gen)
+{
+  return _("xine video output plugin using VDPAU hardware acceleration");
+}
+
+
+
+static void vdpau_dispose_class (video_driver_class_t *this_gen)
+{
+  vdpau_class_t *this = (vdpau_class_t *) this_gen;
+  free (this);
+}
+
+
+
+static void *vdpau_init_class (xine_t *xine, void *visual_gen)
+{
+  vdpau_class_t *this = (vdpau_class_t *) calloc(1, sizeof(vdpau_class_t));
+
+  this->driver_class.open_plugin     = vdpau_open_plugin;
+  this->driver_class.get_identifier  = vdpau_get_identifier;
+  this->driver_class.get_description = vdpau_get_description;
+  this->driver_class.dispose         = vdpau_dispose_class;
+  this->xine                         = xine;
+
+  return this;
+}
+
+
+
+static const vo_info_t vo_info_vdpau = {
+  11,                    /* priority    */
+  XINE_VISUAL_TYPE_X11  /* visual type */
+};
+
+
+/*
+ * exported plugin catalog entry
+ */
+
+const plugin_info_t xine_plugin_info[] EXPORTED = {
+  /* type, API, "name", version, special_info, init_function */
+  { PLUGIN_VIDEO_OUT, 21, "vdpau", XINE_VERSION_CODE, &vo_info_vdpau, vdpau_init_class },
+  { PLUGIN_NONE, 0, "", 0, NULL, NULL }
+};
\ No newline at end of file
diff -Naur xine-lib-1.1.15-old/src/video_out/video_out_xv.c xine-lib-1.1.15-new/src/video_out/video_out_xv.c
--- xine-lib-1.1.15-old/src/video_out/video_out_xv.c	2008-08-01 15:16:05.000000000 -0700
+++ xine-lib-1.1.15-new/src/video_out/video_out_xv.c	2008-12-22 09:11:43.000000000 -0800
@@ -907,6 +907,8 @@
 static int xv_set_property (vo_driver_t *this_gen,
 			    int property, int value) {
   xv_driver_t *this = (xv_driver_t *) this_gen;
+  
+  printf("xv_set_property: property=%d, value=%d\n", property, value );
 
   if (this->props[property].atom != None) {
 
diff -Naur xine-lib-1.1.15-old/src/xine-engine/accel_vdpau.h xine-lib-1.1.15-new/src/xine-engine/accel_vdpau.h
--- xine-lib-1.1.15-old/src/xine-engine/accel_vdpau.h	1969-12-31 16:00:00.000000000 -0800
+++ xine-lib-1.1.15-new/src/xine-engine/accel_vdpau.h	2008-12-22 09:11:43.000000000 -0800
@@ -0,0 +1,59 @@
+/*
+ * Copyright (C) 2008 the xine project
+ *
+ * This file is part of xine, a free video player.
+ *
+ * xine is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * xine is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
+ *
+ *
+ * Common acceleration definitions for vdpau
+ *
+ *
+ */
+
+#ifndef HAVE_XINE_ACCEL_VDPAU_H
+#define HAVE_XINE_ACCEL_VDPAU_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <vdpau/vdpau.h>
+
+
+typedef struct {
+
+  VdpDevice vdp_device;
+
+  VdpGetErrorString *vdp_get_error_string;
+  VdpDecoderCreate *vdp_decoder_create;
+  VdpDecoderDestroy *vdp_decoder_destroy;
+  VdpDecoderRender *vdp_decoder_render;
+
+  VdpVideoSurface surface;
+  VdpChromaType chroma;
+
+} vdpau_accel_t;
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
+
diff -Naur xine-lib-1.1.15-old/src/xine-engine/video_out.h xine-lib-1.1.15-new/src/xine-engine/video_out.h
--- xine-lib-1.1.15-old/src/xine-engine/video_out.h	2008-06-14 16:15:00.000000000 -0700
+++ xine-lib-1.1.15-new/src/xine-engine/video_out.h	2008-12-22 09:11:43.000000000 -0800
@@ -1,24 +1,24 @@
 /*
  * Copyright (C) 2000-2004 the xine project
- * 
+ *
  * This file is part of xine, a free video player.
- * 
+ *
  * xine is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
- * 
+ *
  * xine is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- * 
+ *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
  *
  *
- * xine version of video_out.h 
+ * xine version of video_out.h
  *
  * vo_frame    : frame containing yuv data and timing info,
  *               transferred between video_decoder and video_output
@@ -51,7 +51,7 @@
 #endif
 
 
-typedef struct vo_frame_s vo_frame_t; 
+typedef struct vo_frame_s vo_frame_t;
 typedef struct vo_driver_s vo_driver_t;
 typedef struct video_driver_class_s video_driver_class_t;
 typedef struct vo_overlay_s vo_overlay_t;
@@ -84,7 +84,7 @@
   /* tell video driver that the decoder starts a new field */
   void (*field) (vo_frame_t *vo_img, int which_field);
 
-  /* append this frame to the display queue, 
+  /* append this frame to the display queue,
      returns number of frames to skip if decoder is late */
   /* when the frame does not originate from a stream, it is legal to pass an anonymous stream */
   int (*draw) (vo_frame_t *vo_img, xine_stream_t *stream);
@@ -112,7 +112,7 @@
 
   /* yv12 (planar)       base[0]: y,       base[1]: u,  base[2]: v  */
   /* yuy2 (interleaved)  base[0]: yuyv..., base[1]: --, base[2]: -- */
-  uint8_t                   *base[3];       
+  uint8_t                   *base[3];
   int                        pitches[3];
 
   /* info that can be used for interlaced output (e.g. tv-out)      */
@@ -123,13 +123,13 @@
    */
   int                        progressive_frame;
   int                        picture_coding_type;
-  
+
   /* cropping to be done */
   int                        crop_left, crop_right, crop_top, crop_bottom;
 
   /* extra info coming from input or demuxers */
-  extra_info_t              *extra_info;    
- 
+  extra_info_t              *extra_info;
+
   /* additional information to be able to duplicate frames:         */
   int                        width, height;
   double                     ratio;         /* aspect ratio  */
@@ -138,7 +138,7 @@
   int                        drawn;         /* used by decoder, frame has already been drawn */
   int                        flags;         /* remember the frame flags */
   int                        proc_called;   /* track use of proc_*() methods */
-  
+
   /* Used to carry private data for accelerated plugins.*/
   void                      *accel_data;
 
@@ -146,18 +146,18 @@
   xine_video_port_t         *port;
   vo_driver_t               *driver;
   xine_stream_t             *stream;
-  
+
   /* displacement for overlays */
   int                       overlay_offset_x, overlay_offset_y;
-  
-  /* 
+
+  /*
    * that part is used only by video_out.c for frame management
    * obs: changing anything here will require recompiling vo drivers
    */
   struct vo_frame_s         *next;
   int                        lock_counter;
   pthread_mutex_t            mutex; /* protect access to lock_count */
-  
+
   int                        id; /* debugging - track this frame */
   int                        is_first;
 };
@@ -177,8 +177,8 @@
    * (e.g. you are a post plugin) it is legal to pass an anonymous stream */
   void (*open) (xine_video_port_t *self, xine_stream_t *stream);
 
-  /* 
-   * get_frame - allocate an image buffer from display driver 
+  /*
+   * get_frame - allocate an image buffer from display driver
    *
    * params : width      == width of video to display.
    *          height     == height of video to display.
@@ -186,16 +186,16 @@
    *          format     == FOURCC descriptor of image format
    *          flags      == field/prediction flags
    */
-  vo_frame_t* (*get_frame) (xine_video_port_t *self, uint32_t width, 
-			    uint32_t height, double ratio, 
+  vo_frame_t* (*get_frame) (xine_video_port_t *self, uint32_t width,
+			    uint32_t height, double ratio,
 			    int format, int flags);
 
   /* retrieves the last displayed frame (useful for taking snapshots) */
   vo_frame_t* (*get_last_frame) (xine_video_port_t *self);
-  
+
   /* overlay stuff */
   void (*enable_ovl) (xine_video_port_t *self, int ovl_enable);
-  
+
   /* get overlay manager */
   video_overlay_manager_t* (*get_overlay_manager) (xine_video_port_t *self);
 
@@ -208,11 +208,11 @@
    */
   int (*get_property) (xine_video_port_t *self, int property);
   int (*set_property) (xine_video_port_t *self, int property, int value);
-  
+
   /* return true if port is opened for this stream, stream can be anonymous */
-  int (*status) (xine_video_port_t *self, xine_stream_t *stream, 
+  int (*status) (xine_video_port_t *self, xine_stream_t *stream,
                  int *width, int *height, int64_t *img_duration);
-  
+
   /* video driver is no longer used by decoder => close */
   /* when you are not a full-blown stream, but still need to close the port
    * (e.g. you are a post plugin) it is legal to pass an anonymous stream */
@@ -235,9 +235,9 @@
 #define VO_PROP_BRIGHTNESS            5
 #define VO_PROP_COLORKEY              6
 #define VO_PROP_AUTOPAINT_COLORKEY    7
-#define VO_PROP_ZOOM_X                8 
-#define VO_PROP_PAN_SCAN              9 
-#define VO_PROP_TVMODE		      10 
+#define VO_PROP_ZOOM_X                8
+#define VO_PROP_PAN_SCAN              9
+#define VO_PROP_TVMODE		      10
 #define VO_PROP_MAX_NUM_FRAMES        11
 #define VO_PROP_ZOOM_Y                13
 #define VO_PROP_DISCARD_FRAMES        14 /* not used by drivers */
@@ -271,6 +271,7 @@
 #define VO_PAN_SCAN_FLAG     4
 #define VO_INTERLACED_FLAG   8
 #define VO_NEW_SEQUENCE_FLAG 16 /* set after MPEG2 Sequence Header Code (used by XvMC) */
+#define VO_CHROMA_422        32 /* used by VDPAU, default is chroma_420 */
 
 /* video driver capabilities */
 #define VO_CAP_YV12                   0x00000001 /* driver can handle YUV 4:2:0 pictures */
@@ -280,6 +281,8 @@
 #define VO_CAP_UNSCALED_OVERLAY       0x00000010 /* driver can blend overlay at output resolution */
 #define VO_CAP_CROP                   0x00000020 /* driver can crop */
 #define VO_CAP_XXMC                   0x00000040 /* driver can use extended XvMC */
+#define VO_CAP_VDPAU_H264             0x00000080 /* driver can use VDPAU for H264 */
+#define VO_CAP_VDPAU_MPEG12           0x00000100 /* driver can use VDPAU for mpeg1/2 */
 
 
 /*
@@ -303,7 +306,7 @@
    */
   vo_frame_t* (*alloc_frame) (vo_driver_t *self);
 
-  /* 
+  /*
    * check if the given image fullfills the format specified
    * (re-)allocate memory if necessary
    */
@@ -334,7 +337,7 @@
    * these can be used by the gui directly:
    */
   int (*get_property) (vo_driver_t *self, int property);
-  int (*set_property) (vo_driver_t *self, 
+  int (*set_property) (vo_driver_t *self,
 		       int property, int value);
   void (*get_property_min_max) (vo_driver_t *self,
 				int property, int *min, int *max);
@@ -349,7 +352,7 @@
 			    void *data);
 
   /* check if a redraw is needed (due to resize)
-   * this is only used for still frames, normal video playback 
+   * this is only used for still frames, normal video playback
    * must call that inside display_frame() function.
    */
   int (*redraw_needed) (vo_driver_t *self);
@@ -358,7 +361,7 @@
    * free all resources, close driver
    */
   void (*dispose) (vo_driver_t *self);
-  
+
   void *node; /* needed by plugin_loader */
 };
 
@@ -368,14 +371,14 @@
    * open a new instance of this plugin class
    */
   vo_driver_t* (*open_plugin) (video_driver_class_t *self, const void *visual);
-  
+
   /*
    * return short, human readable identifier for this plugin class
    */
   char* (*get_identifier) (video_driver_class_t *self);
 
   /*
-   * return human readable (verbose = 1 line) description for 
+   * return human readable (verbose = 1 line) description for
    * this plugin class
    */
   char* (*get_description) (video_driver_class_t *self);
@@ -401,7 +404,7 @@
   int               y;             /* y start of subpicture area       */
   int               width;         /* width of subpicture area         */
   int               height;        /* height of subpicture area        */
-  
+
   uint32_t          color[OVL_PALETTE_SIZE];  /* color lookup table     */
   uint8_t           trans[OVL_PALETTE_SIZE];  /* mixer key table        */
   int               rgb_clut;      /* true if clut was converted to rgb */
@@ -414,7 +417,7 @@
   uint32_t          hili_color[OVL_PALETTE_SIZE];
   uint8_t           hili_trans[OVL_PALETTE_SIZE];
   int               hili_rgb_clut; /* true if clut was converted to rgb */
-  
+
   int               unscaled;      /* true if it should be blended unscaled */
 };
 
@@ -427,20 +430,20 @@
  */
 struct video_overlay_manager_s {
   void (*init) (video_overlay_manager_t *this_gen);
-  
+
   void (*dispose) (video_overlay_manager_t *this_gen);
-  
+
   int32_t (*get_handle) (video_overlay_manager_t *this_gen, int object_type );
-  
+
   void (*free_handle) (video_overlay_manager_t *this_gen, int32_t handle);
-  
+
   int32_t (*add_event) (video_overlay_manager_t *this_gen, void *event);
-  
+
   void (*flush_events) (video_overlay_manager_t *this_gen );
-  
+
   int (*redraw_needed) (video_overlay_manager_t *this_gen, int64_t vpts );
-  
-  void (*multiple_overlay_blend) (video_overlay_manager_t *this_gen, int64_t vpts, 
+
+  void (*multiple_overlay_blend) (video_overlay_manager_t *this_gen, int64_t vpts,
                                   vo_driver_t *output, vo_frame_t *vo_img, int enabled);
 };
 
